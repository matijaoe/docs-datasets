[
  {
    "title": "Running on Deno | Kysely",
    "url": "https://kysely.dev/docs/runtimes/deno",
    "html": "Other runtimesRunning on Deno\nRunning on Deno\n\nKysely doesn't include drivers for Deno, but you can still use Kysely as a query builder or implement your own driver:\n\n// We use jsdeliver to get Kysely from npm.\nimport {\n  DummyDriver,\n  Generated,\n  Kysely,\n  PostgresAdapter,\n  PostgresIntrospector,\n  PostgresQueryCompiler,\n} from 'https://cdn.jsdelivr.net/npm/kysely/dist/esm/index.js'\n\ninterface Person {\n  id: Generated<number>\n  first_name: string\n  last_name: string | null\n}\n\ninterface Database {\n  person: Person\n}\n\nconst db = new Kysely<Database>({\n  dialect: {\n    createAdapter() {\n      return new PostgresAdapter()\n    },\n    createDriver() {\n      // You need a driver to be able to execute queries. In this example\n      // we use the dummy driver that never does anything.\n      return new DummyDriver()\n    },\n    createIntrospector(db: Kysely<unknown>) {\n      return new PostgresIntrospector(db)\n    },\n    createQueryCompiler() {\n      return new PostgresQueryCompiler()\n    },\n  },\n})\n\nconst query = db.selectFrom('person').select('id')\nconst sql = query.compile()\n\nconsole.log(sql.sql)\n\nPrevious\nOther runtimes\nNext\nBrowser"
  },
  {
    "title": "Working with schemas | Kysely",
    "url": "https://kysely.dev/docs/recipes/schemas",
    "html": "RecipesWorking with schemas\nWorking with schemas\n\nFirst of all, when we talk about schemas in this document, we mean custom schemas like postgres schemas.\n\nThere are two common ways to use schemas:\n\nTo group a logical set of tables under the same \"namespace\". For example all tables directly related to users could live under a user schema.\n\nTo have a separate namespaced copy of a set of tables for each tenant in a multitenant application.\n\nKysely offers tools for both of these cases.\n\n1​\n\nWhen you have an enumarable set of schemas, you can add them to your database interface like this:\n\ninterface Database {\n  'user.user': UserTable\n  'user.user_permission': UserPermissionTable\n  'user.permission': PermissionTable\n  pet: PetTable\n}\n\n\nthen you can refer to the tables just like you would a normal table:\n\ndb.selectFrom('user.user')\n  .where('username', '=', '')\n  // You can also include the full table name\n  .where('user.user.created_at', '>', createdAt)\n  .innerJoin('user.user_permission as up', 'up.user_id', 'user.user.id')\n  .innerJoin('user.permission as p', 'p.id', 'up.permission_id')\n  .selectAll()\n\n2​\n\nIn the multitenant case you have a schema per tenant and you can't add each of them to the database interface, nor would it make sense to do so. In this case you can use the withSchema method.\n\nThe withSchema method sets the default schema of all table references that don't explicitly specify a schema:\n\ndb.withSchema(tenant)\n  .selectFrom('user')\n  .innerJoin('user_permission as up', 'up.user_id', 'user.id')\n  .innerJoin('public.permission as p', 'p.id', 'up.permission_id')\n  .selectAll()\n\n\nThis is the generated SQL assuming tenant equals 'acme':\n\nselect * from \"acme\".\"user\"\ninner join \"acme\".\"user_permission\" as \"up\" on \"up\".\"user_id\" = \"acme\".\"user\".\"id\"\ninner join \"public\".\"permission\" as \"p\" on \"p\".\"id\" = \"up\".\"permission_id\"\n\n\nIn this example we also referred to a shared table permission in the public schema. Please note that you need to add a 'public.permission': PermissionTable item in your database schema to be able to refer to the public.permission table:\n\ninterface Database {\n  // Add your tenant tables without any schema:\n  user: UserTable\n  user_permission: UserPermissionTable\n\n  // Add schemas and tables you need to explicitly reference like this:\n  'public.permission': PermissionTable\n\n  // You can also have other shared tables with or without schemas here.\n  // But keep in mind that if you want to refer to them from a `withSchema`\n  // query, you need the table name with the schema name.\n  pet: PetTable\n}\n\n\nSee the first case for more info.\n\nPrevious\nRelations\nNext\nSplitting build, compile and execute code"
  },
  {
    "title": "Relations | Kysely",
    "url": "https://kysely.dev/docs/recipes/relations",
    "html": "RecipesRelations\nRelations\nKysely IS NOT an ORM. Kysely DOES NOT have the concept of relations. Kysely IS a query builder. Kysely DOES build the SQL you tell it to, nothing more, nothing less.\n\nPhew, glad we got that out the way..\n\nHaving said all that, there are ways to nest related rows in your queries. You just have to do it using the tools SQL and the underlying dialect (e.g. PostgreSQL, MySQL, or SQLite) provide. In this recipe we show one way to do that when using the built-in PostgreSQL, MySQL, and SQLite dialects.\n\nThe json data type and functions​\n\nPostgreSQL and MySQL have rich JSON support through their json data types and functions. pg and mysql2, the node drivers, automatically parse returned json columns as json objects. With the combination of these two things, we can write some super efficient queries with nested relations.\n\nPARSING JSON\n\nThe built in SqliteDialect and some 3rd party dialects don't parse the returned JSON columns to objects automatically. Not even if they use PostgreSQL or MySQL under the hood! Parsing is handled (or not handled) by the database driver that Kysely has no control over. If your JSON columns get returned as strings, you can use the ParseJSONResultsPlugin:\n\nconst db = new Kysely<DB>({\n  ...\n  plugins: [new ParseJSONResultsPlugin()]\n})\n\n\nLet's start with some raw postgres SQL, and then see how we can write the query using Kysely in a nice type-safe way.\n\nIn the following query, we fetch a list of people (from \"person\" table) and for each person, we nest the person's pets, and mother, into the returned objects:\n\nSELECT\n  person.*,\n\n  -- Select person's pets as a json array\n  (\n    SELECT \n      COALESCE(JSON_AGG(pets), '[]')\n    FROM\n    (\n      SELECT \n        pet.id, pet.name\n      FROM\n        pet\n      WHERE \n        pet.owner_id = person.id\n      ORDER BY \n        pet.name\n    ) pets\n  ) pets,\n\n  -- Select person's mother as a json object\n  (\n    SELECT \n      TO_JSON(mother)\n    FROM\n    (\n      SELECT \n        mother.id, mother.first_name\n      FROM\n        person as mother\n      WHERE \n        mother.id = person.mother_id\n    ) mother\n  ) mother\nFROM\n  person\n\n\nSimple right 😅. Yeah, not so much. But it does provide full control over the queries and a really good performance as long as you have indices (or indexes, we don't judge) for \"pet.owner_id\" and \"person.mother_id\".\n\nFortunately we can improve and simplify this a lot using Kysely. First let's define a couple of helpers:\n\nfunction jsonArrayFrom<O>(\n  expr: Expression<O>\n): RawBuilder<Simplify<O>[]> {\n  return sql`(select coalesce(json_agg(agg), '[]') from ${expr} as agg)`\n}\n\nexport function jsonObjectFrom<O>(\n  expr: Expression<O>\n): RawBuilder<Simplify<O>> {\n  return sql`(select to_json(obj) from ${expr} as obj)`\n}\n\n\nThese helpers are included in Kysely and you can import them from the helpers module like this:\n\nimport { jsonArrayFrom, jsonObjectFrom } from 'kysely/helpers/postgres'\n\n\nMySQL and SQLite versions of the helpers are slightly different but you can use them the same way. You can import them like this:\n\nimport { jsonArrayFrom, jsonObjectFrom } from 'kysely/helpers/mysql'\n\nimport { jsonArrayFrom, jsonObjectFrom } from 'kysely/helpers/sqlite'\n\n\nWith these helpers, our example query already becomes a little more bearable to look at:\n\nconst persons = await db\n  .selectFrom('person')\n  .selectAll('person')\n  .select((eb) => [\n    // pets\n    jsonArrayFrom(\n      eb.selectFrom('pet')\n        .select(['pet.id', 'pet.name'])\n        .whereRef('pet.owner_id', '=', 'person.id')\n        .orderBy('pet.name')\n    ).as('pets'),\n\n    // mother\n    jsonObjectFrom(\n      eb.selectFrom('person as mother')\n        .select(['mother.id', 'mother.first_name'])\n        .whereRef('mother.id', '=', 'person.mother_id')\n    ).as('mother')\n  ])\n  .execute()\n\nconsole.log(persons[0].pets[0].name)\nconsole.log(persons[0].mother.first_name)\n\n\nThat's better right? If you need to do this over and over in your codebase, you can create some helpers like these:\n\nfunction withPets(eb: ExpressionBuilder<DB, 'person'>) {\n  return jsonArrayFrom(\n    eb.selectFrom('pet')\n      .select(['pet.id', 'pet.name'])\n      .whereRef('pet.owner_id', '=', 'person.id')\n      .orderBy('pet.name')\n  ).as('pets')\n}\n\nfunction withMom(eb: ExpressionBuilder<DB, 'person'>) {\n  return jsonObjectFrom(\n    eb.selectFrom('person as mother')\n      .select(['mother.id', 'mother.first_name'])\n      .whereRef('mother.id', '=', 'person.mother_id')\n  ).as('mother')\n}\n\n\nAnd now you get this:\n\nconst persons = await db\n  .selectFrom('person')\n  .selectAll('person')\n  .select((eb) => [\n    withPets(eb),\n    withMom(eb)\n  ])\n  .execute()\n\nconsole.log(persons[0].pets[0].name)\nconsole.log(persons[0].mother.first_name)\n\n\nIf you need to select relations conditionally, $if is your friend:\n\nconst persons = await db\n  .selectFrom('person')\n  .selectAll('person')\n  .$if(includePets, (qb) => qb.select(withPets))\n  .$if(includeMom, (qb) => qb.select(withMom))\n  .execute()\n\nPrevious\nRaw SQL\nNext\nWorking with schemas"
  },
  {
    "title": "Raw SQL | Kysely",
    "url": "https://kysely.dev/docs/recipes/raw-sql",
    "html": "RecipesRaw SQL\nRaw SQL\n\nYou can execute raw SQL strings and pass raw SQL snippets to pretty much any method or function using the sql template tag.\n\nPrevious\nIntrospecting relation metadata\nNext\nRelations"
  },
  {
    "title": "Introspecting relation metadata | Kysely",
    "url": "https://kysely.dev/docs/recipes/introspecting-relation-metadata",
    "html": "RecipesIntrospecting relation metadata\nIntrospecting relation metadata\n\nExtracting metadata about tables and views from your database schema in runtime is possible using the methods in the instrospection property of a Kysely instance.\n\nThe example below uses a PostgreSQL connection to print information about all tables and views found in the database schema:\n\nimport { Kysely, PostgresDialect } from 'kysely'\nimport pg from 'pg'\nconst { Pool } = pg\n\nasync function logDatabaseSchema() {\n  const db = new Kysely({\n    dialect: new PostgresDialect({\n      pool: new Pool({\n        connectionString: process.env.DATABASE_URL,\n      }),\n    }),\n  })\n\n  const tables = await db.introspection.getTables()\n  //        ^?  TableMetadata[]\n\n  console.log({ tables })\n}\n\nlogDatabaseSchema()\n\n\nFor more information check the docs for details on the interfaces DatabaseIntrospector and TableMetadata.\n\nPrevious\nExtending kysely\nNext\nRaw SQL"
  },
  {
    "title": "Expressions | Kysely",
    "url": "https://kysely.dev/docs/recipes/expressions",
    "html": "RecipesExpressions\nExpressions\n\nAn Expression<T> is the basic type-safe query building block in Kysely. Pretty much all methods accept expressions as inputs. Most internal classes like SelectQueryBuilder and RawBuilder (the return value of the sql tag) are expressions themselves.\n\nExpression<T> represents an arbitrary SQL expression, like a binary expression (e.g. a + b), or a function call (e.g. concat(arg1, ' ', arg2, ...)). It can be any combination of those, no matter how complex. T is the output type of the expression.\n\nExpression builder​\n\nExpressions are usually built using an instance of ExpressionBuilder<DB, TB>. DB is the same database type you give to Kysely when you create an instance. TB is the union of all table names that are visible in the context. For example ExpressionBuilder<DB, 'person' | 'pet'> means you can access person and pet tables and all their columns in the expression.\n\nYou can get an instance of the expression builder by using a callback:\n\nconst person = await db\n  .selectFrom('person')\n  // `eb` is an instance of ExpressionBuilder<DB, 'person'>\n  .select((eb) => [\n    // Call the `upper` function on `first_name`. There's a bunch of\n    // shortcuts to functions under the `fn` object such as\n    // `eb.fn.coalesce()` that provide a cleaner syntax.\n    eb.fn('upper', ['first_name']).as('upper_first_name'),\n\n    // Select a subquery\n    eb.selectFrom('pet')\n      .select('name')\n      .whereRef('pet.owner_id', '=', 'person.id')\n      .limit(1)\n      .as('pet_name'),\n      \n    // Select a boolean expression..\n    eb('first_name', '=', 'Jennifer').as('is_jennifer')\n  ])\n  // You can also destructure the expression builder like this\n  .where(({ and, or, eb, not, exists, selectFrom }) => or([\n    and([\n      eb('first_name', '=', firstName),\n      eb('last_name', '=', lastName)\n    ]),\n    not(exists(\n      selectFrom('pet')\n        .select('pet.id')\n        .whereRef('pet.owner_id', '=', 'person.id')\n        .where('pet.species', 'in', ['dog', 'cat'])\n    ))\n  ]))\n  .executeTakeFirstOrThrow()\n\nconsole.log(person.upper_first_name)\nconsole.log(person.pet_name)\nconsole.log(person.is_jennifer)\n\n\nThe generated SQL:\n\nselect\n  upper(\"first_name\") as \"upper_first_name\",\n\n  (\n    select \"name\"\n    from \"pet\"\n    where \"pet\".\"owner_id\" = \"person\".\"id\"\n    limit 1\n  ) as \"pet_name\",\n\n  \"first_name\" = $1 as \"is_jennifer\"\nfrom \n  \"person\"\nwhere (\n  (\n    \"first_name\" = $2\n    and \"last_name\" = $3\n  )\n  or not exists (\n    select \"pet.id\"\n    from \"pet\"\n    where \"pet\".\"owner_id\" = \"person\".\"id\"\n    and \"pet\".\"species\" in ($4, $5)\n  )\n)\n\n\nIn the above query we used the expression builder in select and where methods. You can use it the same way in other methods like having, on, orderBy, groupBy etc.\n\nAll expressions are composable. You can pass expressions as arguments of any expression. All query builder methods in Kysely accept expressions and expression builder callbacks. All expression builder methods offer auto-completions and type-safety just like methods on the query builders.\n\nYou might be wondering, \"why do I need to use a callback to get the expression builder?\". \"Why not just create an instance using a global function?\". The reason is that when you use a callback, Kysely is able to infer the context correctly. The expression builder's methods only auto-complete and accept column and table names that are available in the context. In other words, using a callback provides more type-safety!\n\nThere's also a global function expressionBuilder you can use to create expression builders:\n\nimport { expressionBuilder } from 'kysely'\n\n// `eb1` has type `ExpressionBuilder<DB, 'person'>`\nconst eb1 = expressionBuilder<DB, 'person'>()\n\n// In this one you'd have access to tables `person` and `pet` and all their columns.\nconst eb2 = expressionBuilder<DB, 'person' | 'pet'>()\n\nlet qb = query\n  .selectFrom('person')\n  .innerJoin('movie as m', 'm.director_id', 'person.id')\n\n// You can also provide a query builder instance and the context is inferred automatically.\n// Type of `eb` is `ExpressionBuilder<DB & { m: Movie }, 'person' | 'm'>`\nconst eb = expressionBuilder(qb)\n\nqb = qb.where(eb.not(eb.exists(\n  eb.selectFrom('pet')\n    .select('pet.id')\n    .whereRef('pet.name', '=', 'm.name')\n)))\n\nCreating reusable helpers​\n\nThe expression builder can be used to create reusable helper functions. Let's say we have a complex where expression we want to reuse in multiple queries:\n\nfunction hasDogNamed(name: string): Expression<boolean> {\n  const eb = expressionBuilder<DB, 'person'>()\n\n  return eb.exists(\n    eb.selectFrom('pet')\n      .select('pet.id')\n      .whereRef('pet.owner_id', '=', 'person.id')\n      .where('pet.species', '=', 'dog')\n      .where('pet.name', '=', name)\n  )\n}\n\n\nThis helper can now be used in any query, and would work just fine if \"person\" table is in context:\n\nconst doggoPersons = await db\n  .selectFrom('person')\n  .selectAll('person')\n  .where(hasDogNamed('Doggo'))\n  .execute()\n\n\nThe above helper is not very type-safe. The following code would compile, but fail at runtime:\n\nconst bigFatFailure = await db\n  .selectFrom('movie') // <-- \"person\" table is not in context!\n  .selectAll('movie')\n  .where(hasDogNamed('Doggo')) // <-- but we're refering to \"person.id\" in our helper..\n  .execute()\n\n\nWe can write a more type-safe version of the helper like this:\n\nfunction hasDogNamed(name: string) {\n  return (eb: ExpressionBuilder<DB, 'person'>) => {\n    return eb.exists(\n      eb.selectFrom('pet')\n        .select('pet.id')\n        .whereRef('pet.owner_id', '=', 'person.id')\n        .where('pet.species', '=', 'dog')\n        .where('pet.name', '=', name)\n    )\n  }\n}\n\n\nWith this helper, you get a type error when trying to use it in contexts that don't include the \"person\" table.\n\nConditional expressions​\n\nIn the following, we'll only cover where expressions. The same logic applies to having, on, orderBy, groupBy etc.\n\nThis section should not be confused with conditional selections in select clauses, which is a whole 'nother topic we discuss in this recipe.\n\nHaving a set of optional filters you want to combine using and, is the most basic and common use case of conditional where expressions. Since the where, having and other filter functions are additive, most of the time this is enough:\n\nlet query = db\n  .selectFrom('person')\n  .selectAll('person')\n\nif (firstName) {\n  // The query builder is immutable. Remember to replace the builder\n  // with the new one.\n  query = query.where('first_name', '=', firstName)\n}\n\nif (lastName) {\n  query = query.where('last_name', '=', lastName)\n}\n\nconst persons = await query.execute()\n\n\nThe same query can be built using the expression builder like this:\n\nconst persons = await db\n  .selectFrom('person')\n  .selectAll('person')\n  .where((eb) => {\n    const filters: Expression<boolean>[] = []\n\n    if (firstName) {\n      filters.push(eb('first_name', '=', firstName))\n    }\n\n    if (lastName) {\n      filters.push(eb('last_name', '=', lastName))\n    }\n    \n    return eb.and(filters)\n  })\n\n\nUsing the latter design, you can build conditional expressions of any complexity.\n\nPrevious\nDealing with the Type instantiation is excessively deep and possibly infinite error\nNext\nExtending kysely"
  },
  {
    "title": "Extending kysely | Kysely",
    "url": "https://kysely.dev/docs/recipes/extending-kysely",
    "html": "RecipesExtending kysely\nExtending kysely\n\nIn many cases Kysely doesn't provide a built-in type-safe method for a feature. It's often because adding that feature in a generic way that would work in all use cases would be really difficult or impossible. In many cases it's better to create little helper functions in your project that suit your use case. Kysely makes this really simple.\n\nThe Kysely API is designed around two interfaces Expression<T> and AliasedExpression<T, A>. Almost every method accepts values that implement these interfaces and most Kysely internals achieve their \"type magic\" by implementing them.\n\nMost of the time you can create your helpers using the sql template tag and the RawBuilder<T> and AliasedRawBuilder<T, A> class instances it returns, but it's good to first understand how the underlying interfaces they implement, Expression<T> and AliasedExpression<T, A>, work.\n\nExpression​\n\nExpression<T> is a simple interface that has a type T and a single method toOperationNode(). T tells Kysely's type system the type of the expression. toOperationNode() returns instructions on what SQL should be produced once the expression is compiled.\n\nHere's an example of a custom expression for JSON or JSONB values on postgres:\n\nimport { Expression, Kysely, OperationNode, sql } from 'kysely'\n\nclass JsonValue<T> implements Expression<T> {\n  #value: T\n\n  constructor(value: T) {\n    this.#value = value\n  }\n\n  // This is a mandatory getter. You must add it and always return `undefined`.\n  // The return type must always be `T | undefined`.\n  get expressionType(): T | undefined {\n    return undefined\n  }\n\n  toOperationNode(): OperationNode {\n    const json = JSON.stringify(this.#value)\n    // Most of the time you can use the `sql` template tag to build the returned node.\n    // The `sql` template tag takes care of passing the `json` string as a parameter, alongside the sql string, to the DB.\n    return sql`CAST(${json} AS JSONB)`.toOperationNode()\n  }\n}\n\n\nNow you can use your new JsonValue expression pretty much anywhere as a value in a type-safe way:\n\ninterface DB {\n  person: {\n    address: {\n      postalCode: string\n      street: string\n    }\n  }\n}\n\nasync function test(db: Kysely<DB>) {\n  await db\n    .insertInto('person')\n    .values({\n      address: new JsonValue({\n        postalCode: '123456',\n        street: 'Kysely avenue 42',\n      }),\n    })\n    .execute()\n\n  await db\n    .selectFrom('person')\n    .selectAll()\n    .where(\n      'address',\n      '@>',\n      new JsonValue({ postalCode: '123456', street: 'Kysely avenue 42' })\n    )\n    .execute()\n}\n\n\nMost of the time you don't need to create your own classes that implement the Expression<T> interface. You can simply wrap the sql template tag and the RawBuilder<T> class instance it returns in a function. RawBuilder<T>, like most things in Kysely, implements the Expression<T> interface.\n\nOur previous example would get simplified into this:\n\nimport { Kysely, RawBuilder, sql } from 'kysely'\n\nfunction json<T>(value: T): RawBuilder<T> {\n  return sql`CAST(${JSON.stringify(value)} AS JSONB)`\n}\n\n\nAnd you'd use it like this:\n\ninterface DB {\n  person: {\n    address: {\n      postalCode: string\n      street: string\n    }\n  }\n}\n\nasync function test(db: Kysely<DB>) {\n  await db\n    .insertInto('person')\n    .values({\n      address: json({\n        postalCode: '123456',\n        street: 'Kysely avenue 42',\n      }),\n    })\n    .execute()\n\n  await db\n    .selectFrom('person')\n    .selectAll()\n    .where(\n      'address',\n      '@>',\n      json({ postalCode: '123456', street: 'Kysely avenue 42' })\n    )\n    .execute()\n}\n\nAliasedExpression​\n\nWhile Expression<T> holds the type and compilation instructions of an SQL expression, AliasedExpression<T, A> also holds an alias (a name) for that expression. AliasedExpression<T, A> can be used in places where you need a name for the expression, like in a SELECT statement or a FROM statement. AliasedExpression<T, A> is how kysely is able to infer the name and type of result columns.\n\nLet's expand the JsonValue example from the previous section. We'll add an as method for the JsonValue class that can be used to turn an Expression<T> into an AliasedExpression<T, A>:\n\nimport {\n  Expression,\n  AliasedExpression,\n  Kysely,\n  OperationNode,\n  sql,\n  AliasNode,\n  IdentifierNode,\n} from 'kysely'\n\nclass JsonValue<T> implements Expression<T> {\n  // ... Methods from the previous example ...\n\n  as<A extends string>(alias: A): AliasedJsonValue<T, A> {\n    return new AliasedJsonValue(this, alias)\n  }\n}\n\nclass AliasedJsonValue<T, A extends string> implements AliasedExpression<T, A> {\n  #expression: Expression<T>\n  #alias: A\n\n  constructor(expression: Expression<T>, alias: A) {\n    this.#expression = expression\n    this.#alias = alias\n  }\n\n  get expression(): Expression<T> {\n    return this.#expression\n  }\n\n  get alias(): A {\n    return this.#alias\n  }\n\n  toOperationNode(): AliasNode {\n    return AliasNode.create(\n      this.#expression.toOperationNode(),\n      IdentifierNode.create(this.#alias)\n    )\n  }\n}\n\n\nAnd now you can use JsonValue in select statements too with full type safety:\n\ninterface DB {\n  person: {\n    address: {\n      postalCode: string\n      street: string\n    }\n  }\n}\n\nasync function test(db: Kysely<DB>) {\n  const result = await db\n    .selectFrom('person')\n    .select([new JsonValue({ someValue: 42 }).as('some_object'), 'address'])\n    .where(\n      'address',\n      '@>',\n      new JsonValue({ postalCode: '123456', street: 'Kysely avenue 42' })\n    )\n    .executeTakeFirstOrThrow()\n\n  console.log(result.some_object.someValue)\n  console.log(result.address.postalCode)\n}\n\n\nAgain, in most cases you don't need to implement your own AliasedExpression<T, A>. RawBuilder has a similar as method and we can use the three line long json function from our previous example:\n\nfunction json<T>(value: T): RawBuilder<T> {\n  return sql`CAST(${JSON.stringify(value)} AS JSONB)`\n}\n\ninterface DB {\n  person: {\n    address: {\n      postalCode: string\n      street: string\n    }\n  }\n}\n\nasync function test(db: Kysely<DB>) {\n  const result = await db\n    .selectFrom('person')\n    .select([json({ someValue: 42 }).as('some_object'), 'address'])\n    .where(\n      'address',\n      '@>',\n      json({ postalCode: '123456', street: 'Kysely avenue 42' })\n    )\n    .executeTakeFirstOrThrow()\n\n  console.log(result.address.postalCode)\n  console.log(result.some_object.someValue)\n}\n\nA more complex example​\n\nConsider this query:\n\ninsert into\n  t (t1, t2)\nselect\n  v.v1,\n  j.j2\nfrom\n  (values ($1, $2, $3), ($4, $5, $6)) as v(id, v1, v2)\ninner join\n  j on v.id = j.vid\n\n\nKysely doesn't have built-in support for the values keyword in this context, but you can create a type-safe helper function like this:\n\nfunction values<R extends Record<string, unknown>, A extends string>(\n  records: R[],\n  alias: A\n): AliasedRawBuilder<R, A> {\n  // Assume there's at least one record and all records\n  // have the same keys.\n  const keys = Object.keys(records[0])\n\n  // Transform the records into a list of lists such as\n  // ($1, $2, $3), ($4, $5, $6)\n  const values = sql.join(\n    records.map((r) => sql`(${sql.join(keys.map((k) => r[k]))})`)\n  )\n\n  // Create the alias `v(id, v1, v2)` that specifies the table alias\n  // AND a name for each column.\n  const wrappedAlias = sql.ref(alias)\n  const wrappedColumns = sql.join(keys.map(sql.ref))\n  const aliasSql = sql`${wrappedAlias}(${wrappedColumns})`\n\n  // Finally create a single `AliasedRawBuilder` instance of the\n  // whole thing. Note that we need to explicitly specify\n  // the alias type using `.as<A>` because we are using a\n  // raw sql snippet as the alias.\n  return sql`(values ${values})`.as<A>(aliasSql)\n}\n\n\nThere's a lot going on in this function, but it's all documented in the sql template tag's documentation.\n\nMost of the time a helper like this would return either an instance of RawBuilder or AliasedRawBuilder and you'd create an instance using the sql template tag. You'd return a RawBuilder instance when only the data type of a column/table is needed and an AliasedRawBuilder when also the name of the column/table is needed. Our example function creates kind of a temporary table, so we need to tell Kysely both the type of the table AND the name of the table.\n\nThis is how you could now create our query using the values helper:\n\n// This could come as an input from somewhere.\nconst records = [\n  {\n    id: 1,\n    v1: 'foo',\n    v2: 'bar',\n  },\n  {\n    id: 2,\n    v1: 'baz',\n    v2: 'spam',\n  },\n]\n\ndb.insertInto('t')\n  .columns(['t1', 't2'])\n  .expression(\n    // The `values` function automatically parses the column types\n    // from the records and you can refer to them through the table\n    // alias `v`. This works because Kysely is able to parse the\n    // AliasedRawBuilder<T, A> type.\n    db\n      .selectFrom(values(records, 'v'))\n      .innerJoin('j', 'v.id', 'j.vid')\n      .select(['v.v1', 'j.j2'])\n  )\n\nExtending using inheritance​\n\nYou usually don't want to do this because of the complexity of the types and TypeScript's limitations when it comes to inheritence and return types. You'll quickly run into problems. Even though Kysely uses classes, it is not designed from the OOP point of view. Classes are used because they are supported natively by TypeScript. They provide private variables and a nice discoverable API.\n\nExtending using module augmentation​\n\nDISCLAIMER: We do not support this method. Use at your own risk.\n\nYou can override and extend Kysely's builder classes via Typescript module augmentation.\n\nThe following example adds an addIdColumn method to CreateTableBuilder, that helps in adding a postgres uuid primary key column:\n\ndeclare module 'kysely/dist/cjs/schema/create-table-builder' {\n  interface CreateTableBuilder<TB extends string, C extends string = never> {\n    addIdColumn<CN extends string = 'id'>(\n      col?: CN\n    ): CreateTableBuilder<TB, C | CN>\n  }\n}\nCreateTableBuilder.prototype.addIdColumn = function (\n  this: CreateTableBuilder<any, any>,\n  col?: string\n) {\n  return this.addColumn(col || 'id', 'uuid', (col) =>\n    col.primaryKey().defaultTo(sql`gen_random_uuid()`)\n  )\n}\n\n\nNow you can use addIdColumn seemlessly to create several tables with a uniform primary key definition:\n\ndb.schema.createTable('person').addIdColumn().addColumn('name', 'varchar')\ndb.schema.createTable('pet').addColumn('species', 'varchar').addIdColumn()\n\nPrevious\nExpressions\nNext\nIntrospecting relation metadata"
  },
  {
    "title": "Dealing with the Type instantiation is excessively deep and possibly infinite error | Kysely",
    "url": "https://kysely.dev/docs/recipes/excessively-deep-types",
    "html": "RecipesDealing with the Type instantiation is excessively deep and possibly infinite error\nDealing with the Type instantiation is excessively deep and possibly infinite error\n\nKysely uses complex type magic to achieve its type safety. This complexity is sometimes too much for TypeScript and you get errors like this:\n\nerror TS2589: Type instantiation is excessively deep and possibly infinite.\n\n\nIn these case you can often use the $assertType method to help TypeScript a little bit. When you use this method to assert the output type of a query, Kysely can drop the complex output type that consists of multiple nested helper types and replace it with the simple asserted type.\n\nUsing this method doesn't reduce type safety at all. You have to pass in a type that is structurally equal to the current type.\n\nFor example having more than 12 with statements in a query can lead to the TS2589 error:\n\nconst res = await db\n  .with('w1', (qb) => qb.selectFrom('person').select('first_name as fn1'))\n  .with('w2', (qb) => qb.selectFrom('person').select('first_name as fn2'))\n  .with('w3', (qb) => qb.selectFrom('person').select('first_name as fn3'))\n  .with('w4', (qb) => qb.selectFrom('person').select('first_name as fn4'))\n  .with('w5', (qb) => qb.selectFrom('person').select('first_name as fn5'))\n  .with('w6', (qb) => qb.selectFrom('person').select('first_name as fn6'))\n  .with('w7', (qb) => qb.selectFrom('person').select('first_name as fn7'))\n  .with('w8', (qb) => qb.selectFrom('person').select('first_name as fn8'))\n  .with('w9', (qb) => qb.selectFrom('person').select('first_name as fn9'))\n  .with('w10', (qb) => qb.selectFrom('person').select('first_name as fn10'))\n  .with('w11', (qb) => qb.selectFrom('person').select('first_name as fn11'))\n  .with('w12', (qb) => qb.selectFrom('person').select('first_name as fn12'))\n  .with('w13', (qb) => qb.selectFrom('person').select('first_name as fn13'))\n  .selectFrom(['w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13'])\n  .selectAll()\n  .executeTakeFirstOrThrow()\n\n\nBut if you simplify one or more of the with statements using $assertType, you get rid of the error:\n\nconst res = await db\n  .with('w1', (qb) => qb.selectFrom('person').select('first_name as fn1'))\n  .with('w2', (qb) => qb.selectFrom('person').select('first_name as fn2'))\n  .with('w3', (qb) => qb.selectFrom('person').select('first_name as fn3'))\n  .with('w4', (qb) => qb.selectFrom('person').select('first_name as fn4'))\n  .with('w5', (qb) => qb.selectFrom('person').select('first_name as fn5'))\n  .with('w6', (qb) => qb.selectFrom('person').select('first_name as fn6'))\n  .with('w7', (qb) => qb.selectFrom('person').select('first_name as fn7'))\n  .with('w8', (qb) => qb.selectFrom('person').select('first_name as fn8'))\n  .with('w9', (qb) => qb.selectFrom('person').select('first_name as fn9'))\n  .with('w10', (qb) => qb.selectFrom('person').select('first_name as fn10'))\n  .with('w11', (qb) => qb.selectFrom('person').select('first_name as fn11'))\n  .with('w12', (qb) =>\n    qb\n      .selectFrom('person')\n      .select('first_name as fn12')\n      .$assertType<{ fn12: string }>()\n  )\n  .with('w13', (qb) =>\n    qb\n      .selectFrom('person')\n      .select('first_name as fn13')\n      .$assertType<{ fn13: string }>()\n  )\n  .selectFrom(['w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13'])\n  .selectAll()\n  .executeTakeFirstOrThrow()\n\n\nThe type you provide for $assertType must be structurally equal to the return type of the subquery. Therefore no type safety is lost.\n\nI know what you're thinking: \"can't this be done automatically?\" No, unfortunately it can't. There's no way to do this using current TypeScript features. Typescript drags along all the parts the type is built with. Even though it could simplify the type into a simple object, it doesn't. We need to explictly tell it to do that.\n\n\"But there's this Simplify helper I've seen and it does exactly what you need\". You mean this one:\n\nexport type Simplify<T> = { [K in keyof T]: T[K] } & {}\n\n\nWhile that does simplify the type when you hover over it in your IDE, it doesn't actually drop the complex type underneath. You can try this yourself with the example above.\n\nPrevious\nDeduplicate joins\nNext\nExpressions"
  },
  {
    "title": "Conditional selects | Kysely",
    "url": "https://kysely.dev/docs/recipes/conditional-selects",
    "html": "RecipesConditional selects\nConditional selects\n\nSometimes you may want to select some fields based on a runtime condition. Something like this:\n\nasync function getPerson(id: number, withLastName: boolean) {}\n\n\nIf withLastName is true the person object is returned with a last_name property, otherwise without it.\n\nYour first thought can be to simply do this:\n\nasync function getPerson(id: number, withLastName: boolean) {\n  let query = db.selectFrom('person').select('first_name').where('id', '=', id)\n\n  if (withLastName) {\n    // ❌ The type of `query` doesn't change here\n    query = query.select('last_name')\n  }\n\n  // ❌ Wrong return type { first_name: string }\n  return await query.executeTakeFirstOrThrow()\n}\n\n\nWhile that would compile, the result type would be { first_name: string } without the last_name column, which is wrong. What happens is that the type of query when created is something, let's say A. The type of the query with last_name selection is B which extends A but also contains information about the new selection. When you assign an object of type B to query inside the if statement, the type gets downcast to A.\n\nINFO\n\nYou can write code like this to add conditional where, groupBy, orderBy etc. statements that don't change the type of the query builder, but it doesn't work with select, returning, innerJoin etc. that do change the type of the query builder.\n\nIn this simple case you could implement the method like this:\n\nasync function getPerson(id: number, withLastName: boolean) {\n  const query = db\n    .selectFrom('person')\n    .select('first_name')\n    .where('id', '=', id)\n\n  if (withLastName) {\n    // ✅ The return type is { first_name: string, last_name: string }\n    return await query.select('last_name').executeTakeFirstOrThrow()\n  }\n\n  // ✅ The return type is { first_name: string }\n  return await query.executeTakeFirstOrThrow()\n}\n\n\nThis works fine when you have one single condition. As soon as you have two or more conditions the amount of code explodes if you want to keep things type-safe. You need to create a separate branch for every possible combination of selections or otherwise the types won't be correct.\n\nThis is where the $if method can help you:\n\nasync function getPerson(id: number, withLastName: boolean) {\n  // ✅ The return type is { first_name: string, last_name?: string }\n  return await db\n    .selectFrom('person')\n    .select('first_name')\n    .$if(withLastName, (qb) => qb.select('last_name'))\n    .where('id', '=', id)\n    .executeTakeFirstOrThrow()\n}\n\n\nAny selections added inside the if callback will be added as optional fields to the output type since we can't know if the selections were actually made before running the code.\n\nPrevious\nRecipes\nNext\nDeduplicate joins"
  },
  {
    "title": "Browser | Kysely",
    "url": "https://kysely.dev/docs/runtimes/browser",
    "html": "Other runtimesBrowser\nBrowser\n\nKysely also runs in the browser. Here's a minimal example:\n\nimport {\n  Kysely,\n  Generated,\n  DummyDriver,\n  SqliteAdapter,\n  SqliteIntrospector,\n  SqliteQueryCompiler,\n} from 'kysely'\n\ninterface Person {\n  id: Generated<number>\n  first_name: string\n  last_name: string | null\n}\n\ninterface Database {\n  person: Person\n}\n\nconst db = new Kysely<Database>({\n  dialect: {\n    createAdapter() {\n      return new SqliteAdapter()\n    },\n    createDriver() {\n      return new DummyDriver()\n    },\n    createIntrospector(db: Kysely<unknown>) {\n      return new SqliteIntrospector(db)\n    },\n    createQueryCompiler() {\n      return new SqliteQueryCompiler()\n    },\n  },\n})\n\nwindow.addEventListener('load', () => {\n  const sql = db.selectFrom('person').select('id').compile()\n\n  const result = document.createElement('span')\n  result.id = 'result'\n  result.innerHTML = sql.sql\n\n  document.body.appendChild(result)\n})\n\nPrevious\nRunning on Deno\nNext\nDialects"
  },
  {
    "title": "Deduplicate joins | Kysely",
    "url": "https://kysely.dev/docs/recipes/deduplicate-joins",
    "html": "RecipesDeduplicate joins\nDeduplicate joins\n\nWhen building dynamic queries, you sometimes end up in situations where the same join could be added twice. Consider this query:\n\nasync function getPerson(\n  id: number,\n  withPetName: boolean,\n  withPetSpecies: boolean\n) {\n  return await db\n    .selectFrom('person')\n    .selectAll('person')\n    .$if(withPetName, (qb) =>\n      qb\n        .innerJoin('pet', 'pet.owner_id', 'person.id')\n        .select('pet.name as pet_name')\n    )\n    .$if(withPetSpecies, (qb) =>\n      qb\n        .innerJoin('pet', 'pet.owner_id', 'person.id')\n        .select('pet.species as pet_species')\n    )\n    .where('person.id', '=', id)\n    .executeTakeFirst()\n}\n\n\nWe have two optional selections pet_name and pet_species. Both of them require the pet table to be joined, but we don't want to add an unnecessary join if both withPetName and withPetSpecies are false.\n\nBut if both withPetName and withPetSpecies are true, we end up with two identical joins which will cause an error in the database.\n\nTo prevent the error from happening, you can install the DeduplicateJoinsPlugin. You can either install it globally by providing it in the configuration:\n\nconst db = new Kysely<Database>({\n  dialect,\n  plugins: [new DeduplicateJoinsPlugin()],\n})\n\n\nor you can use it when needed:\n\nasync function getPerson(\n  id: number,\n  withPetName: boolean,\n  withPetSpecies: boolean\n) {\n  return await db\n    .withPlugin(new DeduplicateJoinsPlugin())\n    .selectFrom('person')\n    .selectAll('person')\n    .$if(withPetName, (qb) =>\n      qb\n        .innerJoin('pet', 'pet.owner_id', 'person.id')\n        .select('pet.name as pet_name')\n    )\n    .$if(withPetSpecies, (qb) =>\n      qb\n        .innerJoin('pet', 'pet.owner_id', 'person.id')\n        .select('pet.species as pet_species')\n    )\n    .where('person.id', '=', id)\n    .executeTakeFirst()\n}\n\n\nYou may wonder why this is a plugin and not the default behavior? The reason is that it's surprisingly difficult to detect if two joins are identical. It's trivial for simple joins like the ones in the example, but becomes quite complex with arbitrary joins with nested subqueries etc. There may be corner cases where the DeduplicateJoinsPlugin fails and we don't want it to affect people that don't need this deduplication (most people).\n\nSee this recipe if you are wondering why we are using the $if method.\n\nPrevious\nConditional selects\nNext\nDealing with the Type instantiation is excessively deep and possibly infinite error"
  },
  {
    "title": "Splitting build, compile and execute code | Kysely",
    "url": "https://kysely.dev/docs/recipes/splitting-build-compile-and-execute-code",
    "html": "RecipesSplitting build, compile and execute code\nSplitting build, compile and execute code\n\nKysely is primarily a type-safe sql query builder.\n\nIt also does query execution, migrations, etc. in order to align with Knex's \"batteries included\" approach.\n\n\"Cold\" Kysely instances​\n\nIn order to use Kysely purely as a query builder without database driver dependencies, you can instantiate it with the built-in DummyDriver class:\n\nimport { \n  Generated,\n  DummyDriver,\n  Kysely,\n  PostgresAdapter,\n  PostgresIntrospector,\n  PostgresQueryCompiler,\n} from 'kysely'\n\ninterface Person {\n  id: Generated<number>\n  first_name: string\n  last_name: string | null\n}\n\ninterface Database {\n  person: Person\n}\n\nconst db = new Kysely<Database>({\n  dialect: {\n    createAdapter: () => new PostgresAdapter(),\n    createDriver: () => new DummyDriver(),\n    createIntrospector: (db) => new PostgresIntrospector(db),\n    createQueryCompiler: () => new PostgresQueryCompiler(),\n  },\n})\n\n\nThis Kysely instance will compile to PostgreSQL sql dialect. You can brew \"dummy\" dialects to compile to all kinds of sql dialects (e.g. MySQL). Trying to execute queries using \"cold\" kysely instances will return empty results without communicating with a database.\n\n\"Cold\" Kysely instances are not required for the following sections. You can use \"hot\" kysely instances, with real drivers, if you want to.\n\nCompile a query​\n\nTo compile a query, simply call .compile() at the end of the query building chain:\n\nconst compiledQuery = db\n  .selectFrom('person')\n  .select('first_name')\n  .where('id', '=', id)\n  .compile()\n\nconsole.log(compiledQuery) // { sql: 'select \"first_name\" from \"person\" where \"id\" = $1', parameters: [1], query: { ... } }\n\n\nThe result of .compile() is a CompiledQuery object. It contains the query string (in sql field), parameters and the original Kysely-specific syntax tree used for compilation.\n\nThis output alone can be used with any database driver that understands the sql dialect used (PostgreSQL in this example).\n\nRaw queries can be compiled as well:\n\nimport { Selectable, sql } from 'kysely'\n\nconst compiledQuery = sql<Selectable<Person>>`select * from person where id = ${id}`.compile(db)\n\nconsole.log(compiledQuery) // { sql: 'select * from person where id = $1', parameters: [1], query: { ... } }\n\nInfer result type​\n\nKysely supports inferring a (compiled) query's result type even when detached from query building chains. This allows splitting query building, compilation and execution code without losing type-safety.\n\nimport { InferResult } from 'kysely'\n\nconst query = db\n  .selectFrom('person')\n  .select('first_name')\n  .where('id', '=', id)\n\ntype QueryReturnType = InferResult<typeof query> // { first_name: string }[]\n\nconst compiledQuery = query.compile()\n\ntype CompiledQueryReturnType = InferResult<typeof compiledQuery> // { first_name: string }[]\n\nExecute compiled queries​\n\nThe CompiledQuery object returned by .compile() can be executed via \"hot\" Kysely instances (real drivers in use):\n\nconst compiledQuery = db\n  .selectFrom('person')\n  .select('first_name')\n  .where('id', '=', id)\n  .compile()\n\nconst results = await db.executeQuery(compiledQuery)\n\n\nThe QueryResult object returned by .executeQuery() contains the query results' rows, insertId and number of affected rows (if applicable).\n\nPrevious\nWorking with schemas\nNext\nOther runtimes"
  },
  {
    "title": "Plugin system | Kysely",
    "url": "https://kysely.dev/docs/plugins",
    "html": "Plugin system\nPlugin system\n\nPlugins are classes that implement KyselyPlugin. Plugins are then added to the Kysely instance as follows:\n\nconst db = new Kysely<Database>({\n  dialect: new PostgresDialect({\n    database: 'kysely_test',\n    host: 'localhost',\n  }),\n  plugins: [new CamelCasePlugin()],\n})\n\nBuilt-in plugins​\nCamel case plugin​\n\nA plugin that converts snake_case identifiers in the database into camelCase in the JavaScript side. Learn more.\n\nDeduplicate joins plugin​\n\nPlugin that removes duplicate joins from queries. You can read more about it in the examples section or check the API docs.\n\nPrevious\nGenerating types"
  },
  {
    "title": "Generating types | Kysely",
    "url": "https://kysely.dev/docs/generating-types",
    "html": "Generating types\nGenerating types\n\nTo work with Kysely, you're required to provide a database schema type definition to the Kysely constructor.\n\nIn many cases, defining your database schema definitions manually is good enough.\n\nHowever, when building production applications, its best to stay aligned with the database schema, by automatically generating the database schema type definitions.\n\nThere are several ways to do this using 3rd party libraries:\n\nkysely-codegen - This library generates Kysely database schema type definitions by connecting to and introspecting your database. This library works with all built-in dialects.\n\nprisma-kysely - This library generates Kysely database schema type definitions from your existing Prisma schemas.\n\nkanel-kysely - This library generates Kysely database schema type definitions by connecting to and introspecting your database. This library extends Kanel which is a mature PostgreSQL-only type generator.\n\nkysely-schema-generator - This library generates Kysely database schema type definitions by connecting to and introspecting your database. Current MySQL only.\n\nPrevious\nDialects\nNext\nPlugin system"
  },
  {
    "title": "Dialects | Kysely",
    "url": "https://kysely.dev/docs/dialects",
    "html": "Dialects\nDialects\n\nA dialect is the glue between Kysely and the underlying database engine. Check the API docs to learn how to build your own.\n\nBuilt-in dialects​\nDialect\tLink\nMySQL\thttps://kysely-org.github.io/kysely-apidoc/classes/MysqlDialect.html\nPostgreSQL\thttps://kysely-org.github.io/kysely-apidoc/classes/PostgresDialect.html\nSQLite\thttps://kysely-org.github.io/kysely-apidoc/classes/SqliteDialect.html\n3rd party dialects​\nDialect\tLink\nPlanetScale Serverless Driver\thttps://github.com/depot/kysely-planetscale\nCloudflare D1\thttps://github.com/aidenwallis/kysely-d1\nAWS RDS Data API\thttps://github.com/serverless-stack/kysely-data-api\nSurrealDB\thttps://github.com/igalklebanov/kysely-surrealdb\nNeon\thttps://github.com/seveibar/kysely-neon\nXata\thttps://github.com/xataio/client-ts/tree/main/packages/plugin-client-kysely\nAWS S3 Select\thttps://github.com/igalklebanov/kysely-s3-select\nlibSQL/sqld\thttps://github.com/libsql/kysely-libsql\nSingleStore Data API\thttps://github.com/igalklebanov/kysely-singlestore\nPostgres.js\thttps://github.com/igalklebanov/kysely-postgres-js\nFetch driver\thttps://github.com/andersgee/kysely-fetch-driver\nSQLite WASM\thttps://github.com/DallasHoff/sqlocal\nDeno SQLite\thttps://gitlab.com/soapbox-pub/kysely-deno-sqlite\nTiDB Cloud Serverless Driver\thttps://github.com/tidbcloud/kysely\nCapacitor SQLite Kysely\thttps://github.com/DawidWetzler/capacitor-sqlite-kysely\nPrevious\nBrowser\nNext\nGenerating types"
  },
  {
    "title": "Playground | Kysely",
    "url": "https://kysely.dev/docs/playground",
    "html": "Playground\nPlayground\n\n@wirekang has created a playground for Kysely. You can use it to quickly test stuff out and for creating code examples for your issues, PRs and Discord messages.\n\nCodesandbox​\n\nWe also have a minimal code sandbox example.\n\nPrevious\nGetting started\nNext\nMigrations"
  },
  {
    "title": "Migrations | Kysely",
    "url": "https://kysely.dev/docs/migrations",
    "html": "Migrations\nMigrations\n\nMigration files should look like this:\n\nimport { Kysely } from 'kysely'\n\nexport async function up(db: Kysely<any>): Promise<void> {\n  // Migration code\n}\n\nexport async function down(db: Kysely<any>): Promise<void> {\n  // Migration code\n}\n\n\nThe up function is called when you update your database schema to the next version and down when you go back to previous version. The only argument for the functions is an instance of Kysely<any>. It's important to use Kysely<any> and not Kysely<YourDatabase>.\n\nMigrations should never depend on the current code of your app because they need to work even when the app changes. Migrations need to be \"frozen in time\".\n\nMigrations can use the Kysely.schema module to modify the schema. Migrations can also run normal queries to modify data.\n\nExecution order​\n\nExecution order of the migrations is the alpabetical order of their names. An excellent way to name your migrations is to prefix them with an ISO 8601 date string. A date prefix works well in large teams where multiple team members may add migrations at the same time in parallel commits without knowing about the other migrations.\n\nSingle file vs multiple file migrations​\n\nYou don't need to store your migrations as separate files if you don't want to. You can easily implement your own MigrationProvider and give it to the Migrator class when you instantiate one.\n\nPostgreSQL migration example​\nimport { Kysely, sql } from 'kysely'\n\nexport async function up(db: Kysely<any>): Promise<void> {\n  await db.schema\n    .createTable('person')\n    .addColumn('id', 'serial', (col) => col.primaryKey())\n    .addColumn('first_name', 'varchar', (col) => col.notNull())\n    .addColumn('last_name', 'varchar')\n    .addColumn('gender', 'varchar(50)', (col) => col.notNull())\n    .addColumn('created_at', 'timestamp', (col) =>\n      col.defaultTo(sql`now()`).notNull()\n    )\n    .execute()\n\n  await db.schema\n    .createTable('pet')\n    .addColumn('id', 'serial', (col) => col.primaryKey())\n    .addColumn('name', 'varchar', (col) => col.notNull().unique())\n    .addColumn('owner_id', 'integer', (col) =>\n      col.references('person.id').onDelete('cascade').notNull()\n    )\n    .addColumn('species', 'varchar', (col) => col.notNull())\n    .execute()\n\n  await db.schema\n    .createIndex('pet_owner_id_index')\n    .on('pet')\n    .column('owner_id')\n    .execute()\n}\n\nexport async function down(db: Kysely<any>): Promise<void> {\n  await db.schema.dropTable('pet').execute()\n  await db.schema.dropTable('person').execute()\n}\n\nSQLite migration example​\nimport { Kysely, sql } from 'kysely'\n\nexport async function up(db: Kysely<any>): Promise<void> {\n  await db.schema\n    .createTable('person')\n    .addColumn('id', 'integer', (col) => col.primaryKey())\n    .addColumn('first_name', 'text', (col) => col.notNull())\n    .addColumn('last_name', 'text')\n    .addColumn('gender', 'text', (col) => col.notNull())\n    .addColumn('created_at', 'text', (col) =>\n      col.defaultTo(sql`CURRENT_TIMESTAMP`).notNull()\n    )\n    .execute()\n\n  await db.schema\n    .createTable('pet')\n    .addColumn('id', 'integer', (col) => col.primaryKey())\n    .addColumn('name', 'text', (col) => col.notNull().unique())\n    .addColumn('owner_id', 'integer', (col) =>\n      col.references('person.id').onDelete('cascade').notNull()\n    )\n    .addColumn('species', 'text', (col) => col.notNull())\n    .execute()\n\n  await db.schema\n    .createIndex('pet_owner_id_index')\n    .on('pet')\n    .column('owner_id')\n    .execute()\n}\n\nexport async function down(db: Kysely<any>): Promise<void> {\n  await db.schema.dropTable('pet').execute()\n  await db.schema.dropTable('person').execute()\n}\n\nRunning migrations​\n\nYou can then use\n\nconst migrator = new Migrator(migratorConfig)\nawait migrator.migrateToLatest(pathToMigrationsFolder)\n\n\nto run all migrations that have not yet been run. See the Migrator class's documentation for more info.\n\nKysely doesn't have a CLI for running migrations and probably never will. This is because Kysely's migrations are also written in TypeScript. To run the migrations, you need to first build the TypeScript code into JavaScript. A CLI would cause confusion over which migrations are being run, the TypeScript ones or the JavaScript ones. If we added support for both, the CLI would need to depend on a TypeScript compiler, which most production environments don't (and shouldn't) have. You will probably want to add a simple migration script to your projects like this:\n\nimport * as path from 'path'\nimport { Pool } from 'pg'\nimport { promises as fs } from 'fs'\nimport {\n  Kysely,\n  Migrator,\n  PostgresDialect,\n  FileMigrationProvider,\n} from 'kysely'\n\nasync function migrateToLatest() {\n  const db = new Kysely<Database>({\n    dialect: new PostgresDialect({\n      pool: new Pool({\n        host: 'localhost',\n        database: 'kysely_test',\n      }),\n    }),\n  })\n\n  const migrator = new Migrator({\n    db,\n    provider: new FileMigrationProvider({\n      fs,\n      path,\n      // This needs to be an absolute path.\n      migrationFolder: path.join(__dirname, 'some/path/to/migrations'),\n    }),\n  })\n\n  const { error, results } = await migrator.migrateToLatest()\n\n  results?.forEach((it) => {\n    if (it.status === 'Success') {\n      console.log(`migration \"${it.migrationName}\" was executed successfully`)\n    } else if (it.status === 'Error') {\n      console.error(`failed to execute migration \"${it.migrationName}\"`)\n    }\n  })\n\n  if (error) {\n    console.error('failed to migrate')\n    console.error(error)\n    process.exit(1)\n  }\n\n  await db.destroy()\n}\n\nmigrateToLatest()\n\n\nThe migration methods use a lock on the database level and parallel calls are executed serially. This means that you can safely call migrateToLatest and other migration methods from multiple server instances simultaneously and the migrations are guaranteed to only be executed once. The locks are also automatically released if the migration process crashes or the connection to the database fails.\n\nReference documentation​\n\nMigrator\n\nPrevious\nPlayground\nNext\nExamples"
  },
  {
    "title": "Getting started | Kysely",
    "url": "https://kysely.dev/docs/getting-started",
    "html": "Getting started\nGetting started\nInstallation​\n\nKysely can be installed using any of the following package managers:\n\nnpm\npnpm\nYarn\nDeno\nBun\n\nnpm is the default package manager for Node.js, and to where Kysely is published.\nYour project is using npm if it has a package-lock.json file in its root folder.\n\nRun the following command in your terminal:\n\nterminal\nnpm install kysely\n\nTypes​\n\nFor Kysely's type-safety and autocompletion to work, it needs to know your database structure. This requires a TypeScript Database interface, that contains table names as keys and table schema interfaces as values.\n\nLet's define our first database interface:\n\nsrc/types.ts\nimport { ColumnType, Generated, Insertable, Selectable, Updateable } from 'kysely'\n\nexport interface Database {\n  person: PersonTable\n  pet: PetTable\n}\n\nexport interface PersonTable {\n  // Columns that are generated by the database should be marked\n  // using the `Generated` type. This way they are automatically\n  // made optional in inserts and updates.\n  id: Generated<number>\n\n  first_name: string\n  gender: 'man' | 'woman' | 'other'\n\n  // If the column is nullable in the database, make its type nullable.\n  // Don't use optional properties. Optionality is always determined\n  // automatically by Kysely.\n  last_name: string | null\n\n  // You can specify a different type for each operation (select, insert and\n  // update) using the `ColumnType<SelectType, InsertType, UpdateType>`\n  // wrapper. Here we define a column `created_at` that is selected as\n  // a `Date`, can optionally be provided as a `string` in inserts and\n  // can never be updated:\n  created_at: ColumnType<Date, string | undefined, never>\n}\n\n// You should not use the table schema interfaces directly. Instead, you should\n// use the `Selectable`, `Insertable` and `Updateable` wrappers. These wrappers\n// make sure that the correct types are used in each operation.\nexport type Person = Selectable<PersonTable>\nexport type NewPerson = Insertable<PersonTable>\nexport type PersonUpdate = Updateable<PersonTable>\n\nexport interface PetTable {\n  id: Generated<number>\n  name: string\n  owner_id: number\n  species: 'dog' | 'cat'\n}\n\nexport type Pet = Selectable<PetTable>\nexport type NewPet = Insertable<PetTable>\nexport type PetUpdate = Updateable<PetTable>\n\nCODEGEN\n\nFor production apps, it is recommended to automatically generate your Database interface by introspecting your production database or Prisma schemas. Generated types might differ in naming convention, internal order, etc. Find out more at \"Generating types\".\n\nDialects​\n\nFor Kysely's query compilation and execution to work, it needs to understand your database's SQL specification and how to communicate with it. This requires a Dialect implementation.\n\nThere are 3 built-in Node.js dialects for PostgreSQL, MySQL and SQLite. Additionally, the community has implemented several dialects to choose from. Find out more at \"Dialects\".\n\nDriver installation\n\nA Dialect implementation usually requires a database driver library as a peer dependency. Let's install it using the same package manager command from before:\n\nPostgreSQL\nMySQL\nSQLite\n\nKysely's built-in PostgreSQL dialect uses the \"pg\" driver library under the hood. Please refer to its official documentation for configuration options.\n\nRun the following command in your terminal:\n\nterminal\nnpm install pg\n\n\nI use a different package manager (not npm)\n\nDRIVERLESS\nKysely can also work in compile-only mode that doesn't require a database driver. Find out more at \"Splitting build, compile and execute code\".\nInstantiation​\n\nLet's create a Kysely instance using the built-in PostgresDialect dialect:\n\nsrc/database.ts\nimport { Database } from './types.ts' // this is the Database interface we defined earlier\nimport { Pool } from 'pg'\nimport { Kysely, PostgresDialect } from 'kysely'\n\nconst dialect = new PostgresDialect({\n  pool: new Pool({\n    database: 'test',\n    host: 'localhost',\n    user: 'admin',\n    port: 5434,\n    max: 10,\n  })\n})\n\n// Database interface is passed to Kysely's constructor, and from now on, Kysely \n// knows your database structure.\n// Dialect is passed to Kysely's constructor, and from now on, Kysely knows how \n// to communicate with your database.\nexport const db = new Kysely<Database>({\n  dialect,\n})\n\n\nI use a different package manager (not npm)\n\nI use a different database (not PostgreSQL)\n\nSINGLETON\nIn most cases, you should only create a single Kysely instance per database. Most dialects use a connection pool internally, or no connections at all, so there's no need to create a new instance for each request.\nKEEPING SECRETS\nUse a secrets manager, environment variables (DO NOT commit `.env` files to your repository), or a similar solution, to avoid hardcoding database credentials in your code.\nKILL IT WITH FIRE\nWhen needed, you can dispose of the Kysely instance, release resources and close all connections by invoking the db.destroy() function.\nQuerying​\n\nLet's implement the person repository:\n\nsrc/PersonRepository.ts\nimport { db } from './database'\nimport { PersonUpdate, Person, NewPerson } from './types'\n\nexport async function findPersonById(id: number) {\n  return await db.selectFrom('person')\n    .where('id', '=', id)\n    .selectAll()\n    .executeTakeFirst()\n}\n\nexport async function findPeople(criteria: Partial<Person>) {\n  let query = db.selectFrom('person')\n\n  if (criteria.id) {\n    query = query.where('id', '=', criteria.id) // Kysely is immutable, you must re-assign!\n  }\n\n  if (criteria.first_name) {\n    query = query.where('first_name', '=', criteria.first_name)\n  }\n\n  if (criteria.last_name !== undefined) {\n    query = query.where(\n      'last_name', \n      criteria.last_name === null ? 'is' : '=', \n      criteria.last_name\n    )\n  }\n\n  if (criteria.gender) {\n    query = query.where('gender', '=', criteria.gender)\n  }\n\n  if (criteria.created_at) {\n    query = query.where('created_at', '=', criteria.created_at)\n  }\n\n  return await query.selectAll().execute()\n}\n\nexport async function updatePerson(id: number, updateWith: PersonUpdate) {\n  await db.updateTable('person').set(updateWith).where('id', '=', id).execute()\n}\n\nexport async function createPerson(person: NewPerson) {\n  return await db.insertInto('person')\n    .values(person)\n    .returningAll()\n    .executeTakeFirstOrThrow()\n}\n\nexport async function deletePerson(id: number) {\n  return await db.deleteFrom('person').where('id', '=', id)\n    .returningAll()\n    .executeTakeFirst()\n}\n\n\nI use a different database (not PostgreSQL)\n\nBUT WAIT, THERE'S MORE!\nThis is a simplified example with basic CRUD operations. Kysely supports many more SQL features including: joins, subqueries, complex boolean logic, set operations, CTEs, functions (aggregate and window functions included), raw SQL, transactions, DDL queries, etc.\nFind out more at Examples.\nSummary​\n\nWe've seen how to install and instantiate Kysely, its dialects and underlying drivers. We've also seen how to use Kysely to query a database.\n\nLet's put it all to the test:\n\nsrc/PersonRepository.spec.ts\nimport { sql } from 'kysely'\nimport { db } from './database'\nimport * as PersonRepository from './PersonRepository'\n\ndescribe('PersonRepository', () => {\n  before(async () => {\n    await db.schema.createTable('person')\n      .addColumn('id', 'serial', (cb) => cb.primaryKey())\n      .addColumn('first_name', 'varchar', (cb) => cb.notNull())\n      .addColumn('last_name', 'varchar')\n      .addColumn('gender', 'varchar(50)', (cb) => cb.notNull())\n      .addColumn('created_at', 'timestamp', (cb) =>\n        cb.notNull().defaultTo(sql`now()`)\n      )\n      .execute()\n  })\n    \n  afterEach(async () => {\n    await sql`truncate table ${sql.table('person')}`.execute(db)\n  })\n    \n  after(async () => {\n    await db.schema.dropTable('person').execute()\n  })\n    \n  it('should find a person with a given id', () => {\n    await PersonRepository.findPersonById(123)\n  })\n    \n  it('should find all people named Arnold', () => {\n    await PersonRepository.findPeople({ first_name: 'Arnold' })\n  })\n    \n  it('should update gender of a person with a given id', () => {\n    await PersonRepository.updatePerson(123, { gender: 'woman' })\n  })\n    \n  it('should create a person', () => {\n    await PersonRepository.createPerson({\n      first_name: 'Jennifer',\n      last_name: 'Aniston',\n      gender: 'woman',\n    })\n  })\n    \n  it('should delete a person with a given id', () => {\n    await PersonRepository.deletePerson(123)\n  })\n})\n\n\nI use a different database (not PostgreSQL)\n\nMIGRATIONS\nAs you can see, Kysely supports DDL queries. It also supports classic \"up/down\" migrations. Find out more at Migrations.\nPrevious\nIntroduction\nNext\nPlayground"
  },
  {
    "title": "Introduction | Kysely",
    "url": "https://kysely.dev/docs/intro",
    "html": "Introduction\nIntroduction\n\nKysely (pronounced “Key-Seh-Lee”) is a type-safe and autocompletion-friendly TypeScript SQL query builder. Inspired by Knex. Mainly developed for Node.js but also runs on Deno and in the browser.\n\nKysely makes sure you only refer to tables and columns that are visible to the part of the query you're writing. The result type only has the selected columns with correct types and aliases. As an added bonus you get autocompletion for all that stuff.\n\nAs shown above, through the magic of TypeScript, Kysely is able to parse the alias given to pet.name and add the pet_name column to the result row type. Kysely is able to infer column names, aliases and types from selected subqueries, joined subqueries, with statements and pretty much anything you can think of.\n\nOf course there are cases where things cannot be typed at compile time, and Kysely offers escape hatches for these situations. See the sql template tag and the DynamicModule for more info.\n\nAll API documentation is written in the typing files and you can simply cmd-click on the module, class or method you're using to see it. The same documentation is also hosted here.\n\nLooking for help?​\n\nIf you start using Kysely and can't find something you'd want to use, please open an issue or join our discord server.\n\nNext\nGetting started"
  }
]
