[
  {
    "title": "Drizzle ORM",
    "url": "https://orm.drizzle.team/docs/overview",
    "html": "Overview\nDrizzle ORM\n\nDrizzle is a good friend who's there for you when necessary and doesn't bother when you need some space.\n\nDrizzle ORM is a headless TypeScript ORM with a head üê≤\n\nIt looks and feels simple, performs on day 1000 of your project, lets you do things your way, and is there when you need it.\n\nIt's the only ORM with both relational and SQL-like query APIs, providing you best of both worlds when it comes to accessing your relational data. Drizzle is lightweight, performant, typesafe, non lactose, gluten-free, sober, flexible and serverless-ready by design. Drizzle is not just a library, it's an experience ü§©\n\n(opens in a new tab)\n\nHeadless ORM?\n\nFirst and foremost, Drizzle is a library and a collection of complementary opt-in tools.\n\nORM stands for object relational mapping, and developers tend to call Django-like or Spring-like tools an ORM. We trully believe it's a misconception based on legacy nomenclature and we call them data frameworks.\n\nÔ∏èüíî\n\nWith data frameworks you have to build projects around them and not with them.\n\nDrizzle lets you build your project the way you want, withour interfering with your project or structure.\n\nUsing Drizzle you can define & manage database schemas in typescript, access your data in a SQL-like or relational way, and take advantage of opt in tools to push your developer experience through the roof ü§Ø\n\nWhy SQL-like?\n\nIf you know SQL ‚Äî you know Drizzle.\n\nOther ORMs and data frameworks tend to deviate/abstract you away from SQL which leads to a double learning curve ‚Äî needing to know both SQL and the framework's API.\n\nDrizzle is the opposite. We embrace SQL and built Drizzle to be SQL-like at its core, so you can have zero to none learning curve and access to the full power of SQL.\n\nWe bring all the familiar SQL schema, queries, automatic migrations and one more thing ‚ú®\n\nindex.ts\nschema.ts\nmigration.sql\n// Access your data\nawait db\n\t.select()\n\t.from(countries)\n\t.leftJoin(cities, eq(cities.countryId, countries.id))\n\t.where(eq(countries.id, 10))\nWhy not SQL-like?\n\nWe're always striving for a perfectly balanced solution, and while SQL-like does cover 100% of the needs, there're certain common scenarios where you can query data in a better way.\n\nWe've built Queries API for you, so you can fetch relational nested data from the database in the most convenient and performant way, and never think about joins and data mapping.\n\nDrizzle always outputs exactly 1 SQL query ‚Äî feel free to use it with serverless databases and never worry about performance or roundtrip costs!\n\nconst result = await db.query.users.findMany({\n\twith: {\n\t\tposts: true\n\t},\n});\nServerless?\nü•≥\n\nBest part is no part ‚Äî Drizzle has exactly 0 dependencies!\n\nDrizzle ORM is dialect specific, slim, performant and serverless ready by design.\n\nWe've spent a lot of time to make sure you have best in class SQL dialects support ‚Äî Postgres, MySQL, or any other dialect-specific stuff.\n\nDrizzle is operating natively through industry standard database drivers. We support all major PostgreSQL, MySQL or SQLite drivers out there and we're adding new ones really fast\n(opens in a new tab)\n.\n\nWelcome on board!\n\nMore and more companies adopt Drizzle into production, experiencing immense benefits in both DX and performance.\n\nWe're always there to help, so don't hesitate to reach out ‚Äî we'll gladly assist you in your Drizzle journey!\n\nWe have an outstanding Discord community\n(opens in a new tab)\n and welcome all builders to our Twitter\n(opens in a new tab)\n.\n\nNow go build something awesome with Drizzle and your PostgreSQL, MySQL or SQLite üöÄ\n\nVideo Showcase\nTheo\nMarius Espejo\nPostgreSQL"
  },
  {
    "title": "SQL Select",
    "url": "https://orm.drizzle.team/docs/select",
    "html": "Select\nSQL Select\n\nDrizzle provides you the most SQL-like way to fetch data from your database, while remaining type-safe and composable. It natively supports mostly every query feature and capability of every dialect, and whatever it doesn't support yet, can be added by the user with the powerful sql operator.\n\nFor the following examples, let's assume you have a users table defined like this:\n\nPostgreSQL\nMySQL\nSQLite\nimport { pgTable, serial, text } from 'drizzle-orm/pg-core';\n \nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  age: integer('age'),\n});\nBasic and partial select\nSelect with all columns\n\nSelect all rows from a table including all columns:\n\nconst result = await db.select().from(users);\n/*\n  {\n    id: number;\n    name: string;\n    age: number | null;\n  }[]\n*/\nselect \"id\", \"name\", \"age\" from \"users\";\n\nNotice that the result type is inferred automatically based on the table definition, including columns nullability.\n\nDrizzle always explicitly lists columns in the select clause instead of using select *.\nThis is required internally to guarantee the fields order in the query result, and is also generally considered a good practice.\n\nPartial select\n\nIn some cases, you might want to select only a subset of columns from a table. You can do that by providing a selection object to the .select() method:\n\nconst result = await db.select({\n  field1: users.id,\n  field2: users.name,\n}).from(users);\n \nconst { field1, field2 } = result[0];\nselect \"id\", \"name\" from \"users\";\n\nLike in SQL, you can use arbitrary expressions as selection fields, not just table columns:\n\nconst result = await db.select({\n  id: users.id,\n  lowerName: sql<string>`lower(${users.name})`,\n}).from(users);\nselect \"id\", lower(\"name\") from \"users\";\n‚ö†Ô∏è\n\nBy specifying sql<string>, you are telling Drizzle that the expected type of the field is string.\nIf you specify it incorrectly (e.g. use sql<number> for a field that will be returned as a string), the runtime value won't match the expected type. Drizzle cannot perform any type casts based on the provided type generic, because that information is not available at runtime.\n\nIf you need to apply runtime transformations to the returned value, you can use the .mapWith() method.\n\nIf you have an expression you use frequently, you can extract it into a function:\n\nimport type { Column } from 'drizzle-orm';\nimport { sql } from 'drizzle-orm';\n \nfunction lower(col: Column) {\n  return sql<string>`lower(${col})`;\n}\n \nconst result = await db.select({\n  id: users.id,\n  lowerName: lower(users.name),\n}).from(users);\nConditional select\n\nYou can have a dynamic selection object based on some condition:\n\nasync function selectUsers(withName: boolean) {\n  return db\n    .select({\n      id: users.id,\n      ...(withName ? { name: users.name } : {}),\n    })\n    .from(users);\n}\n \nconst users = await selectUsers(true);\nFiltering\n\nYou can filter the query results using the filter operators in the .where() method:\n\nimport { eq, lt, gte, ne } from 'drizzle-orm';\n \nawait db.select().from(users).where(eq(users.id, 42));\nawait db.select().from(users).where(lt(users.id, 42));\nawait db.select().from(users).where(gte(users.id, 42));\nawait db.select().from(users).where(ne(users.id, 42));\n...\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" < 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" >= 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" <> 42;\n\nAll filter operators are implemented using the sql function. You can use it yourself to write arbitrary SQL filters, or build your own operators. For inspiration, you can check how the operators provided by Drizzle are implemented\n(opens in a new tab)\n.\n\nimport { sql } from 'drizzle-orm';\n \nfunction equals42(col: Column) {\n  return sql`${col} = 42`;\n}\n \nawait db.select().from(users).where(sql`${users.id} < 42`);\nawait db.select().from(users).where(sql`${users.id} = 42`);\nawait db.select().from(users).where(equals42(users.id));\nawait db.select().from(users).where(sql`${users.id} >= 42`);\nawait db.select().from(users).where(sql`${users.id} <> 42`);\nawait db.select().from(users).where(sql`lower(${users.name}) = 'aaron'`);\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' < 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' >= 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' <> 42;\nselect \"id\", \"name\", \"age\" from \"users\" where lower(\"name\") = 'aaron';\n\nAll the values provided to filter operators and to the sql function are parameterized automatically. For example, this query:\n\nawait db.select().from(users).where(eq(users.id, 42));\n\nwill be translated to:\n\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = $1; -- params: [42]\n\nInverting condition with a not operator:\n\nimport { eq, not, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(not(eq(users.id, 42)));\nawait db.select().from(users).where(sql`not ${users.id} = 42`);\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\n\nYou can safely alter schema, rename tables and columns and it will be automatically reflected in your queries because of template interpolation, as opposed to hardcoding column or table names when writing raw SQL.\n\nCombining filters\n\nYou can logically combine filter operators with and() and or() operators:\n\nimport { eq, and, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(\n  and(\n    eq(users.id, 42),\n    eq(users.name, 'Dan')\n  )\n);\nawait db.select().from(users).where(sql`${users.id} = 42 and ${users.name} = 'Dan'`);\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = 'Dan';\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = 'Dan';\nimport { eq, or, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(\n  or(\n    eq(users.id, 42), \n    eq(users.name, 'Dan')\n  )\n);\nawait db.select().from(users).where(sql`${users.id} = 42 or ${users.name} = 'Dan'`);\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = 'Dan';\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = 'Dan';\nDistinct\n\nYou can use .selectDistinct() instead of .select() to retrieve only unique rows from a dataset:\n\nawait db.selectDistinct().from(users).orderBy(usersTable.id, usersTable.name);\n \nawait db.selectDistinct({ id: users.id }).from(users).orderBy(usersTable.id);\nselect distinct \"id\", \"name\" from \"users\" order by \"id\", \"name\";\n \nselect distinct \"id\" from \"users\" order by \"id\";\n\nIn PostgreSQL, you can also use the distinct on clause to specify how the unique rows are determined:\n\nawait db.selectDistinctOn([users.id]).from(users).orderBy(users.id);\nawait db.selectDistinctOn([users.name], { name: users.name }).from(users).orderBy(users.name);\nselect distinct on (\"id\") \"id\", \"name\" from \"users\" order by \"id\";\nselect distinct on (\"name\") \"name\" from \"users\" order by \"name\";\nüí°\n\ndistinct on clause is only supported in PostgreSQL.\n\nLimit & offset\n\nUse .limit() and .offset() to add limit and offset clauses to the query - for example, to implement pagination:\n\nawait db.select().from(users).limit(10);\nawait db.select().from(users).limit(10).offset(10);\nselect \"id\", \"name\", \"age\" from \"users\" limit 10;\nselect \"id\", \"name\", \"age\" from \"users\" limit 10 offset 10;\nOrder By\n\nUse .orderBy() to add order by clause to the query, sorting the results by the specified fields:\n\nimport { asc, desc } from 'drizzle-orm';\n \nawait db.select().from(users).orderBy(users.name);\nawait db.select().from(users).orderBy(desc(users.name));\n \n// order by multiple fields\nawait db.select().from(users).orderBy(users.name, users.name2);\nawait db.select().from(users).orderBy(asc(users.name), desc(users.name2));\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\";\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" desc;\n \nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\", \"name2\";\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" asc, \"name2\" desc;\nWITH clause\n\nUsing the with clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\n\nconst sq = db.$with('sq').as(db.select().from(users).where(eq(users.id, 42)));\n \nconst result = await db.with(sq).select().from(sq);\nwith sq as (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42)\nselect \"id\", \"name\", \"age\" from sq;\n\nTo select arbitrary SQL values as fields in a CTE and reference them in other CTEs or in the main query, you need to add aliases to them:\n\n \nconst sq = db.$with('sq').as(db.select({ \n  name: sql<string>`upper(${users.name})`.as('name'),\n})\n.from(users));\n \nconst result = await db.with(sq).select({ name: sq.name }).from(sq);\n\nIf you don't provide an alias, the field type will become DrizzleTypeError and you won't be able to reference it in other queries. If you ignore the type error and still try to use the field, you will get a runtime error, since there's no way to reference that field without an alias.\n\nSelect from subquery\n\nJust like in SQL, you can embed queries into other queries by using the subquery API:\n\nconst sq = db.select().from(users).where(eq(users.id, 42)).as('sq');\nconst result = await db.select().from(sq);\nselect \"id\", \"name\", \"age\" from (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\";\n\nSubqueries can be used in any place where a table can be used, for example in joins:\n\nconst sq = db.select().from(users).where(eq(users.id, 42)).as('sq');\nconst result = await db.select().from(users).leftJoin(sq, eq(users.id, sq.id));\nselect \"users\".\"id\", \"users\".\"name\", \"users\".\"age\", \"sq\".\"id\", \"sq\".\"name\", \"sq\".\"age\" from \"users\"\n  left join (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\"\n    on \"users\".\"id\" = \"sq\".\"id\";\nAggregations\n\nWith Drizzle, you can do aggregations using functions like sum, count, avg, etc. by grouping and filtering with .groupBy() and .having() respectfully, same as you would do in raw SQL:\n\nimport { gt } from 'drizzle-orm';\n \nawait db.select({\n  age: users.age,\n  count: sql<number>`cast(count(${users.id}) as int)`,\n})\n  .from(users)\n  .groupBy(users.age);\n \nawait db.select({\n  age: users.age,\n  count: sql<number>`cast(count(${users.id}) as int)`,\n})\n  .from(users)\n  .groupBy(users.age)\n  .having(({ count }) => gt(count, 1));\nselect \"age\", cast(count(\"id\") as int)\n  from \"users\"\n  group by \"age\";\n \nselect \"age\", cast(count(\"id\") as int)\n  from \"users\"\n  group by \"age\"\n  having cast(count(\"id\") as int) > 1;\n\ncast(... as int) is necessary because count() returns bigint in PostgreSQL and decimal in MySQL, which are treated as string values instead of numbers. Alternatively, you can use .mapWith(Number) to cast the value to a number at runtime.\n\nA more advanced example:\n\nconst orders = sqliteTable('order', {\n  id: integer('id').primaryKey(),\n  orderDate: integer('order_date', { mode: 'timestamp' }).notNull(),\n  requiredDate: integer('required_date', { mode: 'timestamp' }).notNull(),\n  shippedDate: integer('shipped_date', { mode: 'timestamp' }),\n  shipVia: integer('ship_via').notNull(),\n  freight: numeric('freight').notNull(),\n  shipName: text('ship_name').notNull(),\n  shipCity: text('ship_city').notNull(),\n  shipRegion: text('ship_region'),\n  shipPostalCode: text('ship_postal_code'),\n  shipCountry: text('ship_country').notNull(),\n  customerId: text('customer_id').notNull(),\n  employeeId: integer('employee_id').notNull(),\n});\n \nconst details = sqliteTable('order_detail', {\n  unitPrice: numeric('unit_price').notNull(),\n  quantity: integer('quantity').notNull(),\n  discount: numeric('discount').notNull(),\n  orderId: integer('order_id').notNull(),\n  productId: integer('product_id').notNull(),\n});\n \n \ndb\n  .select({\n    id: orders.id,\n    shippedDate: orders.shippedDate,\n    shipName: orders.shipName,\n    shipCity: orders.shipCity,\n    shipCountry: orders.shipCountry,\n    productsCount: sql<number>`cast(count(${details.productId}) as int)`,\n    quantitySum: sql<number>`sum(${details.quantity})`,\n    totalPrice: sql<number>`sum(${details.quantity} * ${details.unitPrice})`,\n  })\n  .from(orders)\n  .leftJoin(details, eq(orders.id, details.orderId))\n  .groupBy(orders.id)\n  .orderBy(asc(orders.id))\n  .all();\nQuery\nInsert"
  },
  {
    "title": "Query performance",
    "url": "https://orm.drizzle.team/docs/perf-queries",
    "html": "Queries\nQuery performance\n\nWhen it comes to Drizzle ‚Äî we're a thin TypeScript layer on top of SQL with almost 0 overhead and to make it actual 0, you can utilise our prepared statements API.\n\nWhen you run query to the database there're several things that happens:\n\nall the configurations of the query builder got concatenated to the SQL string\nthat string and params are sent to the database driver\ndriver compiles SQL query to the binary SQL executable format and sends it to the database\n\nWith prepared statements you do SQL concatenation once on the Drizzle ORM side and then database driver is able to reuse precompiled binary SQL instead of parsing query all the time. It has extreme performance benefits on large SQL queries.\n\nDifferent database drivers support prepared statements in different ways and sometimes Drizzle ORM you can go faster than better-sqlite3 driver.\n(opens in a new tab)\n\nPrepared statement\nPostgreSQL\nMySQL\nSQLite\nconst db = drizzle(...);\n \nconst prepared = db.select().from(customers).prepare(\"statement_name\");\n \nconst res1 = await prepared.execute();\nconst res2 = await prepared.execute();\nconst res3 = await prepared.execute();\nPlaceholder\n\nWhenever you need to embed a dynamic runtime value - you can use the sql.placeholder(...) api\n\nPostgreSQL\nMySQL\nSQLite\nimport { sql } from \"drizzle-orm\";\n \nconst p1 = db\n  .select()\n  .from(customers)\n  .where(eq(customers.id, sql.placeholder('id')))\n  .prepare(\"p1\")\n \nawait p1.execute({ id: 10 }) // SELECT * FROM customers WHERE id = 10\nawait p1.execute({ id: 12 }) // SELECT * FROM customers WHERE id = 12\n \nconst p2 = db\n  .select()\n  .from(customers)\n  .where(sql`lower(${customers.name}) like ${sql.placeholder('name')}`)\n  .prepare(\"p2\");\n \nawait p2.execute({ name: '%an%' }) // SELECT * FROM customers WHERE name ilike '%an%'\nMagic sql`` operator\nServerless"
  },
  {
    "title": "AWS Data API",
    "url": "https://orm.drizzle.team/docs/quick-postgresql//aws-data-api",
    "html": "PostgreSQL\nAWS Data API\nAWS Data API\n\nDrizzle ORM natively supports aws-sdk driver with drizzle-orm/aws-data-api package.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @aws-sdk/client-rds-data @aws-sdk/credential-providers\nnpm i -D drizzle-kit\nindex.ts\nimport { drizzle } from 'drizzle-orm/aws-data-api/pg';\nimport { RDSDataClient } from '@aws-sdk/client-rds-data';\nimport { fromIni } from '@aws-sdk/credential-providers';\n \nconst rdsClient = new RDSDataClient({\n  \tcredentials: fromIni({ profile: process.env['PROFILE'] }),\n\t\tregion: 'us-east-1',\n});\n \nconst db = drizzle(rdsClient, {\n  database: process.env['DATABASE']!,\n  secretArn: process.env['SECRET_ARN']!,\n  resourceArn: process.env['RESOURCE_ARN']!,\n});\n \nawait db.select().from(...)...;\nSupabase\nHTTP proxy"
  },
  {
    "title": "Supabase",
    "url": "https://orm.drizzle.team/docs/quick-postgresql//supabase",
    "html": "PostgreSQL\nSupabase\nSupabase\n\nAccording to the official website\n(opens in a new tab)\n, Supabase is an open source Firebase alternative for building secure and performant Postgres backends with minimal configuration.\n\nCheckout official Supabase + Drizzle\n(opens in a new tab)\n docs.\n\nInstall dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm postgres\nnpm i -D drizzle-kit\nCreate your models\nschema.ts\nimport { pgTable, serial, text, varchar } from \"drizzle-orm/pg-core\";\n \nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  fullName: text('full_name'),\n  phone: varchar('phone', { length: 256 }),\n});\nMake your first query\nindex.ts\nimport { drizzle } from 'drizzle-orm/postgres-js'\nimport postgres from 'postgres'\nimport { users } from './schema'\n \nconst connectionString = process.env.DATABASE_URL\nconst client = postgres(connectionString)\nconst db = drizzle(client);\n \nconst allUsers = await db.select().from(users);\n\nConnect to your database using the Connection Pooler for serverless environments, and the Direct Connection for long-running servers.\n\nUsage with Cloudflare Workers\n\nNow that Cloudflare Workers supports TCP connections, you can use node-postgres to connect to Supabase's connection pooler.\n\nworker.ts\nimport { Pool } from \"pg\";\nimport { drizzle } from \"drizzle-orm/node-postgres\";\n \nexport default {\n  async fetch(req, env, ctx) {\n    const pool = new Pool({ connectionString: env.DATABASE_URL });\n    const db = drizzle(pool)\n    const result = await db.select().from(...);\n    ctx.waitUntil(pool.end());\n    return new Response(now);\n  }\n}\nVercel Postgres\nAWS Data API"
  },
  {
    "title": "Neon",
    "url": "https://orm.drizzle.team/docs/quick-postgresql//neon",
    "html": "PostgreSQL\nNeon\nNeon\n\nAccording to their official website\n(opens in a new tab)\n, Neon database is a multi-cloud fully managed Postgres.\n\nDrizzle ORM natively supports both Neon Serverless\n(opens in a new tab)\n driver with drizzle-orm/neon-serverless package and postgres or pg drivers to access Neon database, as per the Neon nodejs docs.\n(opens in a new tab)\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @neondatabase/serverless\nnpm i -D drizzle-kit\n\nWith Neon Serverless package [github\n(opens in a new tab)\n, blog post\n(opens in a new tab)\n] you can access Neon database from serverless environments with no TCP available ‚Äî like Cloudflare Workers ‚Äî through websockets.\n\nHTTP\nWebSockets\nindex.ts\nimport { neon, neonConfig } from '@neondatabase/serverless';\nimport { drizzle } from 'drizzle-orm/neon-http';\n \nneonConfig.fetchConnectionCache = true;\n \nconst sql = neon(process.env.DRIZZLE_DATABASE_URL!);\nconst db = drizzle(sql);\n \nconst result = await db.select().from(...);\n\nIf you're unsure how to use Neon from a serverfull environments, you should just use PostgresJS driver according to their official nodejs docs\n(opens in a new tab)\n ‚Äî see docs.\n\nnode-postgres\nVercel Postgres"
  },
  {
    "title": "Usage",
    "url": "https://orm.drizzle.team/docs/valibot",
    "html": "drizzle-valibot\ndrizzle-valibot\n\ndrizzle-valibot is a plugin for Drizzle ORM\n(opens in a new tab)\n that allows you to generate valibot\n(opens in a new tab)\n schemas from Drizzle ORM schemas.\n\nInstall the dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-valibot\nUsage\nimport { pgEnum, pgTable, serial, text, timestamp } from 'drizzle-orm/pg-core';\nimport { createInsertSchema, createSelectSchema } from 'drizzle-valibot';\nimport { string, parse, number } from 'valibot';\n \nconst users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name').notNull(),\n\temail: text('email').notNull(),\n\trole: text('role', { enum: ['admin', 'user'] }).notNull(),\n\tcreatedAt: timestamp('created_at').notNull().defaultNow(),\n});\n \n// Schema for inserting a user - can be used to validate API requests\nconst insertUserSchema = createInsertSchema(users);\n \n// Schema for selecting a user - can be used to validate API responses\nconst selectUserSchema = createSelectSchema(users);\n \n// Overriding the fields\nconst insertUserSchema = createInsertSchema(users, {\n\trole: string(),\n});\n \n// Refining the fields - useful if you want to change the fields before they become nullable/optional in the final schema\nconst insertUserSchema = createInsertSchema(users, {\n\tid: (schema) => number([minValue(0)]),\n\trole: string(),\n});\n \n// Usage\n \nconst isUserValid = parse(insertUserSchema, {\n\tname: 'John Doe',\n\temail: 'johndoe@test.com',\n\trole: 'admin',\n});\ndrizzle-typebox"
  },
  {
    "title": "Usage",
    "url": "https://orm.drizzle.team/docs/typebox",
    "html": "drizzle-typebox\ndrizzle-typebox\n\ndrizzle-typebox is a plugin for Drizzle ORM\n(opens in a new tab)\n that allows you to generate Typebox\n(opens in a new tab)\n schemas from Drizzle ORM schemas.\n\nInstall the dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-typebox\nUsage\nimport { pgEnum, pgTable, serial, text, timestamp } from 'drizzle-orm/pg-core';\nimport { createInsertSchema, createSelectSchema } from 'drizzle-typebox';\nimport { Type } from '@sinclair/typebox';\nimport { Value } from '@sinclair/typebox/value';\n \nconst users = pgTable('users', {\n    id: serial('id').primaryKey(),\n    name: text('name').notNull(),\n    email: text('email').notNull(),\n    role: text('role', { enum: ['admin', 'user'] }).notNull(),\n    createdAt: timestamp('created_at').notNull().defaultNow(),\n});\n \n// Schema for inserting a user - can be used to validate API requests\nconst insertUserSchema = createInsertSchema(users);\n \n// Schema for selecting a user - can be used to validate API responses\nconst selectUserSchema = createSelectSchema(users);\n \n// Overriding the fields\nconst insertUserSchema = createInsertSchema(users, {\n    role: Type.String(),\n});\n \n// Refining the fields - useful if you want to change the fields before they become nullable/optional in the final schema\nconst insertUserSchema = createInsertSchema(users, {\n    id: (schema) => Type.Number({ minimum: 0 }),\n    role: Type.String(),\n});\n \n// Usage\n \nconst isUserValid: boolean = Value.Check(insertUserSchema, {\n    name: 'John Doe',\n    email: 'johndoe@test.com',\n    role: 'admin',\n});\ndrizzle-zod\ndrizzle-valibot"
  },
  {
    "title": "Usage",
    "url": "https://orm.drizzle.team/docs/zod",
    "html": "drizzle-zod\ndrizzle-zod\n\ndrizzle-zod is a plugin for Drizzle ORM\n(opens in a new tab)\n that allows you to generate Zod\n(opens in a new tab)\n schemas from Drizzle ORM schemas.\n\nInstall the dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-zod\nUsage\nimport { pgEnum, pgTable, serial, text, timestamp } from 'drizzle-orm/pg-core';\nimport { createInsertSchema, createSelectSchema } from 'drizzle-zod';\nimport { z } from 'zod';\n \nconst users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  email: text('email').notNull(),\n  role: text('role', { enum: ['admin', 'user'] }).notNull(),\n  createdAt: timestamp('created_at').notNull().defaultNow(),\n});\n \n// Schema for inserting a user - can be used to validate API requests\nconst insertUserSchema = createInsertSchema(users);\n \n// Schema for selecting a user - can be used to validate API responses\nconst selectUserSchema = createSelectSchema(users);\n \n// Overriding the fields\nconst insertUserSchema = createInsertSchema(users, {\n  role: z.string(),\n});\n \n// Refining the fields - useful if you want to change the fields before they become nullable/optional in the final schema\nconst insertUserSchema = createInsertSchema(users, {\n  id: (schema) => schema.id.positive(),\n  email: (schema) => schema.email.email(),\n  role: z.string(),\n});\n \n// Usage\n \nconst user = insertUserSchema.parse({\n  name: 'John Doe',\n  email: 'johndoe@test.com',\n  role: 'admin',\n});\n \n// Zod schema type is also inferred from the table schema, so you have full type safety\nconst requestSchema = insertUserSchema.pick({ name: true, email: true });\nGoodies\ndrizzle-typebox"
  },
  {
    "title": "Goodies",
    "url": "https://orm.drizzle.team/docs/goodies",
    "html": "Goodies\nType API\n\nTo retrieve a type from your table schema for select and insert queries, you can make use of our type helpers.\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, pgTable } from 'drizzle-orm/pg-core';\nimport { type InferSelectModel, type InferInsertModel } from 'drizzle-orm'\n \nconst users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n});\n \ntype SelectUser = typeof users.$inferSelect;\ntype InsertUser = typeof users.$inferInsert;\n// or\ntype SelectUser = typeof users._.$inferSelect;\ntype InsertUser = typeof users._.$inferInsert;\n// or\ntype SelectUser = InferSelectModel<typeof users>;\ntype InsertUser = InferInsertModel<typeof users>;\nLogging\n\nTo enable default query logging, just pass { logger: true } to the drizzle initialization function:\n\nimport { drizzle } from 'drizzle-orm/...'; // driver specific\n \nconst db = drizzle(pool, { logger: true });\n\nYou can change the logs destination by creating a DefaultLogger instance and providing a custom writer to it:\n\nimport { DefaultLogger, LogWriter } from 'drizzle-orm/logger';\nimport { drizzle } from 'drizzle-orm/...'; // driver specific\n \nclass MyLogWriter implements LogWriter {\n  write(message: string) {\n    // Write to file, stdout, etc.\n  }\n}\n \nconst logger = new DefaultLogger({ writer: new MyLogWriter() });\nconst db = drizzle(pool, { logger });\n\nYou can also create a custom logger:\n\nimport { Logger } from 'drizzle-orm/logger';\nimport { drizzle } from 'drizzle-orm/...'; // driver specific\n \nclass MyLogger implements Logger {\n  logQuery(query: string, params: unknown[]): void {\n    console.log({ query, params });\n  }\n}\n \nconst db = drizzle(pool, { logger: new MyLogger() });\nMulti-project schema\n\ntable creator operator lets you define customise table names.\nIt's very useful when you need to keep schemas of different projects in one database.\n\nFor db push docs ‚Äî see here.\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, pgTableCreator } from 'drizzle-orm/pg-core';\n \nconst pgTable = pgTableCreator((name) => `project1_${name}`);\n \nconst users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n});\nPrinting SQL query\n\nYou can print SQL queries with db instance or by using standalone query builder.\n\nconst query = db\n  .select({ id: users.id, name: users.name })\n  .from(users)\n  .groupBy(users.id)\n  .toSQL();\n// query:\n{\n  sql: 'select 'id', 'name' from 'users' group by 'users'.'id'',\n  params: [],\n}\nRaw SQL queries execution\n\nIf you have some complex queries to execute and drizzle-orm can't handle them yet, you can use the db.execute method to execute raw parametrized queries.\n\nPostgreSQL\nMySQL\nSQLite\nconst statement = sql`select * from ${users} where ${users.id} = ${userId}`;\nconst res: postgres.RowList<Record<string, unknown>[]> = await db.execute(sql``)\nStandalone query builder\n\nDrizzle ORM provides a standalone query builder that allows you to build queries without creating a database instance and get generated SQL.\n\nPostgreSQL\nMySQL\nSQLite\nimport { QueryBuilder } from 'drizzle-orm/pg-core';\n \nconst qb = new QueryBuilder();\n \nconst query = qb.select().from(users).where(eq(users.name, 'Dan'));\nconst { sql, params } = query.toSQL();\nGet typed table columns\n\nYou can get a typed table columns map, very useful when you need to omit certain columns upon selection.\n\nPostgreSQL\nMySQL\nSQLite\nindex.ts\nschema.ts\nimport { getTableColumns } from \"drizzle-orm\";\nimport { user } from \"./schema\";\n \nconst { password, role, ...rest } = getTableColumns(user);\n \nawait db.select({ ...rest }).from(users);\nGet table information\nPostgreSQL\nMySQL\nSQLite\nimport { getTableConfig, pgTable } from 'drizzle-orm/pg-core';\n \nexport const table = pgTable(...);\n \nconst {\n  columns,\n  indexes,\n  foreignKeys,\n  checks,\n  primaryKeys,\n  name,\n  schema,\n} = await getTableConfig(table);\nCompare objects types (instanceof alternative)\n\nYou can check if an object is of a specific Drizzle type using the is() function. You can use it with any available type in Drizzle.\n\n‚≠êÔ∏è\n\nYou should always use is() instead of instanceof\n\nFew examples\n\nimport { Column, is } from 'drizzle-orm';\n \nif (is(value, Column)) {\n  // value's type is narrowed to Column\n}\nCustom types\ndrizzle-zod"
  },
  {
    "title": "Common way of defining custom types",
    "url": "https://orm.drizzle.team/docs/custom-types",
    "html": "Custom types\nCommon way of defining custom types\nExamples\n\nThe best way to see how customType definition is working is to check how existing data types in postgres and mysql could be defined using customType function from Drizzle ORM.\n\nPostgres Data Types\nMySql Data Types\n\nSerial\n\nimport { customType } from 'drizzle-orm/pg-core';\n \nconst customSerial = customType<{ data: number; notNull: true; default: true }>(\n  {\n    dataType() {\n      return 'serial';\n    },\n  },\n);\n\nText\n\nimport { customType } from 'drizzle-orm/pg-core';\n \nconst customText = customType<{ data: string }>({\n  dataType() {\n    return 'text';\n  },\n});\n\nBoolean\n\nimport { customType } from 'drizzle-orm/pg-core';\n \nconst customBoolean = customType<{ data: boolean }>({\n  dataType() {\n    return 'boolean';\n  },\n});\n\nJsonb\n\nimport { customType } from 'drizzle-orm/pg-core';\n \nconst customJsonb = <TData>(name: string) =>\n  customType<{ data: TData; driverData: string }>({\n    dataType() {\n      return 'jsonb';\n    },\n    toDriver(value: TData): string {\n      return JSON.stringify(value);\n    },\n  })(name);\n\nTimestamp\n\nimport { customType } from 'drizzle-orm/pg-core';\n \nconst customTimestamp = customType<\n  {\n    data: Date;\n    driverData: string;\n    config: { withTimezone: boolean; precision?: number };\n  }\n>({\n  dataType(config) {\n    const precision = typeof config.precision !== 'undefined'\n      ? ` (${config.precision})`\n      : '';\n    return `timestamp${precision}${\n      config.withTimezone ? ' with time zone' : ''\n    }`;\n  },\n  fromDriver(value: string): Date {\n    return new Date(value);\n  },\n});\n\nUsage for all types will be same as defined functions in Drizzle ORM. For example:\n\nconst usersTable = pgTable('users', {\n  id: customSerial('id').primaryKey(),\n  name: customText('name').notNull(),\n  verified: customBoolean('verified').notNull().default(false),\n  jsonb: customJsonb<string[]>('jsonb'),\n  createdAt: customTimestamp('created_at', { withTimezone: true }).notNull()\n    .default(sql`now()`),\n});\nTS-doc for type definitions\n\nYou can check ts-doc for types and param definition.\n\nexport type CustomTypeValues = {\n  /**\n   * Required type for custom column, that will infer proper type model\n   *\n   * Examples:\n   *\n   * If you want your column to be `string` type after selecting/or on inserting - use `data: string`. Like `text`, `varchar`\n   *\n   * If you want your column to be `number` type after selecting/or on inserting - use `data: number`. Like `integer`\n   */\n  data: unknown;\n \n  /**\n   * Type helper, that represents what type database driver is accepting for specific database data type\n   */\n  driverData?: unknown;\n \n  /**\n   * What config type should be used for {@link CustomTypeParams} `dataType` generation\n   */\n  config?: Record<string, unknown>;\n \n  /**\n   * If your custom data type should be notNull by default you can use `notNull: true`\n   *\n   * @example\n   * const customSerial = customType<{ data: number, notNull: true, default: true }>({\n   *    dataType() {\n   *      return 'serial';\n   *    },\n   * });\n   */\n  notNull?: boolean;\n \n  /**\n   * If your custom data type has default you can use `default: true`\n   *\n   * @example\n   * const customSerial = customType<{ data: number, notNull: true, default: true }>({\n   *    dataType() {\n   *      return 'serial';\n   *    },\n   * });\n   */\n  default?: boolean;\n};\n \nexport interface CustomTypeParams<T extends CustomTypeValues> {\n  /**\n   * Database data type string represenation, that is used for migrations\n   * @example\n   * ```\n   * `jsonb`, `text`\n   * ```\n   *\n   * If database data type needs additional params you can use them from `config` param\n   * @example\n   * ```\n   * `varchar(256)`, `numeric(2,3)`\n   * ```\n   *\n   * To make `config` be of specific type please use config generic in {@link CustomTypeValues}\n   *\n   * @example\n   * Usage example\n   * ```\n   *   dataType() {\n   *     return 'boolean';\n   *   },\n   * ```\n   * Or\n   * ```\n   *   dataType(config) {\n   *     return typeof config.length !== 'undefined' ? `varchar(${config.length})` : `varchar`;\n   *   }\n   * ```\n   */\n  dataType: (config: T['config']) => string;\n \n  /**\n   * Optional mapping function, between user input and driver\n   * @example\n   * For example, when using jsonb we need to map JS/TS object to string before writing to database\n   * ```\n   * toDriver(value: TData): string {\n   *   return JSON.stringify(value);\n   * }\n   * ```\n   */\n  toDriver?: (value: T['data']) => T['driverData'];\n \n  /**\n   * Optional mapping function, that is responsible for data mapping from database to JS/TS code\n   * @example\n   * For example, when using timestamp we need to map string Date representation to JS Date\n   * ```\n   * fromDriver(value: string): Date {\n   *  return new Date(value);\n   * },\n   * ```\n   */\n  fromDriver?: (value: T['driverData']) => T['data'];\n}\nRead Replicas\nGoodies"
  },
  {
    "title": "Read Replicas",
    "url": "https://orm.drizzle.team/docs/read-replicas",
    "html": "Read Replicas\nRead Replicas\n\nWhen your project involves a set of read replica instances, and you require a convenient method for managing SELECT queries from read replicas, as well as performing create, delete, and update operations on the primary instance, you can leverage the withReplicas() function within Drizzle\n\nPostgreSQL\nMySQL\nSQLite\nimport { sql } from 'drizzle-orm';\nimport { drizzle } from 'drizzle-orm/node-postgres';\nimport { boolean, jsonb, pgTable, serial, text, timestamp, withReplicas } from 'drizzle-orm/pg-core';\n \nconst usersTable = pgTable('users', {\n\tid: serial('id' as string).primaryKey(),\n\tname: text('name').notNull(),\n\tverified: boolean('verified').notNull().default(false),\n\tjsonb: jsonb('jsonb').$type<string[]>(),\n\tcreatedAt: timestamp('created_at', { withTimezone: true }).notNull().defaultNow(),\n});\n \nconst primaryDb = drizzle(new Pool({\n  connectionString: \"postgres://user:password@host:port/primary_db\",\n}));\nconst read1 = drizzle(new Pool({\n  connectionString: \"postgres://user:password@host:port/read_replica_1\",\n}));\nconst read2 = drizzle(new Pool({\n  connectionString: \"postgres://user:password@host:port/read_replica_2\",\n}));\n \nconst db = withReplicas(primaryDb, [read1, read2]);\n\nYou can now use the db instance the same way you did before. Drizzle will handle the choice between read replica and the primary instance automatically\n\n// Read from either the read1 connection or the read2 connection\nawait db.select().from(usersTable)\n \n// Use the primary database for the delete operation\nawait db.delete(usersTable).where(eq(usersTable.id, 1))\n\nYou can use the $primary key to force using primary instances even for read operations\n\n// read from primary\nawait db.$primary.select().from(usersTable);\n\nWith Drizzle, you can also specify custom logic for choosing read replicas. You can make a weighted decision or any other custom selection method for random read replica choice. Here is an implementation example of custom logic for selecting read replicas, where the first replica has a 70% chance of being chosen, and the second replica has a 30% chance of being selected.\n\nKeep in mind that you can implement any type of random selection method for read replicas\n\nconst db = withReplicas(primaryDb, [read1, read2], (replicas) => {\n    const weight = [0.7, 0.3];\n    let cumulativeProbability = 0;\n    const rand = Math.random();\n \n    for (const [i, replica] of replicas.entries()) {\n      cumulativeProbability += weight[i]!;\n      if (rand < cumulativeProbability) return replica;\n    }\n    return replicas[0]!\n});\n \nawait db.select().from(usersTable)\nDynamic query building\nCustom types"
  },
  {
    "title": "Dynamic query building",
    "url": "https://orm.drizzle.team/docs/dynamic-query-building",
    "html": "Dynamic query building\nDynamic query building\n\nBy default, as all the query builders in Drizzle try to conform to SQL as much as possible, you can only invoke most of the methods once. For example, in a SELECT statement there might only be one WHERE clause, so you can only invoke .where() once:\n\nconst query = db\n\t.select()\n\t.from(users)\n\t.where(eq(users.id, 1))\n\t.where(eq(users.name, 'John')); // ‚ùå Type error - where() can only be invoked once\n\nIn the previous ORM versions, when such restrictions weren't implemented, this example in particular was a source of confusion for many users, as they expected the query builder to \"merge\" multiple .where() calls into a single condition.\n\nThis behavior is useful for conventional query building, i.e. when you create the whole query at once. However, it becomes a problem when you want to build a query dynamically, i.e. if you have a shared function that takes a query builder and enhances it. To solve this problem, Drizzle provides a special 'dynamic' mode for query builders, which removes the restriction of invoking methods only once. To enable it, you need to call .$dynamic() on a query builder.\n\nLet's see how it works by implementing a simple withPagination function that adds LIMIT and OFFSET clauses to a query based on the provided page number and an optional page size:\n\nfunction withPagination<T extends PgSelect>(\n\tqb: T,\n\tpage: number,\n\tpageSize: number = 10,\n) {\n\treturn qb.limit(pageSize).offset(page * pageSize);\n}\n \nconst query = db.select().from(users).where(eq(users.id, 1));\nwithPagination(query, 1); // ‚ùå Type error - the query builder is not in dynamic mode\n \nconst dynamicQuery = query.$dynamic();\nwithPagination(dynamicQuery, 1); // ‚úÖ OK\n\nNote that the withPagination function is generic, which allows you to modify the result type of the query builder inside it, for example by adding a join:\n\nfunction withFriends<T extends PgSelect>(qb: T) {\n\treturn qb.leftJoin(friends, eq(friends.userId, users.id));\n}\n \nlet query = db.select().from(users).where(eq(users.id, 1)).$dynamic();\nquery = withFriends(query);\n\nThis is possible, because PgSelect and other similar types are specifically designed to be used in dynamic query building. They can only be used in dynamic mode.\n\nHere is the list of all types that can be used as generic parameters in dynamic query building:\n\nDialect\tType\nQuery\tSelect\tInsert\tUpdate\tDelete\nPostgres\tPgSelect\tPgInsert\tPgUpdate\tPgDelete\nPgSelectQueryBuilder\nMySQL\tMySqlSelect\tMySqlInsert\tMySqlUpdate\tMySqlDelete\nMySqlSelectQueryBuilder\nSQLite\tSQLiteSelect\tSQLiteInsert\tSQLiteUpdate\tSQLiteDelete\nSQLiteSelectQueryBuilder\n\nThe ...QueryBuilder types are for usage with standalone query builder instances. DB query builders are subclasses of them, so you can use them as well.\n\n\timport { QueryBuilder } from 'drizzle-orm/pg-core';\n \n\tfunction withFriends<T extends PgSelectQueryBuilder>(qb: T) {\n\t\treturn qb.leftJoin(friends, eq(friends.userId, users.id));\n\t}\n \n\tconst qb = new QueryBuilder();\n\tlet query = qb.select().from(users).where(eq(users.id, 1)).$dynamic();\n\tquery = withFriends(query);\nBatch\nRead Replicas"
  },
  {
    "title": "Batch API",
    "url": "https://orm.drizzle.team/docs/batch-api",
    "html": "Batch\nBatch API\n\nLibSQL Batch API explanation: source\n(opens in a new tab)\n\nWith the libSQL client library, a batch is one or more SQL statements executed in order in an implicit transaction. The transaction is controlled by the libSQL backend. If all of the statements are successful, the transaction is committed. If any of the statements fail, the entire transaction is rolled back and no changes are made.\n\nD1 Batch API explanation: source\n(opens in a new tab)\n\nBatching sends multiple SQL statements inside a single call to the database. This can have a huge performance impact as it reduces latency from network round trips to D1. D1 operates in auto-commit. Our implementation guarantees that each statement in the list will execute and commit, sequentially, non-concurrently. Batched statements are SQL transactions. If a statement in the sequence fails, then an error is returned for that specific statement, and it aborts or rolls back the entire sequence.\n\nDrizzle ORM provides APIs to run SQL statements in batch for LibSQL and D1 (WIP):\n\nconst batchResponse: BatchResponse = await db.batch([\n\tdb.insert(usersTable).values({ id: 1, name: 'John' }).returning({ id: usersTable.id }),\n\tdb.update(usersTable).set({ name: 'Dan' }).where(eq(usersTable.id, 1)),\n\tdb.query.usersTable.findMany({}),\n\tdb.select().from(usersTable).where(eq(usersTable.id, 1)),\n\tdb.select({ id: usersTable.id, invitedBy: usersTable.invitedBy }).from(usersTable),\n]);\n\nType for batchResponse in this example would be:\n\nlibSQL\nD1\ntype BatchResponse = [\n\t{\n\t\tid: number;\n\t}[],\n\tResultSet,\n\t{\n\t\tid: number;\n\t\tname: string;\n\t\tverified: number;\n\t\tinvitedBy: number | null;\n\t}[],\n\t{\n\t\tid: number;\n\t\tname: string;\n\t\tverified: number;\n\t\tinvitedBy: number | null;\n\t}[],\n\t{\n\t\tid: number;\n\t\tinvitedBy: number | null;\n\t}[],\n]\n\nAll possible builders that can be used inside db.batch:\n\ndb.all(),\ndb.get(),\ndb.values(),\ndb.run(),\ndb.query.<table>.findMany(),\ndb.query.<table>.findFirst(),\ndb.select()...,\ndb.update()...,\ndb.delete()...,\ndb.insert()...,\nTransactions\nDynamic query building"
  },
  {
    "title": "Transactions",
    "url": "https://orm.drizzle.team/docs/transactions",
    "html": "Transactions\nTransactions\n\nSQL transaction is a grouping of one or more SQL statements that interact with a database. A transaction in its entirety can commit to a database as a single logical unit or rollback (become undone) as a single logical unit.\n\nDrizzle ORM provides APIs to run SQL statements in transactions:\n\nconst db = drizzle(...)\n \nawait db.transaction(async (tx) => {\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, 'Dan'));\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, 'Andrew'));\n});\n\nDrizzle ORM supports savepoints with nested transactions API:\n\nconst db = drizzle(...)\n \nawait db.transaction(async (tx) => {\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, 'Dan'));\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, 'Andrew'));\n \n  await tx.transaction(async (tx2) => {\n    await tx2.update(users).set({ name: \"Mr. Dan\" }).where(eq(users.name, \"Dan\"));\n  });\n});\n\nYou can embed business logic to the transaction and rollback whenever needed:\n\nconst db = drizzle(...)\n \nawait db.transaction(async (tx) => {\n  const [account] = await tx.select({ balance: accounts.balance }).from(accounts).where(eq(users.name, 'Dan'));\n  if (account.balance < 100) {\n    await tx.rollback()\n    return\n  }\n \n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, 'Dan'));\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, 'Andrew'));\n});\n\nYou can return values from the transaction:\n\nconst db = drizzle(...)\n \nconst newBalance: number = await db.transaction(async (tx) => {\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, 'Dan'));\n  await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, 'Andrew'));\n \n  const [account] = await tx.select({ balance: accounts.balance }).from(accounts).where(eq(users.name, 'Dan'));\n  return account.balance;\n});\n\nYou can use transactions with relational queries:\n\nconst db = drizzle(..., { schema })\n \nawait db.transaction(async (tx) => {\n  await tx.query.users.findMany({\n    with: {\n      accounts: true\n    }\n  });\n});\n\nWe provide dialect-specific transaction configuration APIs:\n\nPostgreSQL\nMySQL\nSQLite\nawait db.transaction(\n  async (tx) => {\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} - 100.00` }).where(eq(users.name, \"Dan\"));\n    await tx.update(accounts).set({ balance: sql`${accounts.balance} + 100.00` }).where(eq(users.name, \"Andrew\"));\n  }, {\n    isolationLevel: \"read committed\",\n    accessMode: \"read write\",\n    deferrable: true,\n  }\n);\n \ninterface PgTransactionConfig {\n  isolationLevel?:\n    | \"read uncommitted\"\n    | \"read committed\"\n    | \"repeatable read\"\n    | \"serializable\";\n  accessMode?: \"read only\" | \"read write\";\n  deferrable?: boolean;\n}\nSet Operations\nBatch"
  },
  {
    "title": "Set Operations",
    "url": "https://orm.drizzle.team/docs/set-operations",
    "html": "Set Operations\nSet Operations\n\nSQL set operations combine the results of multiple query blocks into a single result. The SQL standard defines the following three set operations: UNION, INTERSECT, EXCEPT, UNION ALL, INTERSECT ALL, EXCEPT ALL.\n\nUnion\n\nCombine all results from two query blocks into a single result, omitting any duplicates.\n\nGet all names from customers and users tables without duplicates.\n\nPostgreSQL\nMySQL\nSQLite\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { union } from 'drizzle-orm/pg-core'\nimport { users, customers } from './schema'\n \nconst allNamesForUserQuery = db.select({ name: users.name }).from(users);\n \nconst result = await union(\n\tallNamesForUserQuery,\n\tdb.select({ name: customers.name }).from(customers)\n).limit(10);\n(select \"name\" from \"sellers\")\nunion\n(select \"name\" from \"customers\")\nlimit $1\nUnion All\n\nCombine all results from two query blocks into a single result, with duplicates.\n\nLet's consider a scenario where you have two tables, one representing online sales and the other representing in-store sales. In this case, you want to combine the data from both tables into a single result set. Since there might be duplicate transactions, you want to keep all the records and not eliminate duplicates.\n\nPostgreSQL\nMySQL\nSQLite\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { unionAll } from 'drizzle-orm/pg-core'\nimport { onlineSales, inStoreSales } from './schema'\n \nconst onlineTransactions = db.select({ transaction: onlineSales.transactionId }).from(onlineSales);\nconst inStoreTransactions = db.select({ transaction: inStoreSales.transactionId }).from(inStoreSales);\n \nconst result = await unionAll(onlineTransactions, inStoreTransactions);\nselect \"transaction_id\" from \"online_sales\"\nunion all\nselect \"transaction_id\" from \"in_store_sales\"\nIntersect\n\nCombine only those rows which the results of two query blocks have in common, omitting any duplicates.\n\nSuppose you have two tables that store information about students' course enrollments. You want to find the courses that are common between two different departments, but you want distinct course names, and you're not interested in counting multiple enrollments of the same course by the same student.\n\nIn this scenario, you want to find courses that are common between the two departments but don't want to count the same course multiple times even if multiple students from the same department are enrolled in it.\n\nPostgreSQL\nMySQL\nSQLite\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { intersect } from 'drizzle-orm/pg-core'\nimport { depA, depB } from './schema'\n \nconst departmentACourses = db.select({ courseName: depA.courseName }).from(depA);\nconst departmentBCourses = db.select({ courseName: depB.courseName }).from(depB);\n \nconst result = await intersect(departmentACourses, departmentBCourses);\nselect \"course_name\" from \"department_a_courses\"\nintersect\nselect \"course_name\" from \"department_b_courses\"\nIntersect All\n\nCombine only those rows which the results of two query blocks have in common, with duplicates.\n\nlet's consider a scenario where you have two tables containing data about customer orders, and you want to identify products that are ordered by both regular customers and VIP customers. In this case, you want to keep track of the quantity of each product, even if it's ordered multiple times by different customers.\n\nIn this scenario, you want to find products that are ordered by both regular customers and VIP customers, but you want to retain the quantity information, even if the same product is ordered multiple times by different customers.\n\nPostgreSQL\nMySQL\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { intersectAll } from 'drizzle-orm/pg-core'\nimport { regularCustomerOrders, vipCustomerOrders } from './schema'\n \nconst regularOrders = db.select({ \n    productId: regularCustomerOrders.productId,\n    quantityOrdered: regularCustomerOrders.quantityOrdered }\n).from(regularCustomerOrders);\n \nconst vipOrders = db.select({ \n    productId: vipCustomerOrders.productId,\n    quantityOrdered: vipCustomerOrders.quantityOrdered }\n).from(vipCustomerOrders);\n \nconst result = await intersectAll(regularOrders, vipOrders);\nselect \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\nintersect all\nselect \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\nExcept\n\nFor two query blocks A and B, return all results from A which are not also present in B, omitting any duplicates.\n\nSuppose you have two tables that store information about employees' project assignments. You want to find the projects that are unique to one department and not shared with another department, excluding duplicates.\n\nIn this scenario, you want to identify the projects that are exclusive to one department and not shared with the other department. You don't want to count the same project multiple times, even if multiple employees from the same department are assigned to it.\n\nPostgreSQL\nMySQL\nSQLite\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { except } from 'drizzle-orm/pg-core'\nimport { depA, depB } from './schema'\n \nconst departmentACourses = db.select({ courseName: depA.projectsName }).from(depA);\nconst departmentBCourses = db.select({ courseName: depB.projectsName }).from(depB);\n \nconst result = await except(departmentACourses, departmentBCourses);\nselect \"projects_name\" from \"department_a_projects\"\nexcept\nselect \"projects_name\" from \"department_b_projects\"\nExcept All\n\nFor two query blocks A and B, return all results from A which are not also present in B, with duplicates.\n\nLet's consider a scenario where you have two tables containing data about customer orders, and you want to identify products that are exclusively ordered by regular customers (without VIP customers). In this case, you want to keep track of the quantity of each product, even if it's ordered multiple times by different regular customers.\n\nIn this scenario, you want to find products that are exclusively ordered by regular customers and not ordered by VIP customers. You want to retain the quantity information, even if the same product is ordered multiple times by different regular customers.\n\nPostgreSQL\nMySQL\nimport-pattern\nbuilder-pattern\nschema.ts\nimport { exceptAll } from 'drizzle-orm/pg-core'\nimport { regularCustomerOrders, vipCustomerOrders } from './schema'\n \nconst regularOrders = db.select({ \n    productId: regularCustomerOrders.productId,\n    quantityOrdered: regularCustomerOrders.quantityOrdered }\n).from(regularCustomerOrders);\n \nconst vipOrders = db.select({ \n    productId: vipCustomerOrders.productId,\n    quantityOrdered: vipCustomerOrders.quantityOrdered }\n).from(vipCustomerOrders);\n \nconst result = await exceptAll(regularOrders, vipOrders);\nselect \"product_id\", \"quantity_ordered\" from \"regular_customer_orders\"\nexcept all\nselect \"product_id\", \"quantity_ordered\" from \"vip_customer_orders\"\nBenchmarks\nTransactions"
  },
  {
    "title": "Drizzle Serverless performance",
    "url": "https://orm.drizzle.team/docs/perf-serverless",
    "html": "Serverless\nDrizzle Serverless performance\n\nYou can get immense benefits with serverless functions like AWS Lamba or Vercel Server Functions (they're AWS Lamba based), since they can live up to 15mins and reuse both database connections and prepared statements.\n\nOn the other, hand edge functions tend to clean up straight after they're invoked which leads to little to no performance benefits.\n\nTo reuse your database connection and prepared statements you just have to declare them outside of handler scope:\n\nconst databaseConnection = ...;\nconst db = drizzle(databaseConnection);\nconst prepared = db.select().from(...).prepare();\n \n// AWS handler\nexport const handler = async (event: APIGatewayProxyEvent) => {\n  return prepared.execute();\n}\nQueries\nBenchmarks"
  },
  {
    "title": "Query performance",
    "url": "https://orm.drizzle.team/docs/perf-queries",
    "html": "Queries\nQuery performance\n\nWhen it comes to Drizzle ‚Äî we're a thin TypeScript layer on top of SQL with almost 0 overhead and to make it actual 0, you can utilise our prepared statements API.\n\nWhen you run query to the database there're several things that happens:\n\nall the configurations of the query builder got concatenated to the SQL string\nthat string and params are sent to the database driver\ndriver compiles SQL query to the binary SQL executable format and sends it to the database\n\nWith prepared statements you do SQL concatenation once on the Drizzle ORM side and then database driver is able to reuse precompiled binary SQL instead of parsing query all the time. It has extreme performance benefits on large SQL queries.\n\nDifferent database drivers support prepared statements in different ways and sometimes Drizzle ORM you can go faster than better-sqlite3 driver.\n(opens in a new tab)\n\nPrepared statement\nPostgreSQL\nMySQL\nSQLite\nconst db = drizzle(...);\n \nconst prepared = db.select().from(customers).prepare(\"statement_name\");\n \nconst res1 = await prepared.execute();\nconst res2 = await prepared.execute();\nconst res3 = await prepared.execute();\nPlaceholder\n\nWhenever you need to embed a dynamic runtime value - you can use the sql.placeholder(...) api\n\nPostgreSQL\nMySQL\nSQLite\nimport { sql } from \"drizzle-orm\";\n \nconst p1 = db\n  .select()\n  .from(customers)\n  .where(eq(customers.id, sql.placeholder('id')))\n  .prepare(\"p1\")\n \nawait p1.execute({ id: 10 }) // SELECT * FROM customers WHERE id = 10\nawait p1.execute({ id: 12 }) // SELECT * FROM customers WHERE id = 12\n \nconst p2 = db\n  .select()\n  .from(customers)\n  .where(sql`lower(${customers.name}) like ${sql.placeholder('name')}`)\n  .prepare(\"p2\");\n \nawait p2.execute({ name: '%an%' }) // SELECT * FROM customers WHERE name ilike '%an%'\nMagic sql`` operator\nServerless"
  },
  {
    "title": "Magical sql operator ü™Ñ",
    "url": "https://orm.drizzle.team/docs/sql",
    "html": "Magic sql`` operator\nMagical sql operator ü™Ñ\n\nWhen working with an ORM library, there may be cases where you find it challenging to write a specific query using the provided ORM syntax. In such situations, you can resort to using raw queries, which involve constructing a query as a raw string. However, raw queries often lack the benefits of type safety and query parameterization.\n\nTo address this, many libraries have introduced the concept of an sql template. This template allows you to write more type-safe and parameterized queries, enhancing the overall safety and flexibility of your code. Drizzle, being a powerful ORM library, also supports the sql template.\n\nWith Drizzle's sql template, you can go even further in crafting queries. If you encounter difficulties in writing an entire query using the library's query builder, you can selectively use the sql template within specific sections of the Drizzle query. This flexibility enables you to employ the sql template in partial SELECT statements, WHERE clauses, ORDER BY clauses, HAVING clauses, GROUP BY clauses, and even in relational query builders.\n\nBy leveraging the capabilities of the sql template in Drizzle, you can maintain the advantages of type safety and query parameterization while achieving the desired query structure and complexity. This empowers you to create more robust and maintainable code within your application.\n\nsql`` template\n\nOne of the most common usages you may encounter in other ORMs as well is the ability to use sql queries as-is for raw queries.\n\nimport { sql } from 'drizzle-orm' \n \nconst id = 69;\nawait db.execute(sql`select * from ${usersTable} where ${usersTable.id} = ${id}`)\n\nIt will generate the current query\n\nselect * from \"users\" where \"users\".\"id\" = $1; --> [69]\n\nAny tables and columns provided to the sql parameter are automatically mapped to their corresponding SQL syntax with escaped names for tables, and the escaped table names are appended to column names.\n\nAdditionally, any dynamic parameters such as ${id} will be mapped to the $1 placeholder, and the corresponding values will be moved to an array of values that are passed separately to the database.\n\nThis approach effectively prevents any potential SQL Injection vulnerabilities.\n\nsql<T>\n‚ÑπÔ∏è\n\nPlease note that sql<T> does not perform any runtime mapping. The type you define using sql<T> is purely a helper for Drizzle. It is important to understand that there is no feasible way to determine the exact type dynamically, as SQL queries can be highly versatile and customizable.\n\nYou can define a custom type in Drizzle to be used in places where fields require a specific type other than unknown.\n\nThis feature is particularly useful in partial select queries, ensuring consistent typing for selected fields:\n\n// without sql<T> type defined\nconst response: { id: unknown }[] = await db.select({\n    lowerName: sql`lower(${usersTable.id})`\n}).from(usersTable);\n \n// with sql<T> type defined\nconst response: { id: string }[] = await db.select({\n    lowerName: sql<string>`lower(${usersTable.id})`\n}).from(usersTable);\nsql``.mapWith()\n\nFor the cases you need to make a runtime mapping for values passed from database driver to drizzle you can use .mapWith()\n\nThis function accepts different values, that will map response in runtime.\n\nYou can replicate a specific column mapping strategy as long as the interface inside mapWith is the same interface that is implemented by Column.\n\nconst usersTable = pgTable('users', {\n    id: serial('id').primaryKey(),\n    name: text('name').notNull(),\n});\n \n//  at runtime this values will be mapped same as `text` column is mapped in drizzle\nsql`...`.mapWith(usersTable.name);\n\nYou can also pass your own implementation for the DriverValueDecoder interface:\n\nsql``.mapWith({\n\tmapFromDriverValue: (value: any) => {\n\t\tconst mappedValue = value;\n\t\t// mapping you want to apply\n\t\treturn mappedValue;\n\t},\n});\n    \n// or\nsql``.mapWith(Number);\nsql``.as<T>()\n\nIn different cases, it can sometimes be challenging to determine how to name a custom field that you want to use. You may encounter situations where you need to explicitly specify an alias for a field that will be selected. This can be particularly useful when dealing with complex queries.\n\nTo address these scenarios, we have introduced a helpful .as('alias_name') helper, which allows you to define an alias explicitly. By utilizing this feature, you can provide a clear and meaningful name for the field, making your queries more intuitive and readable.\n\nsql`lower(usersTable.name)`.as('lower_name')\n... \"usersTable\".\"name\" as lower_name ...\nsql.raw()\n\nThere are cases where you may not need to create parameterized values from input or map tables/columns to escaped ones. Instead, you might simply want to generate queries as they are. For such situations, we provide the sql.raw() function.\n\nThe sql.raw() function allows you to include raw SQL statements within your queries without any additional processing or escaping. This can be useful when you have pre-constructed SQL statements or when you need to incorporate complex or dynamic SQL code directly into your queries.\n\nsql.raw(`select * from users where id = ${12}`);\n// vs\nsql`select * from users where id = ${12}`;\nselect * from users where id = 12;\n--> vs\nselect * from users where id = $1; --> [12]\n\nYou can also utilize sql.raw() within the sql function, enabling you to include any raw string without escaping it through the main sql template function.\n\nBy using sql.raw() inside the sql function, you can incorporate unescaped raw strings directly into your queries. This can be particularly useful when you have specific SQL code or expressions that should remain untouched by the template function's automatic escaping or modification.\n\nsql`select * from ${usersTable} where id = ${12}`;\n// vs\nsql`select * from ${usersTable} where id = ${sql.raw(12)}`;\nselect * from \"users\" where id = $1; --> [12]\n--> vs\nselect * from \"users\" where id = 12;\nsql.fromList()\n\nThe sql template generates sql chunks, which are arrays of SQL parts that will be concatenated into the query and params after applying the SQL to the database or query in Drizzle.\n\nIn certain scenarios, you may need to aggregate these chunks into an array using custom business logic and then concatenate them into a single SQL statement that can be passed to the database or query. For such cases, the fromList function can be quite useful.\n\nThe fromList function allows you to combine multiple SQL chunks into a single SQL statement. You can use it to aggregate and concatenate the individual SQL parts according to your specific requirements and then obtain a unified SQL query that can be executed.\n\nconst sqlChunks: SQL[] = [];\n \nsqlChunks.push(sql`select * from users`);\n \n// some logic\n \nsqlChunks.push(sql` where `);\n \n// some logic\n \nfor (let i = 0; i < 5; i++) {\n\tsqlChunks.push(sql`id = ${i}`);\n \n\tif (i === 4) continue;\n\tsqlChunks.push(sql` or `);\n}\n \nconst finalSql: SQL = sql.fromList(sqlChunks)\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\nsql.join()\n\nIndeed, the sql.join function serves a similar purpose to the fromList helper. However, it provides additional flexibility when it comes to handling spaces between SQL chunks or specifying custom separators for concatenating the SQL chunks.\n\nWith sql.join, you can concatenate SQL chunks together using a specified separator. This separator can be any string or character that you want to insert between the chunks.\n\nThis is particularly useful when you have specific requirements for formatting or delimiting the SQL chunks. By specifying a custom separator, you can achieve the desired structure and formatting in the final SQL query.\n\nconst sqlChunks: SQL[] = [];\n \nsqlChunks.push(sql`select * from users`);\n \n// some logic\n \nsqlChunks.push(sql`where`);\n \n// some logic\n \nfor (let i = 0; i < 5; i++) {\n\tsqlChunks.push(sql`id = ${i}`);\n \nif (i === 4) continue;\n    sqlChunks.push(sql`or`);\n}\n \nconst finalSql: SQL = sql.join(sqlChunks, sql.raw(' '));\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\nsql.append()\n\nIf you have already generated SQL using the sql template, you can achieve the same behavior as fromList by using the append function to directly add a new chunk to the generated SQL.\n\nBy using the append function, you can dynamically add additional SQL chunks to the existing SQL string, effectively concatenating them together. This allows you to incorporate custom logic or business rules for aggregating the chunks into the final SQL query.\n\nconst finalSql = sql`select * from users`;\n \n// some logic\n \nfinalSql.append(sql` where `);\n \n// some logic\n \nfor (let i = 0; i < 5; i++) {\n\tfinalSql.append(sql`id = ${i}`);\n \n\tif (i === 4) continue;\n\tfinalSql.append(sql` or `);\n}\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\nsql.empty()\n\nBy using sql.empty(), you can start with a blank SQL object and then dynamically append SQL chunks to it as needed. This allows you to construct the SQL query incrementally, applying custom logic or conditions to determine the contents of each chunk.\n\nOnce you have initialized the SQL object using sql.empty(), you can take advantage of the full range of sql template features such as parameterization, composition, and escaping. This empowers you to construct the SQL query in a flexible and controlled manner, adapting it to your specific requirements.\n\nconst finalSql = sql.empty();\n \n// some logic\n \nfinalSql.append(sql`select * from users`);\n \n// some logic\n \nfinalSql.append(sql` where `);\n \n// some logic\n \nfor (let i = 0; i < 5; i++) {\n\tfinalSql.append(sql`id = ${i}`);\n \n\tif (i === 4) continue;\n\tfinalSql.append(sql` or `);\n}\nselect * from users where id = $1 or id = $2 or id = $3 or id = $4 or id = $5; --> [0, 1, 2, 3, 4]\nConvert sql to string and params\n\nIn all the previous examples, you observed the usage of SQL template syntax in TypeScript along with the generated SQL output.\n\nIf you need to obtain the query string and corresponding parameters generated from the SQL template, you must specify the database dialect you intend to generate the query for. Different databases have varying syntax for parameterization and escaping, so selecting the appropriate dialect is crucial.\n\nOnce you have chosen the dialect, you can utilize the corresponding implementation's functionality to convert the SQL template into the desired query string and parameter format. This ensures compatibility with the specific database system you are working with.\n\nPostgreSQL\nMySQL\nSQLite\nimport { PgDialect } from 'drizzle-orm/pg-core';\n \nconst pgDialect = new PgDialect();\npgDialect.sqlToQuery(sql`select * from ${usersTable} where ${usersTable.id} = ${12}`);\nselect * from \"users\" where \"users\".\"id\" = $1; --> [ 12 ]\nsql select\n\nYou can use the sql functionality in partial select queries as well. Partial select queries allow you to retrieve specific fields or columns from a table rather than fetching the entire row.\n\nFor more detailed information about partial select queries, you can refer to the Core API documentation available at Core API docs.\n\nSelect different custom fields from table\n\nHere you can see a usage for sql<T>, sql``.mapWith(), sql``.as<T>().\n\nimport { sql } from 'drizzle-orm'\nimport { usersTable } from 'schema'\n \nawait db.select({\n    id: usersTable.id,\n    lowerName: sql<string>`lower(${usersTable})`,\n    aliasedName: sql<string>`lower(${usersTable})`.as('aliased_column'),\n    count: sql<number>`count(*)`.mapWith(Number) \n}).from(usersTable)\nselect `id`, lower(`name`), lower(`name`) as `aliased_column`, count(*) from `users`;\nsql in where\n\nIndeed, Drizzle provides a set of available expressions that you can use within the sql template. However, it is true that databases often have a wider range of expressions available, including those provided through extensions or other means.\n\nTo ensure flexibility and enable you to utilize any expressions that are not natively supported by Drizzle, you have the freedom to write the SQL template directly using the sql function. This allows you to leverage the full power of SQL and incorporate any expressions or functionalities specific to your target database.\n\nBy using the sql template, you are not restricted to only the predefined expressions in Drizzle. Instead, you can express complex queries and incorporate any supported expressions that the underlying database system provides.\n\nFiltering by id but with sql\n\nimport { sql } from 'drizzle-orm'\nimport { usersTable } from 'schema'\n \nconst id = 77\n \nawait db.select()\n        .from(usersTable)\n        .where(sql`${usersTable.id} = ${id}`)\nselect * from \"users\" where \"users\".\"id\" = $1; --> [ 77 ]\n\nAdvanced fulltext search where statement\n\nimport { sql } from 'drizzle-orm'\nimport { usersTable } from 'schema'\n \nconst searchParam = \"Ale\"\n \nawait db.select()\n        .from(usersTable)\n        .where(sql`to_tsvector('simple', ${usersTable.name}) @@ to_tsquery('simple', ${searchParam})`)\nselect * from \"users\" where to_tsvector('simple', \"users\".\"name\") @@ to_tsquery('simple', '$1'); --> [ \"Ale\" ]\nsql in orderBy\n\nThe sql template can indeed be used in the ORDER BY clause when you need specific functionality for ordering that is not available in Drizzle, but you prefer not to resort to raw SQL.\n\nimport { sql } from 'drizzle-orm'\nimport { usersTable } from 'schema'\n \nawait db.select().from(usersTable).orderBy(sql`${usersTable.id} desc nulls first`)\nselect * from \"users\" order by \"users\".\"id\" desc nulls first;\nsql in having and groupBy\n\nThe sql template can indeed be used in the HAVING and GROUP BY clauses when you need specific functionality for ordering that is not available in Drizzle, but you prefer not to resort to raw SQL.\n\nimport { sql } from 'drizzle-orm'\nimport { usersTable } from 'schema'\n \nawait db.select({ \n    projectId: usersTable.projectId,\n    count: sql<number>`count(${usersTable.id})`.mapWith(Number)\n}).from(usersTable)\n    .groupBy(sql`${usersTable.projectId}`)\n    .having(sql`count(${usersTable.id}) > 300`)\nselect \"project_id\", count(\"users\".\"id\") from users group by \"users\".\"project_id\" having count(\"users\".\"id\") > 300; \nJoins\nQueries"
  },
  {
    "title": "Joins [SQL]",
    "url": "https://orm.drizzle.team/docs/joins",
    "html": "Joins\nJoins [SQL]\n\nJoin clause in SQL is used to combine 2 or more tables, based on related columns between them. Drizzle ORM joins syntax is a balance between the SQL-likeness and type safety.\n\nJoin types\n\nDrizzle ORM has APIs for INNER JOIN, FULL JOIN, LEFT JOIN and RIGHT JOIN. Lets have a quick look at examples based on below table schemas:\n\nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n});\n \nexport const pets = pgTable('pets', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  ownerId: integer('owner_id').notNull().references(() => users.id),\n})\nLeft Join\nconst result = await db.select().from(users).leftJoin(pets, eq(users.id, pets.ownerId))\nselect ... from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n    user: {\n        id: number;\n        name: string;\n    };\n    pets: {\n        id: number;\n        name: string;\n        ownerId: number;\n    } | null;\n}[];\nRight Join\nconst result = await db.select().from(users).rightJoin(pets, eq(users.id, pets.ownerId))\nselect ... from \"users\" right join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n    user: {\n        id: number;\n        name: string;\n    } | null;\n    pets: {\n        id: number;\n        name: string;\n        ownerId: number;\n    };\n}[];\nInner Join\nconst result = await db.select().from(users).innerJoin(pets, eq(users.id, pets.ownerId))\nselect ... from \"users\" inner join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n    user: {\n        id: number;\n        name: string;\n    };\n    pets: {\n        id: number;\n        name: string;\n        ownerId: number;\n    };\n}[];\nFull Join\nconst result = await db.select().from(users).fullJoin(pets, eq(users.id, pets.ownerId))\nselect ... from \"users\" full join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n    user: {\n        id: number;\n        name: string;\n    } | null;\n    pets: {\n        id: number;\n        name: string;\n        ownerId: number;\n    } | null;\n}[];\nPartial select\n\nIf you need to select a particular subset of fields or to have a flat response type, Drizzle ORM supports joins with partial select and will automatically infer return type based on .select({ ... }) structure.\n\nawait db.select({\n  userId: users.id,\n  petId: pets.id,\n}).from(user).leftJoin(pets, eq(users.id, pets.ownerId))\nselect \"users\".\"id\", \"pets\",\"id\" from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n  userId: number;\n  petId: number | null;\n}[];\n\nYou might've noticed that petId can be null now, it's because we're left joining and there can be users without a pet.\n\nIt's very important to keep in mind when using sql operator for partial selection fields and aggregations when needed, you should to use sql<type | null> for proper result type inference, that one is on you!\n\nconst result = await db.select({\n  userId: users.id,\n  petId: pets.id,\n  petName1: sql`upper(${pets.name})`,\n  petName2: sql<string | null>`upper(${pets.name})`,\n  //ÀÑwe should explicitly tell 'string | null' in type, since we're left joining that field\n}).from(user).leftJoin(pets, eq(users.id, pets.ownerId))\nselect \"users\".\"id\", \"pets\".\"id\", upper(\"pets\".\"name\")... from \"users\" left join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n  userId: number;\n  petId: number | null;\n  petName1: unknown;\n  petName2: string | null;\n}[];\n\nTo avoid plethora of nullable fields when joining tables with lots of columns we can utilise our nested select object syntax, our smart type inference will make whole object nullable instead of making all table fields nullable!\n\nawait db.select({\n  userId: users.id,\n  userName: users.name,\n  pet: {\n    id: pets.id,\n    name: pets.name,\n    upperName: sql<string>`upper(${pets.name})`\n  }\n}).from(user).fullJoin(pets, eq(users.id, pets.ownerId))\nselect ... from \"users\" full join \"pets\" on \"users\".\"id\" = \"pets\".\"owner_id\"\n// result type\nconst result: {\n    userId: number | null;\n    userName: string | null;\n    pet: {\n        id: number;\n        name: string;\n        upperName: string;\n    } | null;\n}[];\nAliases & Selfjoins\n\nDrizzle ORM supports table aliases which comes really handy when you need to do selfjoins.\n\nLets say you need to fetch users with their parents:\n\nindex.ts\nschema.ts\nimport { user } from \"./schema\";\n \nconst parent = alias(user, \"parent\")\nconst result = db\n  .select()\n  .from(user)\n  .leftJoin(parent, eq(parent.id, user.id));\nselect ... from \"user\" left join \"user\" \"parent\" on \"parent\".\"id\" = \"user\".\"id\"\n// result type\nconst result: {\n    user: {\n        id: number;\n        name: string;\n        parentId: number;\n    };\n    parent: {\n        id: number;\n        name: string;\n        parentId: number;\n    } | null;\n}[];\nAggregating results\n\nDrizzle ORM delivers name-mapped results from the driver without changing the structure.\n\nYou're free to operate with results the way you want, here's an example of mapping many-one relational data:\n\ntype User = typeof usersTable.$inferSelect;\ntype Pet = typeof usersTable.$inferSelect;\n \nconst rows = db.select({\n    user: users,\n    pet: pets,\n  }).from(users).leftJoin(pets, eq(users.id, pets.ownerId)).all();\n \nconst result = rows.reduce<Record<number, { user: User; pets: Pet[] }>>(\n  (acc, row) => {\n    const user = row.user;\n    const pet = row.pet;\n \n    if (!acc[user.id]) {\n      acc[user.id] = { user, pets: [] };\n    }\n \n    if (pet) {\n      acc[user.id].pets.push(pet);\n    }\n \n    return acc;\n  },\n  {}\n);\n \n// result type\nconst result: Record<number, {\n    user: User;\n    pets: Pet[];\n}>;\nMany-to-one example\nimport { sqliteTable, text, integer } from 'drizzle-orm/sqlite-core';\nimport { drizzle } from 'drizzle-orm/better-sqlite3';\n \nconst cities = sqliteTable('cities', {\n  id: integer('id').primaryKey(),\n  name: text('name'),\n});\n \nconst users = sqliteTable('users', {\n  id: integer('id').primaryKey(),\n  name: text('name'),\n  cityId: integer('city_id').references(() => cities.id)\n});\n \nconst db = drizzle(sqlite);\n \nconst result = db.select().from(cities).leftJoin(users, eq(cities2.id, users2.cityId)).all();\nMany-to-many example\nconst users = sqliteTable('users', {\n  id: integer('id').primaryKey(),\n  name: text('name'),\n});\n \nconst chatGroups = sqliteTable('chat_groups', {\n  id: integer('id').primaryKey(),\n  name: text('name'),\n});\n \nconst usersToChatGroups = sqliteTable('usersToChatGroups', {\n  userId: integer('user_id').notNull().references(() => users.id),\n  groupId: integer('group_id').notNull().references(() => chatGroups.id),\n});\n \n \n// querying user group with id 1 and all the participants(users)\ndb.select()\n  .from(usersToChatGroups)\n  .leftJoin(users, eq(usersToChatGroups.userId, users.id))\n  .leftJoin(chatGroups, eq(usersToChatGroups.groupId, chatGroups.id))\n  .where(eq(chatGroups.id, 1))\n  .all();\nFilters\nMagic sql`` operator"
  },
  {
    "title": "Filter and conditional operators",
    "url": "https://orm.drizzle.team/docs/operators",
    "html": "Filters\nFilter and conditional operators\n\nWe natively support all dialect specific filter and conditional operators.\n\nYou can import all filter & conditional from drizzle-orm:\n\nimport { eq, ne, gt, gte, ... } from \"drizzle-orm\";\neq\nPostgreSQL\nMySQL\nSQLite\n\nValue equal to n\n\nimport { eq } from \"drizzle-orm\";\n \ndb.select().from(table).where(eq(table.column, 5));\nSELECT * FROM table WHERE table.column = 5\nimport { eq } from \"drizzle-orm\";\n \ndb.select().from(table).where(eq(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 = table.column2\nne\nPostgreSQL\nMySQL\nSQLite\n\nValue is not equal to n\n\nimport { ne } from \"drizzle-orm\";\n \ndb.select().from(table).where(ne(table.column, 5));\nSELECT * FROM table WHERE table.column <> 5\nimport { ne } from \"drizzle-orm\";\n \ndb.select().from(table).where(ne(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 <> table.column2\ngt\nPostgreSQL\nMySQL\nSQLite\n\nValue is greater than n\n\nimport { gt } from \"drizzle-orm\";\n \ndb.select().from(table).where(gt(table.column, 5));\nSELECT * FROM table WHERE table.column > 5\nimport { gt } from \"drizzle-orm\";\n \ndb.select().from(table).where(gt(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 > table.column2\ngte\nPostgreSQL\nMySQL\nSQLite\n\nValue is greater than or equal to n\n\nimport { gte } from \"drizzle-orm\";\n \ndb.select().from(table).where(gte(table.column, 5));\nSELECT * FROM table WHERE table.column >= 5\nimport { gte } from \"drizzle-orm\";\n \ndb.select().from(table).where(gte(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 >= table.column2\nlt\nPostgreSQL\nMySQL\nSQLite\n\nValue is less than n\n\nimport { lt } from \"drizzle-orm\";\n \ndb.select().from(table).where(lt(table.column, 5));\nSELECT * FROM table WHERE table.column < 5\nimport { lt } from \"drizzle-orm\";\n \ndb.select().from(table).where(lt(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 < table.column2\nlte\nPostgreSQL\nMySQL\nSQLite\n\nValue is less than or equal to n.\n\nimport { lte } from \"drizzle-orm\";\n \ndb.select().from(table).where(lte(table.column, 5));\nSELECT * FROM table WHERE table.column <= 5\nimport { lte } from \"drizzle-orm\";\n \ndb.select().from(table).where(lte(table.column1, table.column2));\nSELECT * FROM table WHERE table.column1 <= table.column2\nisNull\nPostgreSQL\nMySQL\nSQLite\n\nValue is null\n\nimport { isNull } from \"drizzle-orm\";\n \ndb.select().from(table).where(isNull(table.column));\nSELECT * FROM table WHERE table.column IS NULL\nisNotNull\nPostgreSQL\nMySQL\nSQLite\n\nValue is not null\n\nimport { isNotNull } from \"drizzle-orm\";\n \ndb.select().from(table).where(isNotNull(table.column));\nSELECT * FROM table WHERE table.column IS NOT NULL\ninArray\nPostgreSQL\nMySQL\nSQLite\n\nValue is in array of values\n\nimport { inArray } from \"drizzle-orm\";\n \ndb.select().from(table).where(inArray(table.column, [1, 2, 3, 4]));\nSELECT * FROM table WHERE table.column in (1, 2, 3, 4)\nimport { inArray } from \"drizzle-orm\";\n \nconst query = db.select({ data: table2.column }).from(table2);\ndb.select().from(table).where(inArray(table.column, query));\nSELECT * FROM table WHERE table.column IN (SELECT table2.column FROM table2)\nnotInArray\nPostgreSQL\nMySQL\nSQLite\n\nValue is not in array of values\n\nimport { notInArray } from \"drizzle-orm\";\n \ndb.select().from(table).where(notInArray(table.column, [1, 2, 3, 4]));\nSELECT * FROM table WHERE table.column NOT in (1, 2, 3, 4)\nimport { notInArray } from \"drizzle-orm\";\n \nconst query = db.select({ data: table2.column }).from(table2);\ndb.select().from(table).where(notInArray(table.column, query));\nSELECT * FROM table WHERE table.column NOT IN (SELECT table2.column FROM table2)\nexists\nPostgreSQL\nMySQL\nSQLite\n\nValue exists\n\nimport { exists } from \"drizzle-orm\";\n \nconst query = db.select().from(table2)\ndb.select().from(table).where(exists(query));\nSELECT * FROM table WHERE EXISTS (SELECT * from table2)\nnotExists\nimport { exists } from \"drizzle-orm\";\n \nconst query = db.select().from(table2)\ndb.select().from(table).where(notExists(query));\nSELECT * FROM table WHERE NOT EXISTS (SELECT * from table2)\nbetween\nPostgreSQL\nMySQL\nSQLite\n\nValue is between two values\n\nimport { between } from \"drizzle-orm\";\n \ndb.select().from(table).where(between(table.column, 2, 7));\nSELECT * FROM table WHERE table.column BETWEEN 2 AND 7\nnotBetween\nPostgreSQL\nMySQL\nSQLite\n\nValue is not between two value\n\nimport { notBetween } from \"drizzle-orm\";\n \ndb.select().from(table).where(notBetween(table.column, 2, 7));\nSELECT * FROM table WHERE table.column NOT BETWEEN 2 AND 7\nlike\nPostgreSQL\nMySQL\nSQLite\n\nValue is like other value, case sensitive\n\nimport { like } from \"drizzle-orm\";\n \ndb.select().from(table).where(like(table.column, \"%llo wor%\"));\nSELECT * FROM table  WHERE table.column LIKE '%llo wor%'\nilike\nPostgreSQL\nMySQL\nSQLite\n\nValue is like some other value, case insensitive\n\nimport { ilike } from \"drizzle-orm\";\n \ndb.select().from(table).where(ilike(table.column, \"%llo wor%\"));\nSELECT * FROM table WHERE table.column ILIKE '%llo wor%'\nnotIlike\nPostgreSQL\nMySQL\nSQLite\n\nValue is not like some other value, case insensitive\n\nimport { notIlike } from \"drizzle-orm\";\n \ndb.select().from(table).where(notIlike(table.column, \"%llo wor%\"));\nSELECT * FROM table WHERE table.column NOT ILIKE '%llo wor%'\nnot\nPostgreSQL\nMySQL\nSQLite\n\nAll conditions must return false.\n\nimport { eq, not } from \"drizzle-orm\";\n \ndb.select().from(table).where(not(eq(table.column, 5)));\nSELECT * FROM table WHERE NOT (table.column = 5)\nand\nPostgreSQL\nMySQL\nSQLite\n\nAll conditions must return true.\n\nimport { gt, lt, and } from \"drizzle-orm\";\n \ndb.select().from(table).where(and(gt(table.column, 5), lt(table.column, 7)));\nSELECT * FROM table WHERE (table.column > 5 AND table.column < 7)\nor\nPostgreSQL\nMySQL\nSQLite\n\nOne or more conditions must return true.\n\nimport { gt, lt, or } from \"drizzle-orm\";\n \ndb.select().from(table).where(or(gt(table.column, 5), lt(table.column, 7)));\nSELECT * FROM table WHERE (table.column > 5 OR table.column < 7)\narrayContains\nPostgreSQL\nMySQL\nSQLite\n\nTest that a column or expression contains all elements of the list passed as the second argument\n\nimport { arrayContains } from \"drizzle-orm\";\n \nconst contains = await db.select({ id: posts.id }).from(posts)\n  .where(arrayContains(posts.tags, ['Typescript', 'ORM']));\n \nconst withSubQuery = await db.select({ id: posts.id }).from(posts)\n  .where(arrayContains(\n    posts.tags,\n    db.select({ tags: posts.tags }).from(posts).where(eq(posts.id, 1)),\n  ));\nselect \"id\" from \"posts\" where \"posts\".\"tags\" @> {Typescript,ORM};\nselect \"id\" from \"posts\" where \"posts\".\"tags\" @> (select \"tags\" from \"posts\" where \"posts\".\"id\" = 1);\narrayContained\nPostgreSQL\nMySQL\nSQLite\n\nTest that the list passed as the second argument contains all elements of a column or expression\n\nimport { arrayContained } from \"drizzle-orm\";\n \nconst contained = await db.select({ id: posts.id }).from(posts)\n  .where(arrayContained(posts.tags, ['Typescript', 'ORM']));\nselect \"id\" from \"posts\" where \"posts\".\"tags\" <@ {Typescript,ORM};\narrayOverlaps\nPostgreSQL\nMySQL\nSQLite\n\nTest that a column or expression contains any elements of the list passed as the second argument.\n\nimport { arrayOverlaps } from \"drizzle-orm\";\n \nconst overlaps = await db.select({ id: posts.id }).from(posts)\n  .where(arrayOverlaps(posts.tags, ['Typescript', 'ORM']));\nselect \"id\" from \"posts\" where \"posts\".\"tags\" && {Typescript,ORM}\nDelete\nJoins"
  },
  {
    "title": "SQL Update",
    "url": "https://orm.drizzle.team/docs/update",
    "html": "Update\nSQL Update\nawait db.update(users)\n  .set({ name: 'Mr. Dan' })\n  .where(eq(users.name, 'Dan'));\nUpdate with returning\nPostgreSQL\nSQLite\nMySQL\n\nYou can update a row and get it back in PostgreSQL and SQLite:\n\nconst updatedUserId: { updatedId: number }[] = await db.update(users)\n  .set({ name: 'Mr. Dan' })\n  .where(eq(users.name, 'Dan'))\n  .returning({ updatedId: users.id });\nInsert\nDelete"
  },
  {
    "title": "SQL Delete",
    "url": "https://orm.drizzle.team/docs/delete",
    "html": "Delete\nSQL Delete\n\nYou can delete all rows in the table:\n\nawait db.delete(users);\n\nAnd you can delete with filters and conditions:\n\nawait db.delete(users).where(eq(users.name, 'Dan'));\nDelete with return\nPostgreSQL\nSQLite\nMySQL\n\nYou can delete a row and get it back in PostgreSQL and SQLite:\n\nconst deletedUser = await db.delete(users)\n  .where(eq(users.name, 'Dan'))\n  .returning();\n \n// partial return\nconst deletedUserIds: { deletedId: number }[] = await db.delete(users)\n  .where(eq(users.name, 'Dan'))\n  .returning({ deletedId: users.id });\nUpdate\nFilters"
  },
  {
    "title": "SQL Insert",
    "url": "https://orm.drizzle.team/docs/insert",
    "html": "Insert\nSQL Insert\n\nDrizzle ORM provides you the most SQL-like way to insert rows into the database tables.\n\nInsert one row\n\nInserting data with Drizzle is extremely straightfoward and sql-like. See for yourself:\n\nawait db.insert(users).values({ name: 'Andrew' });\ninsert into \"users\" (\"name\") values (\"Andrew\");\n\nIf you need insert type for a particular table you can use typeof usersTable.$inferInsert syntax.\n\ntype NewUser = typeof users.$inferInsert;\n \nconst insertUser = async (user: NewUser) => {\n  return db.insert(users).values(user);\n}\n \nconst newUser: NewUser = { name: \"Alef\" };\nawait insertUser(newUser);\nInsert returning\nPostgreSQL\nSQLite\nMySQL\n\nYou can insert a row and get it back in PostgreSQL and SQLite like such:\n\nawait db.insert(users).values({ name: \"Dan\" }).returning();\n \n// partial return\nawait db.insert(users).values({ name: \"Partial Dan\" }).returning({ insertedId: users.id });\nInsert multiple rows\nawait db.insert(users).values([{ name: 'Andrew' }, { name: 'Dan' }]);\nUpserts and conflicts\n\nDrizzle ORM provides simple interfaces for handling upserts and conflicts.\n\nOn conflict do nothing\nPostgreSQL\nSQLite\nMySQL\n\nonConflictDoNothing will cancel the insert if there's a conflict:\n\nawait db.insert(users)\n  .values({ id: 1, name: 'John' })\n  .onConflictDoNothing();\n \n// explicitly specify conflict target\nawait db.insert(users)\n  .values({ id: 1, name: 'John' })\n  .onConflictDoNothing({ target: users.id });\n\nThis is how you upsert with onConflictDoUpdate, you can specify set and where clauses.\n\nPostgreSQL\nSQLite\nMySQL\n\nonConflictDoUpdate will update the row if there's a conflict:\n\nawait db.insert(users)\n  .values({ id: 1, name: 'Dan' })\n  .onConflictDoUpdate({ target: users.id, set: { name: 'John' } });\n\nUpsert with where clause for onConflictDoUpdate:\n\nawait db.insert(users)\n  .values({ id: 1, name: 'John' })\n  .onConflictDoUpdate({\n    target: users.id,\n    set: { name: 'John1' },\n    where: sql`${users.createdAt} > '2023-01-01'::date`,\n  });\nOn duplicate key update\nPostgreSQL\nSQLite\nMySQL\n\nMySQL supports ON DUPLICATE KEY UPDATE\n(opens in a new tab)\n instead of ON CONFLICT clauses. MySQL will automatically determine the conflict target based on the primary key and unique indexes, and will update the row if any unique index conflicts.\n\nDrizzle supports this through the onDuplicateKeyUpdate method:\n\n// Note that MySQL automatically determines targets based on the primary key and unique indexes\nawait db.insert(users)\n  .values({ id: 1, name: 'John' })\n  .onDuplicateKeyUpdate({ set: { name: 'John' } });\n\nWhile MySQL does not directly support doing nothing on conflict, you can perform a no-op by setting any column's value to itself and achieve the same effect:\n\nimport { sql } from 'drizzle-orm';\n \nawait db.insert(users)\n  .values({ id: 1, name: 'John' })\n  .onDuplicateKeyUpdate({ set: { id: sql`id` } });\nSelect\nUpdate"
  },
  {
    "title": "Drizzle Queries",
    "url": "https://orm.drizzle.team/docs/rqb",
    "html": "Query\nDrizzle Queries\n\nDrizzle ORM is designed to be a thin typed layer on top of SQL. We truly believe we've designed the best way to operate an SQL database from TypeScript and it's time to make it better.\n\nRelational queries are meant to provide you with a great developer experience for querying nested relational data from an SQL database, avoiding multiple joins and complex data mappings.\n\nIt is an extension to the existing schema definition and query builder. You can opt-in to use it based on your needs. We've made sure you have both the best-in-class developer experience and performance.\n\nindex.ts\nschema.ts\nimport * as schema from './schema';\nimport { drizzle } from 'drizzle-orm/...';\n \nconst db = drizzle(client, { schema });\n \nconst result = await db.query.users.findMany({\n\twith: {\n\t\tposts: true\t\t\t\n\t},\n});\n[{\n\tid: 10,\n\tname: \"Dan\",\n\tposts: [\n\t\t{\n\t\t\tid: 1,\n\t\t\tcontent: \"SQL is awesome\",\n\t\t\tauthorId: 10,\n\t\t},\n\t\t{\n\t\t\tid: 2,\n\t\t\tcontent: \"But check relational queries\",\n\t\t\tauthorId: 10,\n\t\t}\n\t]\n}]\nModes\n\nDrizzle relational queries always generate exactly one SQL statement to run on the database and it has certain caveats. To have best in class support for every database out there we've introduced modes.\n\nDrizzle relational queries use lateral joins of subqueries under the hood and for now PlanetScale does not support them.\n\nWhen using mysql2 driver with regular MySQL database ‚Äî you should specify mode: \"default\" When using mysql2 driver with PlanetScale ‚Äî you need to specify mode: \"planetscale\"\n\nimport * as schema from './schema';\nimport { drizzle } from \"drizzle-orm/mysql2\";\nimport mysql from \"mysql2/promise\";\n \nconst connection = await mysql.createConnection({\n  uri: process.env.PLANETSCALE_DATABASE_URL,\n});\n \nconst db = drizzle(connection, { schema, mode: 'planetscale' });\nDeclaring relations\nOne-to-one\n\nDrizzle ORM provides you an API to define one-to-one relations between tables with relations operator.\n\nExample of one-to-one relation between users and users who invited them to the service, self reference:\n\nimport { pgTable, serial, text, integer, boolean } from 'drizzle-orm/pg-core';\nimport { relations } from 'drizzle-orm';\n \nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n\tinvitedBy: integer('invited_by'),\n});\n \nexport const usersRelations = relations(users, ({ one }) => ({\n\tinvitee: one(users, {\n\t\tfields: [users.invitedBy],\n\t\treferences: [users.id],\n\t}),\n}));\n\nAnother example would be a user having a profile information stored in separate table:\n\nimport { pgTable, serial, text, integer, jsonb } from 'drizzle-orm/pg-core';\nimport { relations } from 'drizzle-orm';\n \nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const usersRelations = relations(users, ({ one }) => ({\n\tprofileInfo: one(profileInfo),\n}));\n \nexport const profileInfo = pgTable('profile_info', {\n\tid: serial('id').primaryKey(),\n\tuserId: integer(\"user_id\").references(() => users.id),\n\tmetadata: jsonb(\"metadata\"),\n});\nOne-to-many\n\nDrizzle ORM provides you an API to define one-to-many relations between tables with relations operator.\n\nExample of one-to-many relation between users and posts they've written:\n\nimport { pgTable, serial, text, integer } from 'drizzle-orm/pg-core';\nimport { relations } from 'drizzle-orm';\n \nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const usersRelations = relations(users, ({ many }) => ({\n\tposts: many(posts),\n}));\n \nexport const posts = pgTable('posts', {\n\tid: serial('id').primaryKey(),\n\tcontent: text('content'),\n\tauthorId: integer('author_id'),\n});\n \nexport const postsRelations = relations(posts, ({ one }) => ({\n\tauthor: one(users, {\n\t\tfields: [posts.authorId],\n\t\treferences: [users.id],\n\t}),\n}));\n\nNow lets add comments to the posts:\n\n...\n \nexport const posts = pgTable('posts', {\n\tid: serial('id').primaryKey(),\n\tcontent: text('content'),\n\tauthorId: integer('author_id'),\n});\n \nexport const postsRelations = relations(posts, ({ one, many }) => ({\n\tauthor: one(users, {\n\t\tfields: [posts.authorId],\n\t\treferences: [users.id],\n\t}),\n\tcomments: many(comments)\n}));\n \nexport const comments = pgTable('comments', {\n\tid: serial('id').primaryKey(),\n\ttext: text('text'),\n\tauthorId: integer('author_id'),\n\tpostId: integer('post_id'),\n});\n \nexport const commentsRelations = relations(comments, ({ one }) => ({\n\tpost: one(posts, {\n\t\tfields: [comments.postId],\n\t\treferences: [posts.id],\n\t}),\n}));\nMany-to-many\n\nDrizzle ORM provides you an API to define many-to-many relations between tables through so called junction or join tables, they have to be explicitly defined and store associations between related tables.\n\nExample of many-to-many relation between users and groups:\n\nimport { pgTable, serial, text, integer, boolean, primaryKey } from 'drizzle-orm/pg-core';\nimport { relations } from 'drizzle-orm';\n \nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const usersRelations = relations(users, ({ many }) => ({\n\tusersToGroups: many(usersToGroups),\n}));\n \nexport const groups = pgTable('groups', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const groupsRelations = relations(groups, ({ many }) => ({\n\tusersToGroups: many(usersToGroups),\n}));\n \nexport const usersToGroups = pgTable('users_to_groups', {\n\t\tuserId: integer('user_id').notNull().references(() => users.id),\n\t\tgroupId: integer('group_id').notNull().references(() => groups.id),\n\t}, (t) => ({\n\t\tpk: primaryKey(t.userId, t.groupId),\n\t}),\n);\n \nexport const usersToGroupsRelations = relations(usersToGroups, ({ one }) => ({\n\tgroup: one(groups, {\n\t\tfields: [usersToGroups.groupId],\n\t\treferences: [groups.id],\n\t}),\n\tuser: one(users, {\n\t\tfields: [usersToGroups.userId],\n\t\treferences: [users.id],\n\t}),\n}));\nForeign keys\n\nYou might've noticed that relations look similar to foreign keys ‚Äî they even have a references property. So what's the difference?\n\nWhile foreign keys serve a similar purpose, defining relations between tables, they work on a different level compared to relations.\n\nForeign keys are a database level constraint, they are checked on every insert/update/delete operation and throw an error if a constraint is violated. On the other hand, relations are a higher level abstraction, they are used to define relations between tables on the application level only. They do not affect the database schema in any way and do not create foreign keys implicitly.\n\nWhat this means is relations and foreign keys can be used together, but they are not dependent on each other. You can define relations without using foreign keys (and vice versa), which allows them to be used with databases that do not support foreign keys, like PlanetScale.\n\nThe following two examples will work exactly the same in terms of querying the data using Drizzle relational queries.\n\nschema1.ts\nschema2.ts\nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const usersRelations = relations(users, ({ one, many }) => ({\n\tprofileInfo: one(users, {\n\t\tfields: [profileInfo.userId],\n\t\treferences: [users.id],\n\t}),\n}));\n \nexport const profileInfo = pgTable('profile_info', {\n\tid: serial('id').primaryKey(),\n\tuserId: integer(\"user_id\"),\n\tmetadata: jsonb(\"metadata\"),\n});\nDisambiguating relations\n\nDrizzle also provides the relationName option as a way to disambiguate relations when you define multiple of them between the same two tables. For example, if you define a posts table that has the author and reviewer relations.\n\nimport { pgTable, serial, text, integer } from 'drizzle-orm/pg-core';\nimport { relations } from 'drizzle-orm';\n \nexport const users = pgTable('users', {\n\tid: serial('id').primaryKey(),\n\tname: text('name'),\n});\n \nexport const usersRelations = relations(users, ({ many }) => ({\n\tauthor: many(posts, { relationName: 'author' }),\n\treviewer: many(posts, { relationName: 'reviewer' }),\n}));\n \nexport const posts = pgTable('posts', {\n\tid: serial('id').primaryKey(),\n\tcontent: text('content'),\n\tauthorId: integer('author_id'),\n\treviewerId: integer('reviewer_id'),\n});\n \nexport const postsRelations = relations(posts, ({ one }) => ({\n\tauthor: one(users, {\n\t\tfields: [posts.authorId],\n\t\treferences: [users.id],\n\t\trelationName: 'author',\n\t}),\n\treviewer: one(users, {\n\t\tfields: [posts.reviewerId],\n\t\treferences: [users.id],\n\t\trelationName: 'reviewer',\n\t}),\n}));\nQuerying\n\nRelational queries are an extension to Drizzle's original query builder. You need to provide all tables and relations from your schema file/files upon drizzle() initialization and then just use the db.query API.\n\n‚ÑπÔ∏è\n\ndrizzle import path depends on the database driver you're using.\n\nindex.ts\nschema.ts\nimport * as schema from './schema';\nimport { drizzle } from 'drizzle-orm/...';\n \nconst db = drizzle(client, { schema });\n \nawait db.query.users.findMany(...);\n// if you have schema in multiple files\nimport * as schema1 from './schema1';\nimport * as schema2 from './schema2';\nimport { drizzle } from 'drizzle-orm/...';\n \nconst db = drizzle(client, { schema: { ...schema1, ...schema2 } });\n \nawait db.query.users.findMany(...);\n\nDrizzle provides .findMany() and .findFirst() APIs.\n\nFind many\nconst users = await db.query.users.findMany();\n// result type\nconst result: {\n\tid: number;\n\tname: string;\n\tverified: boolean;\n\tinvitedBy: number | null;\n}[];\nFind first\nüí°\n\n.findFirst() will add limit 1 to the query.\n\nconst user = await db.query.users.findFirst();\n// result type\nconst result: {\n\tid: number;\n\tname: string;\n\tverified: boolean;\n\tinvitedBy: number | null;\n};\nInclude relations\n\nWith operator lets you combine data from multiple related tables and properly aggregate results.\n\nGetting all posts with comments:\n\nconst posts = await db.query.posts.findMany({\n\twith: {\n\t\tcomments: true,\n\t},\n});\n\nGetting first post with comments:\n\nconst post = await db.query.posts.findFirst({\n\twith: {\n\t\tcomments: true,\n\t},\n});\n\nYou can chain nested with statements as much as necessary.\nFor any nested with queries Drizzle will infer types using Core Type API.\n\nGet all users with posts. Each post should contain a list of comments:\n\nconst users = await db.query.users.findMany({\n\twith: {\n\t\tposts: {\n\t\t\twith: {\n\t\t\t\tcomments: true,\n\t\t\t},\n\t\t},\n\t},\n});\nPartial fields select\n\ncolumns parameter lets you include or omit columns you want to get from the database.\n\n‚ÑπÔ∏è\n\nDrizzle performs partial selects on the query level, no additional data is transferred from the database.\n\nKeep in mind that a single SQL statement is outputted by Drizzle.\n\nGet all posts with just id, content and include comments:\n\nconst posts = await db.query.posts.findMany({\n\tcolumns: {\n\t\tid: true,\n\t\tcontent: true,\n\t},\n\twith: {\n\t\tcomments: true,\n\t}\n});\n\nGet all posts without content:\n\nconst posts = await db.query.posts.findMany({\n\tcolumns: {\n\t\tcontent: false,\n\t},\n});\n‚ÑπÔ∏è\n\nWhen both true and false select options are present, all false options are ignored.\n\nIf you include the name field and exclude the id field, id exclusion will be redundant, all fields apart from name would be excluded anyways.\n\nExclude and Include fields in the same query:\n\nconst users = await db.query.users.findMany({\n\tcolumns: {\n\t\tname: true,\n\t\tid: false //ignored\n\t},\n});\n// result type\nconst users: {\n\tname: string;\n};\n\nOnly include columns from nested relations:\n\nconst res = await db.query.users.findMany({\n\tcolumns: {},\n\twith: {\n\t\tposts: true\n\t}\n});\n// result type\nconst res: {\n\tposts: {\n\t\tid: number,\n\t\ttext: string\n\t}\n}[];\nNested partial fields select\n\nJust like with partial select, you can include or exclude columns of nested relations:\n\nconst posts = await db.query.posts.findMany({\n\tcolumns: {\n\t\tid: true,\n\t\tcontent: true,\n\t},\n\twith: {\n\t\tcomments: {\n\t\t\tcolumns: {\n\t\t\t\tauthorId: false\n\t\t\t}\n\t\t}\n\t}\n});\nWhere | Filters\n\nJust like in our SQL-like query builder, relational queries API lets you define filters and conditions with the list of our operators.\n\nYou can either import them from drizzle-orm or use from the callback syntax:\n\nimport { eq } from 'drizzle-orm';\n \nconst users = await db.query.users.findMany({\n\twhere: eq(users.id, 1)\n})\nconst users = await db.query.users.findMany({\n\twhere: (users, { eq }) => eq(users.id, 1),\n})\n\nFind post with id=1 and comments that were created before particular date:\n\nawait db.query.posts.findMany({\n\twhere: (posts, { eq }) => (eq(posts.id, 1)),\n\twith: {\n\t\tcomments: {\n\t\t\twhere: (comments, { lt }) => lt(comments.createdAt, new Date()),\n\t\t},\n\t},\n});\nLimit & Offset\n\nDrizzle ORM provides limit & offset API for queries and for the nested entities.\n\nFind 5 posts:\n\nawait db.query.posts.findMany({\n\tlimit: 5,\n});\n\nFind posts and get 3 comments at most:\n\nawait db.query.posts.findMany({\n\twith: {\n\t\tcomments: {\n\t\t\tlimit: 3,\n\t\t},\n\t},\n});\n‚ö†Ô∏è\n\noffset is only available for top level query.\n\nawait db.query.posts.findMany({\n\tlimit: 5,\n\toffset: 2, // correct ‚úÖ\n\twith: {\n\t\tcomments: {\n\t\t\toffset: 3, // incorrect ‚ùå\n\t\t\tlimit: 3,\n\t\t},\n\t},\n});\n\nFind posts with comments from the 5th to the 10th post:\n\nawait db.query.posts.findMany({\n\tlimit: 5,\n  offset: 5,\n\twith: {\n\t\tcomments: true,\n\t},\n});\nOrder By\n\nDrizzle provides API for ordering in the relational query builder.\n\nYou can use same ordering core API or use order by operator from the callback with no imports.\n\nimport { desc, asc } from 'drizzle-orm';\n \nawait db.query.posts.findMany({\n\torderBy: [asc(posts.id)],\n});\nawait db.query.posts.findMany({\n\torderBy: (posts, { asc }) => [asc(posts.id)],\n});\n\nOrder by asc + desc:\n\nawait db.query.posts.findMany({\n\torderBy: (posts, { asc }) => [asc(posts.id)],\n\twith: {\n\t\tcomments: {\n\t\t\torderBy: (comments, { desc }) => [desc(comments.id)],\n\t\t},\n\t},\n});\nInclude custom fields\n\nRelational query API lets you add custom additional fields. It's useful when you need to retrieve data and apply additional functions to it.\n\n‚ö†Ô∏è\n\nAs of now aggregations are not supported in extras, please use core queries for that.\n\nimport { sql } from 'drizzle-orm';\n \nawait db.query.users.findMany({\n\textras: {\n\t\tloweredName: sql`lower(${users.name})`.as('lowered_name'),\n\t},\n})\nawait db.query.users.findMany({\n\textras: {\n\t\tloweredName: (users, { sql }) => sql`lower(${users.name})`.as('lowered_name'),\n\t},\n})\n\nlowerName as a key will be included to all fields in returned object.\n\n‚ö†Ô∏è\n\nYou have to explicitly specify .as(\"<name_for_column>\")\n\nTo retrieve all users with groups, but with the fullName field included (which is a concatenation of firstName and lastName), you can use the following query with the Drizzle relational query builder.\n\nconst res = await db.query.users.findMany({\n\textras: {\n\t\tfullName: sql<string>`concat(${users.name}, \" \", ${users.name})`.as('full_name'),\n\t},\n\twith: {\n\t\tusersToGroups: {\n\t\t\twith: {\n\t\t\t\tgroup: true,\n\t\t\t},\n\t\t},\n\t},\n});\n// result type\nconst res: {\n\tid: number;\n\tname: string;\n\tverified: boolean;\n\tinvitedBy: number | null;\n\tfullName: string;\n\tusersToGroups: {\n\t\t\tgroup: {\n\t\t\t\t\tid: number;\n\t\t\t\t\tname: string;\n\t\t\t\t\tdescription: string | null;\n\t\t\t};\n\t}[];\n}[];\n \n\nTo retrieve all posts with comments and add an additional field to calculate the size of the post content and the size of each comment content:\n\nconst res = await db.query.posts.findMany({\n\textras: (table, { sql }) => ({\n\t\tcontentLength: (sql<number>`length(${table.content})`).as('content_length'),\n\t}),\n\twith: {\n\t\tcomments: {\n\t\t\textras: {\n\t\t\t\tcommentSize: sql<number>`length(${comments.content})`.as('comment_size'),\n\t\t\t},\n\t\t},\n\t},\n});\n// result type\nconst res: {\n\tid: number;\n\tcreatedAt: Date;\n\tcontent: string;\n\tauthorId: number | null;\n\tcontentLength: number;\n\tcomments: {\n\t\t\tid: number;\n\t\t\tcreatedAt: Date;\n\t\t\tcontent: string;\n\t\t\tcreator: number | null;\n\t\t\tpostId: number | null;\n\t\t\tcommentSize: number;\n\t}[];\n};\nPrepared statements\n\nPrepared statements are designed to massively improve query performance ‚Äî see here.\n\nIn this section, you can learn how to define placeholders and execute prepared statements using the Drizzle relational query builder.\n\nPlaceholder in where\nPostgreSQL\nMySQL\nSQLite\nconst prepared = db.query.users.findMany({\n\twhere: ((users, { eq }) => eq(users.id, placeholder('id'))),\n\twith: {\n\t\tposts: {\n\t\t\twhere: ((users, { eq }) => eq(users.id, 1)),\n\t\t},\n\t},\n}).prepare('query_name');\n \nconst usersWithPosts = await prepared.execute({ id: 1 });\nPlaceholder in limit\nPostgreSQL\nMySQL\nSQLite\nconst prepared = db.query.users.findMany({\n\twith: {\n\t\tposts: {\n\t\t\tlimit: placeholder('limit'),\n\t\t},\n\t},\n}).prepare('query_name');\n \nconst usersWithPosts = await prepared.execute({ limit: 1 });\nPlaceholder in offset\nPostgreSQL\nMySQL\nSQLite\nconst prepared = db.query.users.findMany({\n\toffset: placeholder('offset'),\n\twith: {\n\t\tposts: true,\n\t},\n}).prepare('query_name');\n \nconst usersWithPosts = await prepared.execute({ offset: 1 });\nMultiple placeholders\nPostgreSQL\nMySQL\nSQLite\nconst prepared = db.query.users.findMany({\n\tlimit: placeholder('uLimit'),\n\toffset: placeholder('uOffset'),\n\twhere: ((users, { eq, or }) => or(eq(users.id, placeholder('id')), eq(users.id, 3))),\n\twith: {\n\t\tposts: {\n\t\t\twhere: ((users, { eq }) => eq(users.id, placeholder('pid'))),\n\t\t\tlimit: placeholder('pLimit'),\n\t\t},\n\t},\n}).prepare('query_name');\n \nconst usersWithPosts = await prepared.execute({ pLimit: 1, uLimit: 3, uOffset: 1, id: 2, pid: 6 });\nSchemas\nSelect"
  },
  {
    "title": "SQL Select",
    "url": "https://orm.drizzle.team/docs/select",
    "html": "Select\nSQL Select\n\nDrizzle provides you the most SQL-like way to fetch data from your database, while remaining type-safe and composable. It natively supports mostly every query feature and capability of every dialect, and whatever it doesn't support yet, can be added by the user with the powerful sql operator.\n\nFor the following examples, let's assume you have a users table defined like this:\n\nPostgreSQL\nMySQL\nSQLite\nimport { pgTable, serial, text } from 'drizzle-orm/pg-core';\n \nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  age: integer('age'),\n});\nBasic and partial select\nSelect with all columns\n\nSelect all rows from a table including all columns:\n\nconst result = await db.select().from(users);\n/*\n  {\n    id: number;\n    name: string;\n    age: number | null;\n  }[]\n*/\nselect \"id\", \"name\", \"age\" from \"users\";\n\nNotice that the result type is inferred automatically based on the table definition, including columns nullability.\n\nDrizzle always explicitly lists columns in the select clause instead of using select *.\nThis is required internally to guarantee the fields order in the query result, and is also generally considered a good practice.\n\nPartial select\n\nIn some cases, you might want to select only a subset of columns from a table. You can do that by providing a selection object to the .select() method:\n\nconst result = await db.select({\n  field1: users.id,\n  field2: users.name,\n}).from(users);\n \nconst { field1, field2 } = result[0];\nselect \"id\", \"name\" from \"users\";\n\nLike in SQL, you can use arbitrary expressions as selection fields, not just table columns:\n\nconst result = await db.select({\n  id: users.id,\n  lowerName: sql<string>`lower(${users.name})`,\n}).from(users);\nselect \"id\", lower(\"name\") from \"users\";\n‚ö†Ô∏è\n\nBy specifying sql<string>, you are telling Drizzle that the expected type of the field is string.\nIf you specify it incorrectly (e.g. use sql<number> for a field that will be returned as a string), the runtime value won't match the expected type. Drizzle cannot perform any type casts based on the provided type generic, because that information is not available at runtime.\n\nIf you need to apply runtime transformations to the returned value, you can use the .mapWith() method.\n\nIf you have an expression you use frequently, you can extract it into a function:\n\nimport type { Column } from 'drizzle-orm';\nimport { sql } from 'drizzle-orm';\n \nfunction lower(col: Column) {\n  return sql<string>`lower(${col})`;\n}\n \nconst result = await db.select({\n  id: users.id,\n  lowerName: lower(users.name),\n}).from(users);\nConditional select\n\nYou can have a dynamic selection object based on some condition:\n\nasync function selectUsers(withName: boolean) {\n  return db\n    .select({\n      id: users.id,\n      ...(withName ? { name: users.name } : {}),\n    })\n    .from(users);\n}\n \nconst users = await selectUsers(true);\nFiltering\n\nYou can filter the query results using the filter operators in the .where() method:\n\nimport { eq, lt, gte, ne } from 'drizzle-orm';\n \nawait db.select().from(users).where(eq(users.id, 42));\nawait db.select().from(users).where(lt(users.id, 42));\nawait db.select().from(users).where(gte(users.id, 42));\nawait db.select().from(users).where(ne(users.id, 42));\n...\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" < 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" >= 42;\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" <> 42;\n\nAll filter operators are implemented using the sql function. You can use it yourself to write arbitrary SQL filters, or build your own operators. For inspiration, you can check how the operators provided by Drizzle are implemented\n(opens in a new tab)\n.\n\nimport { sql } from 'drizzle-orm';\n \nfunction equals42(col: Column) {\n  return sql`${col} = 42`;\n}\n \nawait db.select().from(users).where(sql`${users.id} < 42`);\nawait db.select().from(users).where(sql`${users.id} = 42`);\nawait db.select().from(users).where(equals42(users.id));\nawait db.select().from(users).where(sql`${users.id} >= 42`);\nawait db.select().from(users).where(sql`${users.id} <> 42`);\nawait db.select().from(users).where(sql`lower(${users.name}) = 'aaron'`);\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' < 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' = 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' >= 42;\nselect \"id\", \"name\", \"age\" from \"users\" where 'id' <> 42;\nselect \"id\", \"name\", \"age\" from \"users\" where lower(\"name\") = 'aaron';\n\nAll the values provided to filter operators and to the sql function are parameterized automatically. For example, this query:\n\nawait db.select().from(users).where(eq(users.id, 42));\n\nwill be translated to:\n\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = $1; -- params: [42]\n\nInverting condition with a not operator:\n\nimport { eq, not, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(not(eq(users.id, 42)));\nawait db.select().from(users).where(sql`not ${users.id} = 42`);\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\nselect \"id\", \"name\", \"age\" from \"users\" where not (\"id\" = 42);\n\nYou can safely alter schema, rename tables and columns and it will be automatically reflected in your queries because of template interpolation, as opposed to hardcoding column or table names when writing raw SQL.\n\nCombining filters\n\nYou can logically combine filter operators with and() and or() operators:\n\nimport { eq, and, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(\n  and(\n    eq(users.id, 42),\n    eq(users.name, 'Dan')\n  )\n);\nawait db.select().from(users).where(sql`${users.id} = 42 and ${users.name} = 'Dan'`);\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = 'Dan';\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 and \"name\" = 'Dan';\nimport { eq, or, sql } from 'drizzle-orm';\n \nawait db.select().from(users).where(\n  or(\n    eq(users.id, 42), \n    eq(users.name, 'Dan')\n  )\n);\nawait db.select().from(users).where(sql`${users.id} = 42 or ${users.name} = 'Dan'`);\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = 'Dan';\nselect \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42 or \"name\" = 'Dan';\nDistinct\n\nYou can use .selectDistinct() instead of .select() to retrieve only unique rows from a dataset:\n\nawait db.selectDistinct().from(users).orderBy(usersTable.id, usersTable.name);\n \nawait db.selectDistinct({ id: users.id }).from(users).orderBy(usersTable.id);\nselect distinct \"id\", \"name\" from \"users\" order by \"id\", \"name\";\n \nselect distinct \"id\" from \"users\" order by \"id\";\n\nIn PostgreSQL, you can also use the distinct on clause to specify how the unique rows are determined:\n\nawait db.selectDistinctOn([users.id]).from(users).orderBy(users.id);\nawait db.selectDistinctOn([users.name], { name: users.name }).from(users).orderBy(users.name);\nselect distinct on (\"id\") \"id\", \"name\" from \"users\" order by \"id\";\nselect distinct on (\"name\") \"name\" from \"users\" order by \"name\";\nüí°\n\ndistinct on clause is only supported in PostgreSQL.\n\nLimit & offset\n\nUse .limit() and .offset() to add limit and offset clauses to the query - for example, to implement pagination:\n\nawait db.select().from(users).limit(10);\nawait db.select().from(users).limit(10).offset(10);\nselect \"id\", \"name\", \"age\" from \"users\" limit 10;\nselect \"id\", \"name\", \"age\" from \"users\" limit 10 offset 10;\nOrder By\n\nUse .orderBy() to add order by clause to the query, sorting the results by the specified fields:\n\nimport { asc, desc } from 'drizzle-orm';\n \nawait db.select().from(users).orderBy(users.name);\nawait db.select().from(users).orderBy(desc(users.name));\n \n// order by multiple fields\nawait db.select().from(users).orderBy(users.name, users.name2);\nawait db.select().from(users).orderBy(asc(users.name), desc(users.name2));\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\";\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" desc;\n \nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\", \"name2\";\nselect \"id\", \"name\", \"age\" from \"users\" order by \"name\" asc, \"name2\" desc;\nWITH clause\n\nUsing the with clause can help you simplify complex queries by splitting them into smaller subqueries called common table expressions (CTEs):\n\nconst sq = db.$with('sq').as(db.select().from(users).where(eq(users.id, 42)));\n \nconst result = await db.with(sq).select().from(sq);\nwith sq as (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42)\nselect \"id\", \"name\", \"age\" from sq;\n\nTo select arbitrary SQL values as fields in a CTE and reference them in other CTEs or in the main query, you need to add aliases to them:\n\n \nconst sq = db.$with('sq').as(db.select({ \n  name: sql<string>`upper(${users.name})`.as('name'),\n})\n.from(users));\n \nconst result = await db.with(sq).select({ name: sq.name }).from(sq);\n\nIf you don't provide an alias, the field type will become DrizzleTypeError and you won't be able to reference it in other queries. If you ignore the type error and still try to use the field, you will get a runtime error, since there's no way to reference that field without an alias.\n\nSelect from subquery\n\nJust like in SQL, you can embed queries into other queries by using the subquery API:\n\nconst sq = db.select().from(users).where(eq(users.id, 42)).as('sq');\nconst result = await db.select().from(sq);\nselect \"id\", \"name\", \"age\" from (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\";\n\nSubqueries can be used in any place where a table can be used, for example in joins:\n\nconst sq = db.select().from(users).where(eq(users.id, 42)).as('sq');\nconst result = await db.select().from(users).leftJoin(sq, eq(users.id, sq.id));\nselect \"users\".\"id\", \"users\".\"name\", \"users\".\"age\", \"sq\".\"id\", \"sq\".\"name\", \"sq\".\"age\" from \"users\"\n  left join (select \"id\", \"name\", \"age\" from \"users\" where \"id\" = 42) \"sq\"\n    on \"users\".\"id\" = \"sq\".\"id\";\nAggregations\n\nWith Drizzle, you can do aggregations using functions like sum, count, avg, etc. by grouping and filtering with .groupBy() and .having() respectfully, same as you would do in raw SQL:\n\nimport { gt } from 'drizzle-orm';\n \nawait db.select({\n  age: users.age,\n  count: sql<number>`cast(count(${users.id}) as int)`,\n})\n  .from(users)\n  .groupBy(users.age);\n \nawait db.select({\n  age: users.age,\n  count: sql<number>`cast(count(${users.id}) as int)`,\n})\n  .from(users)\n  .groupBy(users.age)\n  .having(({ count }) => gt(count, 1));\nselect \"age\", cast(count(\"id\") as int)\n  from \"users\"\n  group by \"age\";\n \nselect \"age\", cast(count(\"id\") as int)\n  from \"users\"\n  group by \"age\"\n  having cast(count(\"id\") as int) > 1;\n\ncast(... as int) is necessary because count() returns bigint in PostgreSQL and decimal in MySQL, which are treated as string values instead of numbers. Alternatively, you can use .mapWith(Number) to cast the value to a number at runtime.\n\nA more advanced example:\n\nconst orders = sqliteTable('order', {\n  id: integer('id').primaryKey(),\n  orderDate: integer('order_date', { mode: 'timestamp' }).notNull(),\n  requiredDate: integer('required_date', { mode: 'timestamp' }).notNull(),\n  shippedDate: integer('shipped_date', { mode: 'timestamp' }),\n  shipVia: integer('ship_via').notNull(),\n  freight: numeric('freight').notNull(),\n  shipName: text('ship_name').notNull(),\n  shipCity: text('ship_city').notNull(),\n  shipRegion: text('ship_region'),\n  shipPostalCode: text('ship_postal_code'),\n  shipCountry: text('ship_country').notNull(),\n  customerId: text('customer_id').notNull(),\n  employeeId: integer('employee_id').notNull(),\n});\n \nconst details = sqliteTable('order_detail', {\n  unitPrice: numeric('unit_price').notNull(),\n  quantity: integer('quantity').notNull(),\n  discount: numeric('discount').notNull(),\n  orderId: integer('order_id').notNull(),\n  productId: integer('product_id').notNull(),\n});\n \n \ndb\n  .select({\n    id: orders.id,\n    shippedDate: orders.shippedDate,\n    shipName: orders.shipName,\n    shipCity: orders.shipCity,\n    shipCountry: orders.shipCountry,\n    productsCount: sql<number>`cast(count(${details.productId}) as int)`,\n    quantitySum: sql<number>`sum(${details.quantity})`,\n    totalPrice: sql<number>`sum(${details.quantity} * ${details.unitPrice})`,\n  })\n  .from(orders)\n  .leftJoin(details, eq(orders.id, details.orderId))\n  .groupBy(orders.id)\n  .orderBy(asc(orders.id))\n  .all();\nQuery\nInsert"
  },
  {
    "title": "Table schemas",
    "url": "https://orm.drizzle.team/docs/schemas",
    "html": "Schemas\nTable schemas\nPostgreSQL\nMySQL\nSQLite\n\nDrizzle ORM provides you an API for declaring SQL schemas for PostgreSQL and MySQL dialects.\n\nIf you declare table within a schema, query builder will prepend schema names in queries select * from \"schema\".\"users\"\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, pgTable, pgSchema } from \"drizzle-orm/pg-core\";\n \nexport const mySchema = pgSchema(\"my_schema\")\n \nexport const mySchemaUsers = mySchema.table('users', {\n  id: serial('id').primaryKey(),\n  name: text('name'),\n});\nCREATE SCHEMA \"my_schema\";\n \nCREATE TABLE \"my_schema\".\"users\" (\n  \"id\" serial PRIMARY KEY,\n  \"name\" text\n);\nViews\nQuery"
  },
  {
    "title": "Views (WIP)",
    "url": "https://orm.drizzle.team/docs/views",
    "html": "Views\nViews (WIP)\n‚ö†Ô∏è\n\nViews are currently only implemented in the drizzle-orm, drizzle-kit does not support views yet. You can query the views that already exist in the database, but they won't be added to drizzle-kit migrations or db push as of now.\n\nViews declaration\n\nThere're several ways you can declare views with Drizzle ORM.\n\nYou can declare views that have to be created or you can declare views that already exist in the database.\n\nYou can declare views statements with an inline query builder syntax, with standalone query builder and with raw sql operators.\n\nWhen views are created with either inlined or standalone query builders, view columns schema will be automatically inferred, yet when you use sql you have to explicitly declare view columns schema.\n\nDeclaring views\nPostgreSQL\nMySQL\nSQLite\nschema.ts\nimport { pgTable, pgView, serial, text, timestamp } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  email: text(\"email\"),\n  password: text(\"password\"),\n  role: text(\"role\").$type<\"admin\" | \"customer\">(),\n  createdAt: timestamp(\"created_at\"),\n  updatedAt: timestamp(\"updated_at\"),\n});\n \nexport const userView = pgView(\"user_view\").as((qb) => qb.select().from(user));\nexport const customersView = pgView(\"customers_view\").as((qb) => qb.select().from(user).where(eq(user.role, \"customer\")));\nCREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\nCREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = 'customer';\n\nIf you need a subset of columns you can use .select({ ... }) method in query builder, like this:\n\nexport const customersView = pgView(\"customers_view\").as((qb) => {\n  return qb\n    .select({\n      id: user.id,\n      name: user.name,\n      email: user.email,\n    })\n    .from(user);\n});\nCREATE VIEW \"customers_view\" AS SELECT \"id\", \"name\", \"email\" FROM \"user\" WHERE \"role\" = 'customer';\n\nYou can also declare views using standalone query builder, it works exactly the same way:\n\nPostgreSQL\nMySQL\nSQLite\nschema.ts\nimport { pgTable, pgView, serial, text, timestamp, QueryBuilder} from \"drizzle-orm/pg-core\";\n \nconst qb = new QueryBuilder();\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  email: text(\"email\"),\n  password: text(\"password\"),\n  role: text(\"role\").$type<\"admin\" | \"customer\">(),\n  createdAt: timestamp(\"created_at\"),\n  updatedAt: timestamp(\"updated_at\"),\n});\n \nexport const userView = pgView(\"user_view\").as(qb.select().from(user));\nexport const customersView = pgView(\"customers_view\").as(qb.select().from(user).where(eq(user.role, \"customer\")));\nCREATE VIEW \"user_view\" AS SELECT * FROM \"user\";\nCREATE VIEW \"customers_view\" AS SELECT * FROM \"user\" WHERE \"role\" = 'customer';\nDeclaring views with raw SQL\n\nWhenever you need to declare view using a syntax that is not supported by the query builder, you can directly use sql operator and explicitly specify view columns schema.\n\n// regular view\nconst newYorkers = pgView('new_yorkers', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  cityId: integer('city_id').notNull(),\n}).as(sql`select * from ${users} where ${eq(users.cityId, 1)}`);\n \n// materialized view\nconst newYorkers = pgMaterializedView('new_yorkers', {\n  id: serial('id').primaryKey(),\n  name: text('name').notNull(),\n  cityId: integer('city_id').notNull(),\n}).as(sql`select * from ${users} where ${eq(users.cityId, 1)}`);\nDeclaring existing views\n\nWhen you're provided with a read only access to an existing view in the database you should use .existing() view configuration, drizzle-kit will ignore and will not generate a create view statement in the generated migration.\n\nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  email: text(\"email\"),\n  password: text(\"password\"),\n  role: text(\"role\").$type<\"admin\" | \"customer\">(),\n  createdAt: timestamp(\"created_at\"),\n  updatedAt: timestamp(\"updated_at\"),\n});\n \n// regular view\nexport const trimmedUser = pgView(\"trimmed_user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  email: text(\"email\"),\n}).existing();\n \n// materialized view won't make any difference, yet you can use it for consistency\nexport const trimmedUser = pgMaterializedView(\"trimmed_user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  email: text(\"email\"),\n}).existing();\nMaterialized views\nPostgreSQL\nMySQL\nSQLite\n\nAccording to the official docs, PostgreSQL has both regular\n(opens in a new tab)\n and materialized\n(opens in a new tab)\n views.\n\nMaterialized views in PostgreSQL use the rule system like views do, but persist the results in a table-like form.\n\nDrizzle ORM natively supports PostgreSQL materialized views:\n\nschema.ts\n \n \nconst newYorkers = pgMaterializedView('new_yorkers').as((qb) => qb.select().from(users).where(eq(users.cityId, 1)));\nCREATE MATERIALIZED VIEW \"new_yorkers\" AS SELECT * FROM \"users\";\n\nYou can then refresh materialized views in the application runtime:\n\nawait db.refreshMaterializedView(newYorkers);\n \nawait db.refreshMaterializedView(newYorkers).concurrently();\n \nawait db.refreshMaterializedView(newYorkers).withNoData();\nExtended example\n‚ÑπÔ∏è\n\nAll the parameters inside the query will be inlined, instead of replaced by $1, $2, etc.\n\n// regular view\nconst newYorkers = pgView('new_yorkers')\n  .with({\n    checkOption: 'cascaded',\n    securityBarrier: true,\n    securityInvoker: true,\n  })\n  .as((qb) => {\n    const sq = qb\n      .$with('sq')\n      .as(\n        qb.select({ userId: users.id, cityId: cities.id })\n          .from(users)\n          .leftJoin(cities, eq(cities.id, users.homeCity))\n          .where(sql`${users.age1} > 18`),\n      );\n    return qb.with(sq).select().from(sq).where(sql`${users.homeCity} = 1`);\n  });\n \n// materialized view\nconst newYorkers2 = pgMaterializedView('new_yorkers')\n  .using('btree')\n  .with({\n    fillfactor: 90,\n    toast_tuple_target: 0.5,\n    autovacuum_enabled: true,\n    ...\n  })\n  .tablespace('custom_tablespace')\n  .withNoData()\n  .as((qb) => {\n    const sq = qb\n      .$with('sq')\n      .as(\n        qb.select({ userId: users.id, cityId: cities.id })\n          .from(users)\n          .leftJoin(cities, eq(cities.id, users.homeCity))\n          .where(sql`${users.age1} > 18`),\n      );\n    return qb.with(sq).select().from(sq).where(sql`${users.homeCity} = 1`);\n  });\nMigrations\nSchemas"
  },
  {
    "title": "Indexes & Constraints",
    "url": "https://orm.drizzle.team/docs/indexes-constraints",
    "html": "Indexes & Constraints\nIndexes & Constraints\nConstraints\n\nSQL constraints are the rules enforced on table columns. They are used to prevent invalid data from being entered into the database.\n\nThis ensures the accuracy and reliability of your data in the database.\n\nDefault\n\nThe DEFAULT clause specifies a default value to use for the column if no value provided by the user when doing an INSERT. If there is no explicit DEFAULT clause attached to a column definition, then the default value of the column is NULL.\n\nAn explicit DEFAULT clause may specify that the default value is NULL, a string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\n\nPostgreSQL\nMySQL\nSQLite\nimport { sql } from \"drizzle-orm\";\nimport { integer, uuid, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n  integer1: integer('integer1').default(42),\n  integer2: integer('integer2').default(sql`'42'::integer`),\n  uuid1: uuid('uuid1').defaultRandom(),\n  uuid2: uuid('uuid2').default(sql`gen_random_uuid()`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n  \"integer1\" integer DEFAULT 42,\n  \"integer2\" integer DEFAULT '42'::integer,\n  \"uuid1\" uuid DEFAULT gen_random_uuid(),\n  \"uuid2\" uuid DEFAULT gen_random_uuid()\n);\nNot null\n\nBy default, a column can hold NULL values. The NOT NULL constraint enforces a column to NOT accept NULL values.\n\nThis enforces a field to always contain a value, which means that you cannot insert a new record, or update a record without adding a value to this field.\n\nPostgreSQL\nMySQL\nSQLite\nimport { integer, sqliteTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n  integer: integer('integer').notNull(),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n  \"integer\" integer NOT NULL,\n);\nUnique\n\nThe UNIQUE constraint ensures that all values in a column are different.\n\nBoth the UNIQUE and PRIMARY KEY constraints provide a guarantee for uniqueness for a column or set of columns.\n\nA PRIMARY KEY constraint automatically has a UNIQUE constraint.\n\n‚ÑπÔ∏è\n\nYou can have many UNIQUE constraints per table, but only one PRIMARY KEY constraint per table.\n\nPostgreSQL\nMySQL\nSQLite\nimport { integer, text, unique, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable('user', {\n  id: integer('id').unique(),\n});\n \nexport const table = pgTable('table', {\n  id: integer('id').unique('custom_name'),\n});\n \nexport const composite = pgTable('composite_example', {\n  id: integer('id'),\n  name: text('name'),\n}, (t) => ({\n  unq: unique().on(t.id, t.name),\n  unq2: unique('custom_name').on(t.id, t.name)\n}));\n \n// In Postgres 15.0+ NULLS NOT DISTINCT is available\n// This example demonstrates both available usages\nexport const userNulls = pgTable('user_nulls_example', {\n  id: integer('id').unique(\"custom_name\", { nulls: 'not distinct' }),\n}, (t) => ({\n  unq: unique().on(t.id).nullsNotDistinct()\n}));\nCREATE TABLE IF NOT EXISTS \"composite_example\" (\n  \"id\" integer,\n  \"name\" text,\n  CONSTRAINT \"composite_example_id_name_unique\" UNIQUE(\"id\",\"name\"),\n  CONSTRAINT \"custom_name\" UNIQUE(\"id\",\"name\")\n);\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"id\" integer,\n\tCONSTRAINT \"custom_name\" UNIQUE(\"id\")\n);\n \nCREATE TABLE IF NOT EXISTS \"user\" (\n\t\"id\" integer,\n\tCONSTRAINT \"user_id_unique\" UNIQUE(\"id\")\n);\n \nCREATE TABLE IF NOT EXISTS \"user_nulls_example\" (\n  \"id\" integer,\n  CONSTRAINT \"custom_name\" UNIQUE NULLS NOT DISTINCT(\"id\"),\n  CONSTRAINT \"user_nulls_example_id_unique\" UNIQUE NULLS NOT DISTINCT(\"id\")\n);\nCheck\n\nThe CHECK constraint is used to limit the value range that can be placed in a column.\n\nIf you define a CHECK constraint on a column it will allow only certain values for this column.\n\nIf you define a CHECK constraint on a table it can limit the values in certain columns based on values in other columns in the row.\n\nüõë\n\nNOT YET IMPLEMENTED IN DRIZZLE ORM\n\nPrimary Key\n\nThe PRIMARY KEY constraint uniquely identifies each record in a table.\nPrimary keys must contain UNIQUE values, and cannot contain NULL values.\n\nA table can have only ONE primary key; and in the table, this primary key can consist of single or multiple columns (fields).\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, pgTable } from \"drizzle-orm/pg-core\";\n \nconst user = pgTable('user', {\n  id: serial('id').primaryKey(),\n});\n \nconst table = pgTable('table', {\n  id: text('cuid').primaryKey(),\n});\nCREATE TABLE IF NOT EXISTS \"user\" (\n  \"id\" serial PRIMARY KEY,\n);\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n  \"cuid\" text PRIMARY KEY,\n);\nComposite Primary Key\n\nJust like PRIMARY KEY, composite primary key uniquely each record in a table using multiple fields.\n\nDrizzle ORM provides a standalone primaryKey operator for that:\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, integer, primaryKey, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\").primaryKey(),\n  name: text(\"name\"),\n});\n \nexport const book = pgTable(\"book\", {\n  id: serial(\"id\").primaryKey(),\n  name: text(\"name\"),\n});\n \nexport const booksToAuthors = pgTable(\"books_to_authors\", {\n  authorId: integer(\"author_id\"),\n  bookId: integer(\"book_id\"),\n}, (table) => {\n  return {\n    pk: primaryKey({ columns: [table.bookId, table.authorId] }),\n    pkWithCustomName: primaryKey({ name: 'custom_name', columns: [table.bookId, table.authorId] }),\n  };\n});\n...\n \nCREATE TABLE IF NOT EXISTS \"books_to_authors\" (\n  \"author_id\" integer,\n  \"book_id\" integer,\n  PRIMARY KEY(\"book_id\",\"author_id\"),\n);\n \nALTER TABLE \"books_to_authors\" ADD CONSTRAINT \"custom_name\" PRIMARY KEY(\"book_id\",\"author_id\");\nForeign key\n\nThe FOREIGN KEY constraint is used to prevent actions that would destroy links between tables. A FOREIGN KEY is a field (or collection of fields) in one table, that refers to the PRIMARY KEY in another table. The table with the foreign key is called the child table, and the table with the primary key is called the referenced or parent table.\n\nDrizzle ORM provides several ways to declare foreign keys. You can declare them in a column declaration statement:\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, integer, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n});\n \nexport const book = pgTable(\"book\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  authorId: integer(\"author_id\").references(() => user.id)\n});\n\nIf you want to do a self reference, due to a TypeScript limitations you will have to either explicitly set return type for reference callback or user a standalone foreignKey operator.\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, integer, foreignKey, pgTable, AnyPgColumn } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  parentId: integer(\"parent_id\").references((): AnyPgColumn => user.id)\n});\n \n// or\nexport const user = pgTable(\"user\", {\n  id: serial(\"id\"),\n  name: text(\"name\"),\n  parentId: integer(\"parent_id\"),\n}, (table) => {\n  return {\n    parentReference: foreignKey({\n      columns: [table.parentId],\n      foreignColumns: [table.id],\n      name: \"custom_fk\"\n    }),\n  };\n});\n\nTo declare multicolumn foreign keys you can use a dedicated foreignKey operator:\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, foreignKey, pgTable, AnyPgColumn } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  firstName: text(\"firstName\"),\n  lastName: text(\"lastName\"),\n}, (table) => {\n  return {\n    pk: primaryKey({ columns: [table.firstName, table.lastName]}),\n  };\n});\n \nexport const profile = pgTable(\"profile\", {\n  id: serial(\"id\").primaryKey(),\n  userFirstName: text(\"user_first_name\"),\n  userLastName: text(\"user_last_name\"),\n}, (table) => {\n  return {\n    userReference: foreignKey({\n      columns: [table.userFirstName, table.userLastName],\n      foreignColumns: [user.firstName, user.lastName]\n      name: \"custom_fk\"\n    })\n  }\n})\nIndexes\n\nDrizzle ORM provides API for both index and unique index declaration:\n\nPostgreSQL\nMySQL\nSQLite\nimport { serial, text, index, uniqueIndex, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const user = pgTable(\"user\", {\n  id: serial(\"id\").primaryKey(),\n  name: text(\"name\"),\n  email: text(\"email\"),\n}, (table) => {\n  return {\n    nameIdx: index(\"name_idx\").on(table.name),\n    emailIdx: uniqueIndex(\"email_idx\").on(table.email),\n  };\n});\nCREATE TABLE \"user\" (\n  ...\n);\n \nCREATE INDEX \"name_idx\" ON \"user\" (\"name\");\nCREATE UNIQUE INDEX \"email_idx\" ON \"user\" (\"email\");\n‚ö†Ô∏è\n\nAs of now drizzle-kit only supports index name and on() param.\n\nDrizzle ORM provides set of all params for index creation:\n\n// Index declaration reference\nindex('name')\n  .on(table.column1, table.column2, ...) or .onOnly(table.column1, table.column2, ...)\n  .concurrently()\n  .using(sql``) // sql expression\n  .asc() or .desc()\n  .nullsFirst() or .nullsLast()\n  .where(sql``) // sql expression\nSQLite\nMigrations"
  },
  {
    "title": "Migrations",
    "url": "https://orm.drizzle.team/docs/migrations",
    "html": "Migrations\nMigrations\n\nThe most important thing about Drizzle is that you can use its schema as a source of truth for everything else.\ndrizzle-kit is a CLI companion for Drizzle ORM which you can use to generate SQL migrations automatically based on your schema changes or apply those changes directly to the database.\n\nSee detailed docs for extended examples and walk-throughs.\n\nQuick start\nDeclare your schema\nsrc/schema.ts\nimport { index, integer, mysqlTable, bigint, varchar } from 'drizzle-orm/mysql-core';\n \nexport const users = mysqlTable('users', {\n  id: bigint('id', { mode: 'number' }).primaryKey().autoincrement(),\n  fullName: varchar('full_name', { length: 256 }),\n}, (users) => ({\n  nameIdx: index('name_idx').on(users.fullName),\n}));\n \nexport const authOtps = mysqlTable('auth_otp', {\n  id: bigint('id', { mode: 'number' }).primaryKey().autoincrement(),\n  phone: varchar('phone', { length: 256 }),\n  userId: int('user_id').references(() => users.id),\n});\n‚ö†Ô∏è\n\nThe schema files SHOULD NOT contain any runtime logic besides defining your DB schema. In particular, your DB connection should be defined separately. Otherwise, that logic will be executed whenever you run any drizzle-kit commands.\n\nSchema-related type definitions, on the other hand, are allowed and even encouraged, as they are not executed at runtime.\n\nCreate the config\n\nCreate a drizzle.config.ts file in your project root:\n\ndrizzle.config.ts\nimport 'dotenv/config';\nimport type { Config } from 'drizzle-kit';\n \nexport default {\n\tschema: './src/schema.ts',\n\tout: './drizzle/migrations',\n\tdriver: 'mysql2', // 'pg' | 'mysql2' | 'better-sqlite' | 'libsql' | 'turso'\n\tdbCredentials: {\n    host: process.env.DB_HOST,\n    user: process.env.DB_USER,\n    password: process.env.DB_PASSWORD,\n    database: process.env.DB_NAME,\n\t},\n} satisfies Config;\nGenerate the migration\npnpm drizzle-kit generate:mysql\n\nThis will generate a migration SQL file:\n\ndrizzle/migrations/0000_better_than_prisma.sql\nCREATE TABLE `users` (\n `id` bigint primary key auto_increment,\n `full_name` varchar(256)\n);\n \n \nCREATE TABLE `auth_otp` (\n `id` bigint primary key auto_increment,\n `phone` varchar(256),\n `user_id` int\n);\n \n \nALTER TABLE auth_otp ADD CONSTRAINT auth_otp_user_id_users_id_fk FOREIGN KEY (`user_id`) REFERENCES users(`id`) ;\nCREATE INDEX name_idx ON users (`full_name`);\nRun the migrations\n\nDrizzle ORM is designed to be an opt-in solution at any point of your development flow. You can either run the generated migrations via Drizzle, or treat them as generic SQL migrations and run them with any other tool.\n\nTo run the migrations with Drizzle, you can use the migrate() helper, available for every supported driver:\n\nsrc/db.ts\nimport { drizzle } from 'drizzle-orm/mysql2';\nimport mysql from 'mysql2/promise';\nimport * as schema from './schema';\n \nexport const connection = mysql.createConnection({\n  host: process.env.DB_HOST,\n  user: process.env.DB_USER,\n  password: process.env.DB_PASSWORD,\n  database: process.env.DB_NAME,\n  multipleStatements: true,\n});\n \nexport const db = drizzle(connection, { schema });\nsrc/migrate.ts\nimport 'dotenv/config';\nimport { migrate } from 'drizzle-orm/mysql2/migrator';\nimport { db, connection } from './db';\n \n// This will run migrations on the database, skipping the ones already applied\nawait migrate(db, { migrationsFolder: './drizzle' });\n \n// Don't forget to close the connection, otherwise the script will hang\nawait connection.end();\npnpm tsx src/migrate.ts\nIndexes & Constraints\nViews"
  },
  {
    "title": "SQLite column types",
    "url": "https://orm.drizzle.team/docs/column-types/sqlite",
    "html": "Column types\nSQLite\nSQLite column types\n\nBased on the official SQLite docs\n(opens in a new tab)\n, each value stored in an SQLite database (or manipulated by the database engine) has one of the following storage classes NULL, INTEGER, REAL, TEXT and BLOB.\n\nWe have native support for all of them, yet if that's not enough for you, feel free to create custom types.\n\nInteger\n\nA signed integer, stored in 0, 1, 2, 3, 4, 6, or 8 bytes depending on the magnitude of the value.\n\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\tid: integer('id')\n});\n \n// you can customize integer mode to be number, boolean, timestamp, timestamp_ms\ninteger('id', { mode: 'number' })\ninteger('id', { mode: 'boolean' })\ninteger('id', { mode: 'timestamp_ms' })\ninteger('id', { mode: 'timestamp' }) // Date\n \nCREATE TABLE `table` (\n\t`id` integer\n);\n// to make integer primary key auto increment\ninteger('id', { mode: 'number' }).primaryKey({ autoIncrement: true })\nCREATE TABLE `table` (\n\t`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL\n);\nReal\n\nA floating point value, stored as an 8-byte IEEE floating point number.\n\nimport { real, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\treal: real('real')\n});\n \nCREATE TABLE `table` (\n\t`real` real\n);\nText\n\nA text string, stored using the database encoding (UTF-8, UTF-16BE or UTF-16LE).\n\n‚ÑπÔ∏è\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\ttext: text('text')\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\ntext('text', { enum: [\"value1\", \"value2\"] })\ntext('text', { mode: 'json' })\ntext('text', { mode: 'json' }).$type<{ foo: string }>()\nCREATE TABLE `table` (\n\t`text` text\n);\nBlob\n\nA blob of data, stored exactly as it was input.\n\n‚ÑπÔ∏è\n\nIt's recommended to use text('', { mode: 'json' }) instead of blob('', { mode: 'json' }), because it supports JSON functions:\n\nAll JSON functions currently throw an error if any of their arguments are BLOBs because BLOBs are reserved for a future enhancement in which BLOBs will store the binary encoding for JSON.\n\nSee https://www.sqlite.org/json1.html\n(opens in a new tab)\n.\n\nimport { blob, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\tblob: blob('blob')\n});\n \nblob('blob')\nblob('blob', { mode: 'buffer' })\nblob('blob', { mode: 'bigint' })\n \nblob('blob', { mode: 'json' })\nblob('blob', { mode: 'json' }).$type<{ foo: string }>()\n \nCREATE TABLE `table` (\n\t`blob` blob\n);\n\nYou can specify .$type<..>() for blob inference, it won't check runtime values. It provides compile time protection for default values, insert and select schemas.\n\n// will be infered as { foo: string }\njson: blob('json', { mode: 'json' }).$type<{ foo: string }>();\n \n// will be infered as string[]\njson: blob('json', { mode: 'json' }).$type<string[]>();\n \n// won't compile\njson: blob('json', { mode: 'json' }).$type<string[]>().default({});\nBoolean\n\nSQLite does not have native boolean data type, yet you can specify integer column to be in a boolean mode. This allows you to operate boolean values in your code and Drizzle stores them as 0 and 1 integer values in the database.\n\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\tid: integer('id', { mode: 'boolean' })\n});\nCREATE TABLE `table` (\n\t`id` integer\n);\nBigint\n\nSince there is no bigint data type in SQLite, Drizzle offers a special bigint mode for blob columns. This mode allows you to work with BigInt instances in your code, and Drizzle stores them as blob values in the database.\n\nimport { blob, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\tid: blob('id', { mode: 'bigint' })\n});\n \nCREATE TABLE `table` (\n\t`id` blob\n);\nCustomizing column data type\n\nEvery column builder has a .$type() method, which allows you to customize the data type of the column. This is useful, for example, with unknown or branded types.\n\ntype UserId = number & { __brand: 'user_id' };\ntype Data = {\n\tfoo: string;\n\tbar: number;\n};\n \nconst users = sqliteTable('users', {\n  id: integer('id').$type<UserId>().primaryKey(),\n  jsonField: blob('json_field').$type<Data>(),\n});\nColumns constraints\nNot null\n\nNOT NULL constraint dictates that the associated column may not contain a NULL value.\n\nconst table = sqliteTable('table', { \n\tnumInt: integer('numInt').notNull() \n});\nCREATE TABLE table (\n\t`numInt` integer NOT NULL\n);\nDefault value\n\nThe DEFAULT clause specifies a default value to use for the column if no value is explicitly provided by the user when doing an INSERT. If there is no explicit DEFAULT clause attached to a column definition, then the default value of the column is NULL.\n\nAn explicit DEFAULT clause may specify that the default value is NULL, a string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\n\nimport { sql } from \"drizzle-orm\";\nimport { integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable('table', {\n\tint1: integer('int1').default(42),\n\tint2: integer('int2').default(sql`(abs(42))`)\n});\n \nCREATE TABLE `table` (\n\t`int1` integer DEFAULT 42\n\t`int2` integer DEFAULT (abs(42))\n);\n\nA default value may also be one of the special case-independent keywords CURRENT_TIME, CURRENT_DATE or CURRENT_TIMESTAMP.\n\nimport { sql } from \"drizzle-orm\";\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst table = sqliteTable(\"table\", {\n  time: text(\"time\").default(sql`CURRENT_TIME`),\n  date: text(\"date\").default(sql`CURRENT_DATE`),\n  timestamp: text(\"timestamp\").default(sql`CURRENT_TIMESTAMP`),\n});\nCREATE TABLE `table` (\n\t`time` text DEFAULT CURRENT_TIME\n\t`date` text DEFAULT CURRENT_DATE\n\t`timestamp` text DEFAULT CURRENT_TIMESTAMP\n);\n\nWhen using $default() or $defaultFn(), which are simply different aliases for the same function, you can generate defaults at runtime and use these values in all insert queries. These functions can assist you in utilizing various implementations such as uuid, cuid, cuid2, and many more.\n\n‚ÑπÔ∏è\n\nNote: This value does not affect the drizzle-kit behavior, it is only used at runtime in drizzle-orm\n\nimport { text, sqliteTable } from \"drizzle-orm/sqlite-core\";\nimport { createId } from '@paralleldrive/cuid2';\n \nconst table = sqliteTable('table', {\n\tid: text('id').$defaultFn(() => createId()),\n});\nMySQL\nIndexes & Constraints"
  },
  {
    "title": "MySQL column types",
    "url": "https://orm.drizzle.team/docs/column-types/mysql",
    "html": "Column types\nMySQL\nMySQL column types\n\nWe have native support for all of them, yet if that's not enough for you, feel free to create custom types.\n\nInteger\n\nA signed integer, stored in 0, 1, 2, 3, 4, 6, or 8 bytes depending on the magnitude of the value.\n\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tid: int('id')\n});\nCREATE TABLE `table` (\n\t`int` int,\n);\ntinyint\nimport { tinyint, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttinyint: tinyint('tinyint')\n});\nCREATE TABLE `table` (\n\t`tinyint` tinyint,\n);\nsmallint\nimport { smallint, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tsmallint: smallint('smallint')\n});\nCREATE TABLE `table` (\n\t`smallint` smallint,\n);\nmediumint\nimport { mediumint, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tmediumint: mediumint('mediumint')\n});\nCREATE TABLE `table` (\n\t`mediumint` mediumint,\n);\nbigint\nimport { bigint, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tbigint: bigint('bigint', { mode: 'number' })\n\tbigintUnsigned: bigint('bigintU', { mode: 'number', unsigned: true })\n});\n \nbigint('...', { mode: 'number' | 'bigint' });\n \n// You can also specify unsigned option for bigint\nbigint('...', { mode: 'number' | 'bigint', unsigned: true })\nCREATE TABLE `table` (\n\t`bigint` bigint,\n\t`bigintU` bigint unsigned,\n);\nreal\nimport { real, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\treal: real('real')\n});\nCREATE TABLE `table` (\n\t`real` real,\n);\nimport { real, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\trealPrecision: real('real_precision', { precision: 1,}),\n\trealPrecisionScale: real('real_precision_scale', { precision: 1, scale: 1,}),\n});\nCREATE TABLE `table` (\n\t`real_precision` real(1),\n\t`real_precision_scale` real(1, 1),\n);\ndecimal\nimport { decimal, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdecimal: decimal('decimal')\n});\nCREATE TABLE `table` (\n\t`decimal` decimal,\n);\nimport { decimal, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdecimalPrecision: decimal('decimal_precision', { precision: 1,}),\n\tdecimalPrecisionScale: decimal('decimal_precision_scale', { precision: 1, scale: 1,}),\n});\nCREATE TABLE `table` (\n\t`decimal_precision` real(1),\n\t`decimal_precision_scale` real(1, 1),\n);\ndouble\nimport { double, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdouble: double('double')\n});\nCREATE TABLE `table` (\n\t`double` double,\n);\nimport { double, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdoublePrecision: double('double_precision', { precision: 1,}),\n\tdoublePrecisionScale: double('double_precision_scale', { precision: 1, scale: 1,}),\n});\nCREATE TABLE `table` (\n\t`double_precision` real(1),\n\t`double_precision_scale` real(1, 1),\n);\nfloat\nimport { float, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tfloat: float('float')\n});\nCREATE TABLE `table` (\n\t`float` float,\n);\nserial\n\nSERIAL is an alias for BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE.\n\nimport { serial, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tserial: serial('serial')\n});\nCREATE TABLE `table` (\n\t`serial` serial AUTO_INCREMENT,\n);\nbinary\nimport { binary, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tbinary: binary('binary')\n});\nCREATE TABLE `table` (\n\t`binary` binary,\n);\nvarbinary\nimport { varbinary, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tvarbinary: varbinary('varbinary', { length: 2}),\n});\nCREATE TABLE `table` (\n\t`varbinary` varbinary(2),\n);\nchar\nimport { char, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tchar: char('char'),\n});\nCREATE TABLE `table` (\n\t`char` char,\n);\nvarchar\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nimport { varchar, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tvarchar: varchar('varchar', { length: 2 }),\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\nvarchar: varchar('varchar', { length: 6, enum: [\"value1\", \"value2\"] })\nCREATE TABLE `table` (\n\t`varchar` varchar(2),\n);\ntext\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nimport { text, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttext: text('text'),\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\ntext: text('text', { enum: [\"value1\", \"value2\"] });\nCREATE TABLE `table` (\n\t`text` text,\n);\nboolean\nimport { boolean, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tboolean: boolean('boolean'),\n});\nCREATE TABLE `table` (\n\t`boolean` boolean,\n);\ndate\nimport { boolean, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdate: date('date'),\n});\nCREATE TABLE `table` (\n\t`date` date,\n);\ndatetime\nimport { datetime, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdatetime: datetime('datetime'),\n});\n \ndatetime('...', { mode: 'date' | \"string\"}),\ndatetime('...', { fsp : 0..6}),\nCREATE TABLE `table` (\n\t`datetime` datetime,\n);\nimport { datetime, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tdatetime: datetime('datetime', { mode: 'date', fsp: 6 }),\n});\nCREATE TABLE `table` (\n\t`datetime` datetime(6),\n);\ntime\nimport { time, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttime: time('time'),\n\ttimefsp: time('time_fsp', { fsp: 6 }),\n});\n\t\ntime('...', { fsp: 0..6 }),\nCREATE TABLE `table` (\n\t`time` time,\n\t`time_fsp` time(6),\n);\nyear\nimport { year, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tyear: year('year'),\n});\nCREATE TABLE `table` (\n\t`year` year,\n);\ntimestamp\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttimestamp: timestamp('timestamp'),\n});\n \ntimestamp('...', { mode: 'date' | \"string\"}),\ntimestamp('...', { fsp : 0..6}),\nCREATE TABLE `table` (\n\t`timestamp` timestamp,\n);\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttimestamp: timestamp('timestamp', { mode: 'date', fsp: 6 }),\n});\nCREATE TABLE `table` (\n\t`timestamp` timestamp(6),\n);\nimport { timestamp, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\ttimestamp: timestamp('timestamp').defaultNow(),\n});\nCREATE TABLE `table` (\n\t`timestamp` timestamp DEFAULT (now()),\n);\njson\nimport { json, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tjson: json('json'),\n});\n \nCREATE TABLE `table` (\n\t`json` json,\n);\n\nYou can specify .$type<..>() for json object inference, it won't check runtime values. It provides compile time protection for default values, insert and select schemas.\n\n// will be infered as { foo: string }\njson: json('json').$type<{ foo: string }>();\n \n// will be infered as string[]\njson: json('json').$type<string[]>();\n \n// won't compile\njson: json('json').$type<string[]>().default({});\nenumColumn\nimport { mysqlEnum, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tmysqlEnum: mysqlEnum('popularity', ['unknown', 'known', 'popular']),\n});\nCREATE TABLE `table` (\n\t`popularity` enum('unknown','known','popular'),\n);\nCustomizing column data type\n\nEvery column builder has a .$type() method, which allows you to customize the data type of the column. This is useful, for example, with unknown or branded types.\n\ntype UserId = number & { __brand: 'user_id' };\ntype Data = {\n\tfoo: string;\n\tbar: number;\n};\n \nconst users = mysqlTable('users', {\n  id: int('id').$type<UserId>().primaryKey(),\n  jsonField: json('json_field').$type<Data>(),\n});\nColumns constraints\nNot null\n\nNOT NULL constraint dictates that the associated column may not contain a NULL value.\n\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tint: int('int').notNull(),\n});\nCREATE TABLE `table` (\n\t`int` int NOT NULL,\n);\nDefault value\n\nThe DEFAULT clause specifies a default value to use for the column if no value is explicitly provided by the user when doing an INSERT. If there is no explicit DEFAULT clause attached to a column definition, then the default value of the column is NULL.\n\nAn explicit DEFAULT clause may specify that the default value is NULL, a string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\n\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tint: int('int').default(3),\n});\nCREATE TABLE `table` (\n\t`int` int DEFAULT 3,\n);\n\nWhen using $default() or $defaultFn(), which are simply different aliases for the same function, you can generate defaults at runtime and use these values in all insert queries. These functions can assist you in utilizing various implementations such as uuid, cuid, cuid2, and many more.\n\n‚ÑπÔ∏è\n\nNote: This value does not affect the drizzle-kit behavior, it is only used at runtime in drizzle-orm\n\nimport { varchar, mysqlTable } from \"drizzle-orm/mysql-core\";\nimport { createId } from '@paralleldrive/cuid2';\n \nconst table = mysqlTable('table', {\n\tid: varchar('id', { length: 128 }).$defaultFn(() => createId()),\n});\nPrimary key\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tint: int('int').primaryKey(),\n});\nCREATE TABLE `table` (\n\t`int` int PRIMARY KEY NOT NULL,\n);\nAuto increment\nimport { int, mysqlTable } from \"drizzle-orm/mysql-core\";\n \nconst table = mysqlTable('table', {\n\tint: int('int').autoincrement(),\n});\nCREATE TABLE `table` (\n\t`int` int AUTO_INCREMENT\n);\nPostgreSQL\nSQLite"
  },
  {
    "title": "PostgreSQL column types",
    "url": "https://orm.drizzle.team/docs/column-types/pg",
    "html": "Column types\nPostgreSQL\nPostgreSQL column types\n\nWe have native support for all of them, yet if that's not enough for you, feel free to create custom types.\n\ninteger\n\ninteger int int4\nSigned 4-byte integer\n\nIf you need integer autoincrement please refer to serial.\n\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tint: integer('int')\n});\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"int\" integer\n);\nimport { sql } from \"drizzle-orm\";\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tint1: integer('int1').default(10)\n\tint2: integer('int2').default(sql`'10'::int`)\n});\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"int1\" integer DEFAULT 10\n\t\"int2\" integer DEFAULT '10'::int\n);\nsmallint\n\nsmallint int2\nSmall-range signed 2-byte integer\n\nIf you need smallint autoincrement please refer to smallserial.\n\nimport { smallint, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tsmallint: smallint('smallint')\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"smallint\" smallint\n);\nimport { sql } from \"drizzle-orm\";\nimport { smallint, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tsmallint1: smallint('smallint1').default(10)\n\tsmallint2: smallint('smallint2').default(sql`'10'::smallint`)\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"smallint1\" smallint DEFAULT 10\n\t\"smallint2\" smallint DEFAULT '10'::smallint\n);\nbigint\n\nbigint int8\nSigned 8-byte integer\n\nIf you need bigint autoincrement please refer to bigserial.\n\nIf you're expecting values above 2^31 but below 2^53, you can utilise mode: 'number' and deal with javascript number as opposed to bigint.\n\nimport { bigint, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tbigint: bigint('bigint', { mode: 'number' })\n});\n \n// will be inferred as `number`\nbigint: bigint('bigint', { mode: 'number' })\n \n// will be inferred as `bigint`\nbigint: bigint('bigint', { mode: 'bigint' })\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"bigint\" bigint\n);\nimport { sql } from \"drizzle-orm\";\nimport { bigint, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tbigint1: bigint('bigint1').default(10)\n\tbigint2: bigint('bigint2').default(sql`'10'::bigint`)\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"bigint1\" bigint DEFAULT 10\n\t\"bigint2\" bigint DEFAULT '10'::bigint\n);\nserial\n\nserial serial4\nAuto incrementing 4-bytes integer, notational convenience for creating unique identifier columns (similar to the AUTO_INCREMENT property supported by some other databases).\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { serial, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  serial: serial('serial'),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"serial\" serial NOT NULL,\n);\nsmallserial\n\nsmallserial serial2\nAuto incrementing 2-bytes integer, notational convenience for creating unique identifier columns (similar to the AUTO_INCREMENT property supported by some other databases).\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { smallserial, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  smallserial: smallserial('smallserial'),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"smallserial\" smallserial NOT NULL,\n);\nbigserial\n\nbigserial serial8\nAuto incrementing 8-bytes integer, notational convenience for creating unique identifier columns (similar to the AUTO_INCREMENT property supported by some other databases).\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nIf you're expecting values above 2^31 but below 2^53, you can utilise mode: 'number' and deal with javascript number as opposed to bigint.\n\nimport { bigserial, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  bigserial: bigserial('bigserial', { mode: 'number' }),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"bigserial\" bigserial NOT NULL,\n);\nboolean\n\nPostgreSQL provides the standard SQL type boolean.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { boolean, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n\tboolean: boolean('boolean')\n});\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"boolean\" boolean,\n);\ntext\n\ntext\nVariable-length(unlimited) character string.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nimport { text, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  text: text('text')\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\ntext: text('text', { enum: [\"value1\", \"value2\"] })\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"text\" text,\n);\nvarchar\n\ncharacter varying(n) varchar(n)\nVariable-length character string, can store strings up to n characters (not bytes).\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nThe length parameter is optional according to PostgreSQL docs.\n\nimport { varchar, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  varchar1: varchar('varchar1'),\n  varchar1: varchar('varchar2', { length: 256 }),\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\nvarchar: varchar('varchar', { enum: [\"value1\", \"value2\"] }),\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"varchar1\" varchar,\n\t\"varchar2\" varchar(256),\n);\nchar\n\ncharacter(n) char(n)\nFixed-length, blank padded character string, can store strings up to n characters(not bytes).\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nYou can define { enum: [\"value1\", \"value2\"] } config to infer insert and select types, it won't check runtime values.\n\nThe length parameter is optional according to PostgreSQL docs.\n\nimport { char, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  char1: char('char1'),\n  char2: char('char2', { length: 256 }),\n});\n \n// will be inferred as text: \"value1\" | \"value2\" | null\nchar: char('char', { enum: [\"value1\", \"value2\"] }),\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"char1\" char,\n\t\"char2\" char(256),\n);\nnumeric\n\nnumeric decimal\nExact numeric of selectable precision. Can store numbers with a very large number of digits, up to 131072 digits before the decimal point and up to 16383 digits after the decimal point.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { numeric, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const table = pgTable('table', {\n  numeric1: numeric('numeric1'),\n  numeric2: numeric('numeric2', { precision: 100 }),\n  numeric3: numeric('numeric3', { precision: 100, scale: 20 }),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"numeric1\" numeric,\n\t\"numeric2\" numeric(100),\n\t\"numeric3\" numeric(100, 20),\n);\ndecimal\n\nAn alias of numeric.\n\nreal\n\nreal float4\nSingle precision floating-point number (4 bytes)\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { sql } from \"drizzle-orm\";\nimport { real, pgTable } from \"drizzle-orm/pg-core\";  \n \nconst table = pgTable('table', {\n\treal1: real('real1'),\n\treal2: real('real2').default(10.10),\n\treal2: real('real2').default(sql`'10.10'::real`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"real1\" real,\n\t\"real2\" real default 10.10,\n\t\"real2\" real default '10.10'::real\n);\ndouble precision\n\ndouble precision float8\nDouble precision floating-point number (8 bytes)\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { sql } from \"drizzle-orm\";\nimport { doublePrecision, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tdouble1: doublePrecision('double1'),\n\tdouble2: doublePrecision('double2').default(10.10),\n\tdouble3: doublePrecision('double3').default(sql`'10.10'::double precision`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"double1\" double precision,\n\t\"double2\" double precision default 10.10,\n\t\"double3\" double precision default '10.10'::double precision,\n);\njson\n\njson\nTextual JSON data, as specified in RFC 7159.\n(opens in a new tab)\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { sql } from \"drizzle-orm\";\nimport { json, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tjson1: json('json1'),\n\tjson2: json('json2').default({ foo: \"bar\" }),\n\tjson3: json('json3').default(sql`'{foo: \"bar\"}'::json`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"json1\" json,\n\t\"json2\" json default '{\"foo\": \"bar\"}'::json,\n\t\"json3\" json default '{\"foo\": \"bar\"}'::json,\n);\n\nYou can specify .$type<..>() for json object inference, it won't check runtime values. It provides compile time protection for default values, insert and select schemas.\n\n// will be infered as { foo: string }\njson: json('json').$type<{ foo: string }>();\n \n// will be infered as string[]\njson: json('json').$type<string[]>();\n \n// won't compile\njson: json('json').$type<string[]>().default({});\njsonb\n\njsonb\nBinary JSON data, decomposed.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { jsonb, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tjsonb1: jsonb('jsonb1'),\n\tjsonb2: jsonb('jsonb2').default({ foo: \"bar\" }),\n\tjsonb3: jsonb('jsonb3').default(sql`'{foo: \"bar\"}'::jsonb`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"jsonb1\" jsonb,\n\t\"jsonb2\" jsonb default '{\"foo\": \"bar\"}'::jsonb,\n\t\"jsonb3\" jsonb default '{\"foo\": \"bar\"}'::jsonb,\n);\n\nYou can specify .$type<..>() for json object inference, it won't check runtime values. It provides compile time protection for default values, insert and select schemas.\n\n// will be infered as { foo: string }\njsonb: jsonb('jsonb').$type<{ foo: string }>();\n \n// will be infered as string[]\njsonb: jsonb('jsonb').$type<string[]>();\n \n// won't compile\njsonb: jsonb('jsonb').$type<string[]>().default({});\ntime\n\ntime timetz time with timezone time without timezone\nTime of day with or without time zone.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { time, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n  time1: time('time1'),\n  time2: time('time2', { withTimezone: true }),\n  time3: time('time3', { precision: 6 }),\n\ttime4: time('time4', { precision: 6, withTimezone: true })\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"time1\" time,\n\t\"time2\" time with timezone,\n\t\"time3\" time(6),\n\t\"time4\" time(6) with timezone,\n);\ntimestamp\n\ntimestamp timestamptz timestamp with time zone timestamp without time zone\nDate and time with or without time zone.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { sql } from \"drizzle-orm\";\nimport { timestamp, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n  timestamp1: timestamp('timestamp1'),\n\ttimestamp2: timestamp('timestamp2', { precision: 6, withTimezone: true }),\n\ttimestamp3: timestamp('timestamp3').defaultNow(),\n\ttimestamp4: timestamp('timestamp4').default(sql`now()`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"timestamp1\" timestamp,\n\t\"timestamp2\" timestamp (6) with time zone,\n\t\"timestamp3\" timestamp default now(),\n\t\"timestamp4\" timestamp default now(),\n);\n\nYou can specify either date or string infer modes:\n\n// will infer as date\ntimestamp: timestamp('timestamp', { mode: \"date\" }),\n \n// will infer as string\ntimestamp: timestamp('timestamp', { mode: \"string\" }),\ndate\n\ndate\nCalendar date (year, month, day)\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { date, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tdate: date('date'),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"date\" date,\n);\n\nYou can specify either date or string infer modes:\n\n// will infer as date\ndate: date('date', { mode: \"date\" }),\n \n// will infer as string\ndate: date('date', { mode: \"string\" }),\ninterval\n\ninterval\nTime span\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { interval, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tinterval1: interval('interval1'),\n  interval2: interval('interval2', { fields: 'day' }),\n  interval3: interval('interval3', { fields: 'month' , precision: 6 }),\n});\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"interval1\" interval,\n\t\"interval2\" interval day,\n\t\"interval3\" interval(6) month,\n);\nenum\n\nenum enumerated types\nEnumerated (enum) types are data types that comprise a static, ordered set of values. They are equivalent to the enum types supported in a number of programming languages. An example of an enum type might be the days of the week, or a set of status values for a piece of data.\n\nFor more info please refer to the official PostgreSQL docs.\n(opens in a new tab)\n\nimport { pgEnum, pgTable } from \"drizzle-orm/pg-core\";\n \nexport const moodEnum = pgEnum('mood', ['sad', 'ok', 'happy']);\n \nexport const table = pgTable('table', {\n  mood: moodEnum('mood'),\n});\nCREATE TYPE mood AS ENUM ('sad', 'ok', 'happy');\n \nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"mood\" mood,\n);\nCustomizing column data type\n\nEvery column builder has a .$type() method, which allows you to customize the data type of the column.\n\nThis is useful, for example, with unknown or branded types:\n\ntype UserId = number & { __brand: 'user_id' };\ntype Data = {\n\tfoo: string;\n\tbar: number;\n};\n \nconst users = pgTable('users', {\n  id: serial('id').$type<UserId>().primaryKey(),\n  jsonField: json('json_field').$type<Data>(),\n});\nConstraints & defaults\nDefault value\n\nThe DEFAULT clause specifies a default value to use for the column if no value is explicitly provided by the user when doing an INSERT. If there is no explicit DEFAULT clause attached to a column definition, then the default value of the column is NULL.\n\nAn explicit DEFAULT clause may specify that the default value is NULL, a string constant, a blob constant, a signed-number, or any constant expression enclosed in parentheses.\n\nimport { sql } from \"drizzle-orm\";\nimport { integer, pgTable, uuid } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tinteger1: integer('integer1').default(42),\n\tinteger2: integer('integer2').default(sql`'42'::integer`),\n\tuuid1: uuid('uuid1').defaultRandom(),\n\tuuid2: uuid('uuid2').default(sql`gen_random_uuid()`),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"integer1\" integer DEFAULT 42,\n\t\"integer2\" integer DEFAULT '42'::integer,\n\t\"uuid1\" uuid DEFAULT gen_random_uuid(),\n\t\"uuid2\" uuid DEFAULT gen_random_uuid()\n);\n\nWhen using $default() or $defaultFn(), which are simply different aliases for the same function, you can generate defaults at runtime and use these values in all insert queries.\n\nThese functions can assist you in utilizing various implementations such as uuid, cuid, cuid2, and many more.\n\n‚ÑπÔ∏è\n\nNote: This value does not affect the drizzle-kit behavior, it is only used at runtime in drizzle-orm\n\nimport { text, pgTable } from \"drizzle-orm/pg-core\";\nimport { createId } from '@paralleldrive/cuid2';\n \nconst table = pgTable('table', {\n\tid: text('id').$defaultFn(() => createId()),\n});\nNot null\n\nNOT NULL constraint dictates that the associated column may not contain a NULL value.\n\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tinteger: integer('integer').notNull(),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"integer\" integer NOT NULL,\n);\nPrimary key\n\nA primary key constraint indicates that a column, or group of columns, can be used as a unique identifier for rows in the table. This requires that the values be both unique and not null.\n\nimport { integer, pgTable } from \"drizzle-orm/pg-core\";\n \nconst table = pgTable('table', {\n\tid: serial('id').primaryKey(),\n});\nCREATE TABLE IF NOT EXISTS \"table\" (\n\t\"integer\" serial PRIMARY KEY NOT NULL,\n);\nOverview\nMySQL"
  },
  {
    "title": "SQL schema declaration",
    "url": "https://orm.drizzle.team/docs/sql-schema-declaration",
    "html": "Overview\nSQL schema declaration\n\nYou can declare your SQL schema directly in TypeScript either in a single schema.ts file, or you can spread them around ‚Äî whichever you prefer, all the freedom!\n\n1 File\nSeparate Files\nSeparate Folders\n\nEverything in 1 file:\n\nüì¶ <project root>\n‚îî üìÇ src\n‚îî üìÇ db\n   ‚îî üìú schema.ts\n\nYou can declare tables, indexes and constraints, foreign keys and enums.\n\n‚ö†Ô∏è\n\nPay attention to the mandatory export keyword, if you're using drizzle-kit SQL migrations generator.\n\nPostgreSQL\nMySQL\nSQLite\nimport { integer, pgEnum, pgTable, serial, uniqueIndex, varchar } from 'drizzle-orm/pg-core';\n \n// declaring enum in database\nexport const popularityEnum = pgEnum('popularity', ['unknown', 'known', 'popular']);\n \nexport const countries = pgTable('countries', {\n  id: serial('id').primaryKey(),\n  name: varchar('name', { length: 256 }),\n}, (countries) => {\n  return {\n    nameIndex: uniqueIndex('name_idx').on(countries.name),\n  }\n});\n \nexport const cities = pgTable('cities', {\n  id: serial('id').primaryKey(),\n  name: varchar('name', { length: 256 }),\n  countryId: integer('country_id').references(() => countries.id),\n  popularity: popularityEnum('popularity'),\n});\n\nDatabase and table explicit entity types:\n\nimport { pgTable, serial, text, varchar } from 'drizzle-orm/pg-core';\nimport { drizzle } from 'drizzle-orm/node-postgres';\n \nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  fullName: text('full_name'),\n  phone: varchar('phone', { length: 256 }),\n});\n \nexport type User = typeof users.$inferSelect; // return type when queried\nexport type NewUser = typeof users.$inferInsert; // insert type\n...\n \nconst db = drizzle(...);\n \nconst result: User[] = await db.select().from(users);\n \nexport async function insertUser(user: NewUser): Promise<User[]> {\n  return db.insert(users).values(user).returning();\n}\n\nCheck out all supported PostgreSQL column types here.\n\nPostgreSQL column types\nMySQL column types\nSQLite column types\nHTTP proxy\nPostgreSQL"
  },
  {
    "title": "HTTP proxy",
    "url": "https://orm.drizzle.team/docs/quick-sqlite/http-proxy",
    "html": "SQLite\nHTTP proxy\nHTTP proxy\nconst db = drizzle(async (sql, params, method) => {\n  try {\n    const rows = await axios.post('http://localhost:3000/query', { sql, params, method });\n \n    return { rows: rows.data };\n  } catch (e: any) {\n    console.error('Error from sqlite proxy server: ', e.response.data)\n    return { rows: [] };\n  }\n});\n\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\n\nimport { sql } from \"drizzle-orm\";\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst users = sqliteTable('users', {\n  id: text('id'),\n  textModifiers: text('text_modifiers').notNull().default(sql`CURRENT_TIMESTAMP`),\n  intModifiers: integer('int_modifiers', { mode: 'boolean' }).notNull().default(false),\n});\n\nFor more details about column types, see the SQLite column types in Drizzle.\n\nbetter-sqlite3\nOverview"
  },
  {
    "title": "BetterSqlite3",
    "url": "https://orm.drizzle.team/docs/quick-sqlite/better-sqlite3",
    "html": "SQLite\nbetter-sqlite3\nBetterSqlite3\n\nAccording to the official docs\n(opens in a new tab)\n, BetterSqlite3 is the fastest and simplest library for SQLite3 in Node.js.\n\nDrizzle ORM embraces SQL dialects and dialect specific drivers and syntax and unlike any other ORM, for synchronous drivers like better-sqlite3 both async and sync APIs and we mirror most popular SQLite-like all, get, values and run query methods syntax.\n\nnpm\npnpm\nyarn\nbun\nnpm install drizzle-orm better-sqlite3\nnpm install -D drizzle-kit \nimport { drizzle } from 'drizzle-orm/better-sqlite3';\nimport Database from 'better-sqlite3';\n \nconst sqlite = new Database('sqlite.db');\nconst db = drizzle(sqlite);\n \nconst result = await db.select().from(users);\n\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\n\nimport { sql } from \"drizzle-orm\";\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst users = sqliteTable('users', {\n  id: text('id'),\n  textModifiers: text('text_modifiers').notNull().default(sql`CURRENT_TIMESTAMP`),\n  intModifiers: integer('int_modifiers', { mode: 'boolean' }).notNull().default(false),\n});\n\nFor more details about column types, see the SQLite column types in Drizzle.\n\n‚ÑπÔ∏è\n\nIf your db.insert() returns data, append all() to your query, otherwise append run()\n\nIf you want to use sync APIs:\n\nimport { drizzle, BetterSQLite3Database } from 'drizzle-orm/bun-sqlite';\nimport Database from 'better-sqlite3';\n \nconst sqlite = new Database('sqlite.db');\nconst db: BetterSQLite3Database = drizzle(sqlite);\n \nconst result = db.select().from(users).all();\nconst result = db.select().from(users).get();\nconst result = db.select().from(users).values();\nconst result = db.select().from(users).run();\n\nMore on sync and async APIs for sqlite - read here.\n\nbun:sqlite\nHTTP proxy"
  },
  {
    "title": "Bun SQLite",
    "url": "https://orm.drizzle.team/docs/quick-sqlite/bun",
    "html": "SQLite\nbun:sqlite\nBun SQLite\n\nAccording to the official website\n(opens in a new tab)\n, Bun is a fast all-in-one JavaScript runtime.\n\nDrizzle ORM natively supports bun:sqlite\n(opens in a new tab)\n module and it's crazy fast üöÄ\n\nWe embraces SQL dialects and dialect specific drivers and syntax and unlike any other ORM, for synchronous drivers like bun:sqlite we have both async and sync APIs and we mirror most popular SQLite-like all, get, values and run query methods syntax.\n\nbun\nnpm\npnpm\nyarn\nbun add drizzle-orm\nbun add -d drizzle-kit \nimport { drizzle } from 'drizzle-orm/bun-sqlite';\nimport { Database } from 'bun:sqlite';\n \nconst sqlite = new Database('sqlite.db');\nconst db = drizzle(sqlite);\n \nconst result = await db.select().from(users);\n\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\n\nimport { sql } from \"drizzle-orm\";\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst users = sqliteTable('users', {\n  id: text('id'),\n  textModifiers: text('text_modifiers').notNull().default(sql`CURRENT_TIMESTAMP`),\n  intModifiers: integer('int_modifiers', { mode: 'boolean' }).notNull().default(false),\n});\n\nFor more details about column types, see the SQLite column types in Drizzle.\n\nIf you want to use sync APIs:\n\nimport { drizzle } from 'drizzle-orm/bun-sqlite';\nimport { Database } from 'bun:sqlite';\n \nconst sqlite = new Database('sqlite.db');\nconst db = drizzle(sqlite);\n \nconst result = db.select().from(users).all();\nconst result = db.select().from(users).get();\nconst result = db.select().from(users).values();\nconst result = db.select().from(users).run();\n\nMore on sync and async APIs for sqlite - read here.\n\nCloudflare D1\nbetter-sqlite3"
  },
  {
    "title": "Cloudflare D1",
    "url": "https://orm.drizzle.team/docs/quick-sqlite/d1",
    "html": "SQLite\nCloudflare D1\nCloudflare D1\n\nAccording to the official website\n(opens in a new tab)\n, D1 is Cloudflare's first queryable relational database.\n\nDrizzle ORM fully supports the Cloudflare D1 database and Cloudflare Workers environment. We embrace SQL dialects and dialect specific drivers and syntax and mirror most popular SQLite-like all, get, values and run query methods syntax.\n\nTo setup project for your Cloudflare D1 please refer to official docs.\n(opens in a new tab)\n\n## your wrangler.toml will look something like this:\n \nname = \"YOUR PROJECT NAME\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2022-11-07\"\nnode_compat = true\n \n[[ d1_databases ]]\nbinding = \"DB\"\ndatabase_name = \"YOUR DB NAME\"\ndatabase_id = \"YOUR DB ID\"\n\nInitialize local database and run server locally:\n\nwrangler d1 execute <DATABASE_NAME> --local --file=./drizzle/0000_short_lockheed.sql\nwrangler dev # on wrangler versions below 3.0.0, add the --local and --persist flags\n\nInstall Drizzle ORM:\n\nnpm\npnpm\nyarn\nbun\nnpm install drizzle-orm\nnpm install -D drizzle-kit \n\nMake your first D1 query:\n\nimport { drizzle } from 'drizzle-orm/d1';\n \nexport interface Env {\n  <BINDING_NAME>: D1Database;\n}\n \nexport default {\n  async fetch(request: Request, env: Env) {\n    const db = drizzle(env.<BINDING_NAME>);\n    const result = await db.select().from(users).all()\n    return Response.json(results);\n  },\n};\n\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\n\nimport { sql } from \"drizzle-orm\";\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst users = sqliteTable('users', {\n  id: text('id'),\n  textModifiers: text('text_modifiers').notNull().default(sql`CURRENT_TIMESTAMP`),\n  intModifiers: integer('int_modifiers', { mode: 'boolean' }).notNull().default(false),\n});\n\nFor more details about column types, see the SQLite column types in Drizzle.\n\nTurso\nbun:sqlite"
  },
  {
    "title": "Turso",
    "url": "https://orm.drizzle.team/docs/quick-sqlite/turso",
    "html": "SQLite\nTurso\nTurso\n\nAccording to the official website\n(opens in a new tab)\n, Turso is a libSQL\n(opens in a new tab)\n powered edge SQLite database as a service.\n\nDrizzle ORM natively supports libSQL driver, we embrace SQL dialects and dialect specific drivers and syntax and mirror most popular SQLite-like all, get, values and run query methods syntax.\n\nnpm\npnpm\nyarn\nbun\nnpm install drizzle-orm @libsql/client\nnpm install -D drizzle-kit \nimport { drizzle } from 'drizzle-orm/libsql';\nimport { createClient } from '@libsql/client';\n \nconst client = createClient({ url: 'DATABASE_URL', authToken: 'DATABASE_AUTH_TOKEN' });\n \nconst db = drizzle(client);\n \nconst result = await db.select().from(users).all()\n\nUnless you plan on writing every SQL query by hand, a table declaration is helpful:\n\nimport { sql } from \"drizzle-orm\";\nimport { text, integer, sqliteTable } from \"drizzle-orm/sqlite-core\";\n \nconst users = sqliteTable('users', {\n  id: text('id'),\n  textModifiers: text('text_modifiers').notNull().default(sql`CURRENT_TIMESTAMP`),\n  intModifiers: integer('int_modifiers', { mode: 'boolean' }).notNull().default(false),\n});\n\nFor more details about column types, see the SQLite column types in Drizzle.\n\nSQLite\nCloudflare D1"
  },
  {
    "title": "Quick Sqlite",
    "url": "https://orm.drizzle.team/docs/quick-sqlite",
    "html": "SQLite\nSQLite\nTurso\nTurso is an edge SQLite database\nCloudflare D1\nD1 is Cloudflare's first queryable relational database\nBun SQLite\nFast all-in-one JavaScript runtime\nbetter-sqlite3\nLibrary for SQLite3 in Node.js\nSQLite HTTP proxy\nSQLite3 HTTP proxy implementation\nHTTP proxy\nTurso"
  },
  {
    "title": "HTTP proxy",
    "url": "https://orm.drizzle.team/docs/quick-mysql/http-proxy",
    "html": "MySQL\nHTTP proxy\nHTTP proxy\n\nExample of driver implementation\n\nimport { drizzle } from 'drizzle-orm/mysql-proxy';\n \nconst db = drizzle(async (sql, params, method) => {\n  try {\n    const rows = await axios.post('http://localhost:3000/query', { sql, params, method });\n \n    return { rows: rows.data };\n  } catch (e: any) {\n    console.error('Error from mysql proxy server: ', e.response.data)\n    return { rows: [] };\n  }\n});\n\nExample of server implementation\n\nimport * as mysql from 'mysql2/promise';\nimport express from 'express';\n \nconst app = express();\n \napp.use(express.json());\nconst port = 3000;\n \nconst main = async () => {\n    const connection = await mysql.createConnection('mysql://root:mysql@127.0.0.1:5432/drizzle');\n \n    app.post('/query', async (req, res) => {\n    \tconst { sql, params, method } = req.body;\n \n      // prevent multiple queries\n    \tconst sqlBody = sql.replace(/;/g, '');\n \n      try {\n            const result = await connection.query({\n                sql: sqlBody,\n                values: params,\n                rowsAsArray: method === 'all',\n                typeCast: function(field: any, next: any) {\n                    if (field.type === 'TIMESTAMP' || field.type === 'DATETIME' || field.type === 'DATE') {\n                        return field.string();\n                    }\n                    return next();\n                },\n            });\n    \t} catch (e: any) {\n    \t\tres.status(500).json({ error: e });\n    \t}\n \n    \tif (method === 'all') {\n    \t\tres.send(result[0]);\n    \t} else if (method === 'execute') {\n    \t\tres.send(result);\n    \t}\n    \tres.status(500).json({ error: 'Unknown method value' });\n    });\n \n    app.listen(port, () => {\n    \tconsole.log(`Example app listening on port ${port}`);\n    });\n}\n \nmain();\nMySQL 2\nSQLite"
  },
  {
    "title": "Node MySQL 2",
    "url": "https://orm.drizzle.team/docs/quick-mysql/mysql2",
    "html": "MySQL\nMySQL 2\nNode MySQL 2\n\nAccording to the official website\n(opens in a new tab)\n, mysql2 is a MySQL client for Node.js with focus on performance.\n\nDrizzle ORM natively supports mysql2 with drizzle-orm/mysql2 package.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm mysql2\nnpm i -D drizzle-kit\n\nThere're two ways you can connect to the MySQL with mysql2 driver, either single client connection or a pool.\n\nClient connection\nPool connection\nindex.ts\nimport { drizzle } from \"drizzle-orm/mysql2\";\nimport mysql from \"mysql2/promise\";\n \nconst connection = await mysql.createConnection({\n  host: \"host\",\n  user: \"user\",\n  database: \"database\",\n  ...\n});\n \nconst db = drizzle(connection);\n‚öôÔ∏è\n\nFor the built in migrate function with DDL migrations we and drivers strongly encourage you to use single client connection.\n\nFor querying purposes feel free to use either client or pool based on your business demands.\n\nPlanetScale\nHTTP proxy"
  },
  {
    "title": "PlanetScale",
    "url": "https://orm.drizzle.team/docs/quick-mysql/planetscale",
    "html": "MySQL\nPlanetScale\nPlanetScale\n\nAccording to the official website\n(opens in a new tab)\n, PlanetScale is the world's most advanced serverless MySQL platform.\n\nWith Drizzle ORM you can access PlanetScale over http through their official database-js\n(opens in a new tab)\n driver from serverless and serverfull environments with our drizzle-orm/planetscale-serverless package.\n\nYou can also access PlanetScale through TCP with mysql2 driver ‚Äî see here.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @planetscale/database\nnpm i -D drizzle-kit\nindex.ts\nimport { drizzle } from \"drizzle-orm/planetscale-serverless\";\nimport { connect } from \"@planetscale/database\";\n \n// create the connection\nconst connection = connect({\n  host: process.env[\"DATABASE_HOST\"],\n  username: process.env[\"DATABASE_USERNAME\"],\n  password: process.env[\"DATABASE_PASSWORD\"],\n});\n \nconst db = drizzle(connection);\n\nMake sure to checkout the PlanetScale official MySQL courses\n(opens in a new tab)\n, we think they're outstanding üôå\n\nMySQL\nMySQL 2"
  },
  {
    "title": "Quick Mysql",
    "url": "https://orm.drizzle.team/docs/quick-mysql",
    "html": "MySQL\nMySQL\nPlanetScale\nWorld's most advanced serverless MySQL platform\nMySQL 2\nMySQL client for Node.js with focus on performance\nMySQL HTTP proxy\nMySQL HTTP proxy implementation\nHTTP proxy\nPlanetScale"
  },
  {
    "title": "HTTP proxy",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/http-proxy",
    "html": "PostgreSQL\nHTTP proxy\nHTTP proxy\n\nExample of driver implementation\n\nimport { drizzle } from 'drizzle-orm/pg-proxy';\n \nconst db = drizzle(async (sql, params, method) => {\n  try {\n    const rows = await axios.post('http://localhost:3000/query', { sql, params, method });\n \n    return { rows: rows.data };\n  } catch (e: any) {\n    console.error('Error from pg proxy server: ', e.response.data)\n    return { rows: [] };\n  }\n});\n\nExample of server implementation\n\nimport { Client } from 'pg';\nimport express from 'express';\n \nconst app = express();\n \napp.use(express.json());\nconst port = 3000;\n \nconst client = new Client('postgres://postgres:postgres@localhost:5432/postgres');\n \napp.post('/query', async (req, res) => {\n\tconst { sql, params, method } = req.body;\n \n\t// prevent multiple queries\n\tconst sqlBody = sql.replace(/;/g, '');\n \n    try {\n        const result = await client.query({\n            text: sqlBody,\n            values: params,\n            rowMode: method === 'all' ? 'array': undefined,\n        });\n\t\tres.send(result.rows);\n\t} catch (e: any) {\n\t\tres.status(500).json({ error: e });\n\t}\n \n\tres.status(500).json({ error: 'Unknown method value' });\n});\n \napp.listen(port, () => {\n\tconsole.log(`Example app listening on port ${port}`);\n});\nAWS Data API\nMySQL"
  },
  {
    "title": "AWS Data API",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/aws-data-api",
    "html": "PostgreSQL\nAWS Data API\nAWS Data API\n\nDrizzle ORM natively supports aws-sdk driver with drizzle-orm/aws-data-api package.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @aws-sdk/client-rds-data @aws-sdk/credential-providers\nnpm i -D drizzle-kit\nindex.ts\nimport { drizzle } from 'drizzle-orm/aws-data-api/pg';\nimport { RDSDataClient } from '@aws-sdk/client-rds-data';\nimport { fromIni } from '@aws-sdk/credential-providers';\n \nconst rdsClient = new RDSDataClient({\n  \tcredentials: fromIni({ profile: process.env['PROFILE'] }),\n\t\tregion: 'us-east-1',\n});\n \nconst db = drizzle(rdsClient, {\n  database: process.env['DATABASE']!,\n  secretArn: process.env['SECRET_ARN']!,\n  resourceArn: process.env['RESOURCE_ARN']!,\n});\n \nawait db.select().from(...)...;\nSupabase\nHTTP proxy"
  },
  {
    "title": "Supabase",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/supabase",
    "html": "PostgreSQL\nSupabase\nSupabase\n\nAccording to the official website\n(opens in a new tab)\n, Supabase is an open source Firebase alternative for building secure and performant Postgres backends with minimal configuration.\n\nCheckout official Supabase + Drizzle\n(opens in a new tab)\n docs.\n\nInstall dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm postgres\nnpm i -D drizzle-kit\nCreate your models\nschema.ts\nimport { pgTable, serial, text, varchar } from \"drizzle-orm/pg-core\";\n \nexport const users = pgTable('users', {\n  id: serial('id').primaryKey(),\n  fullName: text('full_name'),\n  phone: varchar('phone', { length: 256 }),\n});\nMake your first query\nindex.ts\nimport { drizzle } from 'drizzle-orm/postgres-js'\nimport postgres from 'postgres'\nimport { users } from './schema'\n \nconst connectionString = process.env.DATABASE_URL\nconst client = postgres(connectionString)\nconst db = drizzle(client);\n \nconst allUsers = await db.select().from(users);\n\nConnect to your database using the Connection Pooler for serverless environments, and the Direct Connection for long-running servers.\n\nUsage with Cloudflare Workers\n\nNow that Cloudflare Workers supports TCP connections, you can use node-postgres to connect to Supabase's connection pooler.\n\nworker.ts\nimport { Pool } from \"pg\";\nimport { drizzle } from \"drizzle-orm/node-postgres\";\n \nexport default {\n  async fetch(req, env, ctx) {\n    const pool = new Pool({ connectionString: env.DATABASE_URL });\n    const db = drizzle(pool)\n    const result = await db.select().from(...);\n    ctx.waitUntil(pool.end());\n    return new Response(now);\n  }\n}\nVercel Postgres\nAWS Data API"
  },
  {
    "title": "Vercel Postgres",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/vercel",
    "html": "PostgreSQL\nVercel Postgres\nVercel Postgres\n\nAccording to their official website\n(opens in a new tab)\n, Vercel Postgres is a serverless SQL database designed to integrate with Vercel Functions.\n\nDrizzle ORM natively supports both @vercel/postgres\n(opens in a new tab)\n serverless driver with drizzle-orm/vercel-postgres package and postgres or pg drivers to access Vercel Postgres through postgesql://\n\nCheck out the official Vercel Postgres + Drizzle\n(opens in a new tab)\n docs.\n\nInstall dependencies\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @vercel/postgres \nnpm i -D drizzle-kit \nPrepare Vercel Postgres\n\nSetup a project according to the official docs.\n(opens in a new tab)\n\nMake your first query\nindex.ts\nimport { sql } from '@vercel/postgres';\nimport { drizzle } from 'drizzle-orm/vercel-postgres';\n \nconst db = drizzle(sql)\nconst result = await db.select().from(...);\n\nWith @vercel/postgres\n(opens in a new tab)\n severless package you can access Vercel Postgres from either serverful or serverless environments with no TCP available, like Cloudflare Workers, through websockets.\n\nIf you're about to use Vercel Postgres from a serverfull environment, you can do it either with @vercel/postgres or directly access the DB through postgesql:// with either postgres or pg.\n\nNeon\nSupabase"
  },
  {
    "title": "Neon",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/neon",
    "html": "PostgreSQL\nNeon\nNeon\n\nAccording to their official website\n(opens in a new tab)\n, Neon database is a multi-cloud fully managed Postgres.\n\nDrizzle ORM natively supports both Neon Serverless\n(opens in a new tab)\n driver with drizzle-orm/neon-serverless package and postgres or pg drivers to access Neon database, as per the Neon nodejs docs.\n(opens in a new tab)\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm @neondatabase/serverless\nnpm i -D drizzle-kit\n\nWith Neon Serverless package [github\n(opens in a new tab)\n, blog post\n(opens in a new tab)\n] you can access Neon database from serverless environments with no TCP available ‚Äî like Cloudflare Workers ‚Äî through websockets.\n\nHTTP\nWebSockets\nindex.ts\nimport { neon, neonConfig } from '@neondatabase/serverless';\nimport { drizzle } from 'drizzle-orm/neon-http';\n \nneonConfig.fetchConnectionCache = true;\n \nconst sql = neon(process.env.DRIZZLE_DATABASE_URL!);\nconst db = drizzle(sql);\n \nconst result = await db.select().from(...);\n\nIf you're unsure how to use Neon from a serverfull environments, you should just use PostgresJS driver according to their official nodejs docs\n(opens in a new tab)\n ‚Äî see docs.\n\nnode-postgres\nVercel Postgres"
  },
  {
    "title": "node-postgres",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/node-postgres",
    "html": "PostgreSQL\nnode-postgres\nnode-postgres\n\nAccording to the official website\n(opens in a new tab)\n, node-postgres is a collection of Node.js modules for interfacing with your PostgreSQL database.\n\nDrizzle ORM natively supports pg with drizzle-orm/pg package.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm pg\nnpm i -D drizzle-kit @types/pg\n\nYou can connect to a PostgreSQL database either using a single client connection or a pool.\n\nClient connection\nPool connection\nindex.ts\nimport { pgTable, serial, text, varchar } from \"drizzle-orm/pg-core\";\nimport { drizzle } from \"drizzle-orm/node-postgres\";\nimport { Client } from \"pg\";\n \nconst client = new Client({\n  connectionString: \"postgres://user:password@host:port/db\",\n});\n \n// or\nconst client = new Client({\n  host: \"127.0.0.1\",\n  port: 5432,\n  user: \"postgres\",\n  password: \"password\",\n  database: \"db_name\",\n});\n \nawait client.connect();\nconst db = drizzle(client);\n‚öôÔ∏è\n\nFor the built in migrate function with DDL migrations we strongly encourage you to use max: 1 connection configuration.\n\nFor querying purposes feel free to use pool size of your choice based on your business demands.\n\nPostgres.JS\nNeon"
  },
  {
    "title": "PostgresJS",
    "url": "https://orm.drizzle.team/docs/quick-postgresql/postgresjs",
    "html": "PostgreSQL\nPostgres.JS\nPostgresJS\n\nAccording to the official website\n(opens in a new tab)\n, PostgresJS is the fastest fully featured PostgreSQL client for Node.js and Deno.\n\nDrizzle ORM natively supports postgresjs driver with drizzle-orm/postgres-js package.\n\nnpm\npnpm\nyarn\nbun\nnpm i drizzle-orm postgres\nnpm i -D drizzle-kit\nindex.ts\nimport { drizzle } from 'drizzle-orm/postgres-js';\nimport { migrate } from 'drizzle-orm/postgres-js/migrator';\nimport postgres from 'postgres';\n \n// for migrations\nconst migrationClient = postgres(\"postgres://postgres:adminadmin@0.0.0.0:5432/db\", { max: 1 });\nmigrate(drizzle(migrationClient), ...)\n \n// for query purposes\nconst queryClient = postgres(\"postgres://postgres:adminadmin@0.0.0.0:5432/db\");\nconst db = drizzle(queryClient);\nawait db.select().from(...)...\n‚öôÔ∏è\n\nFor the built in migrate function with DDL migrations we strongly encourage you to use max: 1 connection configuration.\n\nFor querying purposes feel free to use pool size of your choice based on your business demands.\n\nPostgreSQL\nnode-postgres"
  },
  {
    "title": "Drizzle ORM",
    "url": "https://orm.drizzle.team/docs/overview",
    "html": "Overview\nDrizzle ORM\n\nDrizzle is a good friend who's there for you when necessary and doesn't bother when you need some space.\n\nDrizzle ORM is a headless TypeScript ORM with a head üê≤\n\nIt looks and feels simple, performs on day 1000 of your project, lets you do things your way, and is there when you need it.\n\nIt's the only ORM with both relational and SQL-like query APIs, providing you best of both worlds when it comes to accessing your relational data. Drizzle is lightweight, performant, typesafe, non lactose, gluten-free, sober, flexible and serverless-ready by design. Drizzle is not just a library, it's an experience ü§©\n\n(opens in a new tab)\n\nHeadless ORM?\n\nFirst and foremost, Drizzle is a library and a collection of complementary opt-in tools.\n\nORM stands for object relational mapping, and developers tend to call Django-like or Spring-like tools an ORM. We trully believe it's a misconception based on legacy nomenclature and we call them data frameworks.\n\nÔ∏èüíî\n\nWith data frameworks you have to build projects around them and not with them.\n\nDrizzle lets you build your project the way you want, withour interfering with your project or structure.\n\nUsing Drizzle you can define & manage database schemas in typescript, access your data in a SQL-like or relational way, and take advantage of opt in tools to push your developer experience through the roof ü§Ø\n\nWhy SQL-like?\n\nIf you know SQL ‚Äî you know Drizzle.\n\nOther ORMs and data frameworks tend to deviate/abstract you away from SQL which leads to a double learning curve ‚Äî needing to know both SQL and the framework's API.\n\nDrizzle is the opposite. We embrace SQL and built Drizzle to be SQL-like at its core, so you can have zero to none learning curve and access to the full power of SQL.\n\nWe bring all the familiar SQL schema, queries, automatic migrations and one more thing ‚ú®\n\nindex.ts\nschema.ts\nmigration.sql\n// Access your data\nawait db\n\t.select()\n\t.from(countries)\n\t.leftJoin(cities, eq(cities.countryId, countries.id))\n\t.where(eq(countries.id, 10))\nWhy not SQL-like?\n\nWe're always striving for a perfectly balanced solution, and while SQL-like does cover 100% of the needs, there're certain common scenarios where you can query data in a better way.\n\nWe've built Queries API for you, so you can fetch relational nested data from the database in the most convenient and performant way, and never think about joins and data mapping.\n\nDrizzle always outputs exactly 1 SQL query ‚Äî feel free to use it with serverless databases and never worry about performance or roundtrip costs!\n\nconst result = await db.query.users.findMany({\n\twith: {\n\t\tposts: true\n\t},\n});\nServerless?\nü•≥\n\nBest part is no part ‚Äî Drizzle has exactly 0 dependencies!\n\nDrizzle ORM is dialect specific, slim, performant and serverless ready by design.\n\nWe've spent a lot of time to make sure you have best in class SQL dialects support ‚Äî Postgres, MySQL, or any other dialect-specific stuff.\n\nDrizzle is operating natively through industry standard database drivers. We support all major PostgreSQL, MySQL or SQLite drivers out there and we're adding new ones really fast\n(opens in a new tab)\n.\n\nWelcome on board!\n\nMore and more companies adopt Drizzle into production, experiencing immense benefits in both DX and performance.\n\nWe're always there to help, so don't hesitate to reach out ‚Äî we'll gladly assist you in your Drizzle journey!\n\nWe have an outstanding Discord community\n(opens in a new tab)\n and welcome all builders to our Twitter\n(opens in a new tab)\n.\n\nNow go build something awesome with Drizzle and your PostgreSQL, MySQL or SQLite üöÄ\n\nVideo Showcase\nTheo\nMarius Espejo\nPostgreSQL"
  },
  {
    "title": "Quick Postgresql",
    "url": "https://orm.drizzle.team/docs/quick-postgresql",
    "html": "PostgreSQL\nPostgreSQL\nPostgres.JS\nFastest full featured PostgreSQL client for Node.js and Deno\nnode-postgres\nCollection of nodejs modules to interact with PostgreSQL\nNeon\nServerless multi-cloud fully managed Postgres\nVercel Postgres\nServerless SQL database designed to integrate with Vercel Functions\nSupabase\nOpen source Firebase alternative for building secure and performant Postgres backends\nAWS Data API\nData API for AWS Aurora Serverless\nPostgreSQL HTTP proxy\nPostgreSQL HTTP proxy implementation\nOverview\nPostgres.JS"
  },
  {
    "title": "Drizzle ORM",
    "url": "https://orm.drizzle.team/docs/overview",
    "html": "Overview\nDrizzle ORM\n\nDrizzle is a good friend who's there for you when necessary and doesn't bother when you need some space.\n\nDrizzle ORM is a headless TypeScript ORM with a head üê≤\n\nIt looks and feels simple, performs on day 1000 of your project, lets you do things your way, and is there when you need it.\n\nIt's the only ORM with both relational and SQL-like query APIs, providing you best of both worlds when it comes to accessing your relational data. Drizzle is lightweight, performant, typesafe, non lactose, gluten-free, sober, flexible and serverless-ready by design. Drizzle is not just a library, it's an experience ü§©\n\n(opens in a new tab)\n\nHeadless ORM?\n\nFirst and foremost, Drizzle is a library and a collection of complementary opt-in tools.\n\nORM stands for object relational mapping, and developers tend to call Django-like or Spring-like tools an ORM. We trully believe it's a misconception based on legacy nomenclature and we call them data frameworks.\n\nÔ∏èüíî\n\nWith data frameworks you have to build projects around them and not with them.\n\nDrizzle lets you build your project the way you want, withour interfering with your project or structure.\n\nUsing Drizzle you can define & manage database schemas in typescript, access your data in a SQL-like or relational way, and take advantage of opt in tools to push your developer experience through the roof ü§Ø\n\nWhy SQL-like?\n\nIf you know SQL ‚Äî you know Drizzle.\n\nOther ORMs and data frameworks tend to deviate/abstract you away from SQL which leads to a double learning curve ‚Äî needing to know both SQL and the framework's API.\n\nDrizzle is the opposite. We embrace SQL and built Drizzle to be SQL-like at its core, so you can have zero to none learning curve and access to the full power of SQL.\n\nWe bring all the familiar SQL schema, queries, automatic migrations and one more thing ‚ú®\n\nindex.ts\nschema.ts\nmigration.sql\n// Access your data\nawait db\n\t.select()\n\t.from(countries)\n\t.leftJoin(cities, eq(cities.countryId, countries.id))\n\t.where(eq(countries.id, 10))\nWhy not SQL-like?\n\nWe're always striving for a perfectly balanced solution, and while SQL-like does cover 100% of the needs, there're certain common scenarios where you can query data in a better way.\n\nWe've built Queries API for you, so you can fetch relational nested data from the database in the most convenient and performant way, and never think about joins and data mapping.\n\nDrizzle always outputs exactly 1 SQL query ‚Äî feel free to use it with serverless databases and never worry about performance or roundtrip costs!\n\nconst result = await db.query.users.findMany({\n\twith: {\n\t\tposts: true\n\t},\n});\nServerless?\nü•≥\n\nBest part is no part ‚Äî Drizzle has exactly 0 dependencies!\n\nDrizzle ORM is dialect specific, slim, performant and serverless ready by design.\n\nWe've spent a lot of time to make sure you have best in class SQL dialects support ‚Äî Postgres, MySQL, or any other dialect-specific stuff.\n\nDrizzle is operating natively through industry standard database drivers. We support all major PostgreSQL, MySQL or SQLite drivers out there and we're adding new ones really fast\n(opens in a new tab)\n.\n\nWelcome on board!\n\nMore and more companies adopt Drizzle into production, experiencing immense benefits in both DX and performance.\n\nWe're always there to help, so don't hesitate to reach out ‚Äî we'll gladly assist you in your Drizzle journey!\n\nWe have an outstanding Discord community\n(opens in a new tab)\n and welcome all builders to our Twitter\n(opens in a new tab)\n.\n\nNow go build something awesome with Drizzle and your PostgreSQL, MySQL or SQLite üöÄ\n\nVideo Showcase\nTheo\nMarius Espejo\nPostgreSQL"
  }
]
