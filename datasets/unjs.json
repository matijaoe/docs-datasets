[
  {
    "title": "",
    "url": "https://unjs.io/packages/src/config.ts",
    "html": "404\n\nPage not found\n\nGo back home"
  },
  {
    "title": "webpackbar · UnJS",
    "url": "https://unjs.io/packages/webpackbar",
    "html": "webpackbar\n\nElegant ProgressBar and Profiler for webpack 3 , 4 and 5\n\nElegant ProgressBar and Profiler for Webpack\n\n✔ Display elegant progress bar while building or watch\n\n✔ Support of multiple concurrent builds (useful for SSR)\n\n✔ Pretty print filename and loaders\n\n✔ Windows compatible\n\n✔ Fully customizable using reporters\n\n✔ Advanced build profiler\n\n\n\n\nMulti progress bars\n\n\n\n\n\n\nBuild Profiler\n\n\n\nGetting Started\n\nTo begin, you'll need to install webpackbar:\n\nUsing npm:\n\nnpm install webpackbar -D\n\nCopy to clipboard\n\nUsing yarn:\n\nyarn add webpackbar -D\n\nCopy to clipboard\n\nThen add the reporter as a plugin to your webpack config.\n\nwebpack.config.js\n\nconst webpack = require(\"webpack\");\n\nconst WebpackBar = require(\"webpackbar\");\n\n\n\nmodule.exports = {\n\n  context: path.resolve(__dirname),\n\n  devtool: \"source-map\",\n\n  entry: \"./entry.js\",\n\n  output: {\n\n    filename: \"./output.js\",\n\n    path: path.resolve(__dirname),\n\n  },\n\n  plugins: [new WebpackBar()],\n\n};\n\nCopy to clipboard\nOptions\nname\nDefault: webpack\n\nName.\n\ncolor\nDefault: green\n\nPrimary color (can be HEX like #xxyyzz or a web color like green).\n\nprofile\nDefault: false\n\nEnable profiler.\n\nfancy\nDefault: true when not in CI or testing mode.\n\nEnable bars reporter.\n\nbasic\nDefault: true when running in minimal environments.\n\nEnable a simple log reporter (only start and end).\n\nreporter\n\nRegister a custom reporter.\n\nreporters\nDefault: []\n\nRegister an Array of your custom reporters. (Same as reporter but array)\n\nCustom Reporters\n\nWebpackbar comes with a fancy progress-bar out of the box. But you may want to show progress somewhere else or provide your own.\n\nFor this purpose, you can provide one or more extra reporters using reporter and reporters options.\n\nNOTE: If you plan to provide your own reporter, don't forget to setting fancy and basic options to false to prevent conflicts.\n\nA reporter should be instance of a class or plain object and functions for special hooks. It is not necessary to implement all functions, webpackbar only calls those that exists.\n\nSimple logger:\n\n{\n\n start(context) {\n\n   // Called when (re)compile is started\n\n },\n\n change(context) {\n\n   // Called when a file changed on watch mode\n\n },\n\n update(context) {\n\n   // Called after each progress update\n\n },\n\n done(context) {\n\n   // Called when compile finished\n\n },\n\n progress(context) {\n\n   // Called when build progress updated\n\n },\n\n allDone(context) {\n\n   // Called when _all_ compiles finished\n\n },\n\n beforeAllDone(context) {\n\n },\n\n afterAllDone(context) {\n\n },\n\n}\n\nCopy to clipboard\n\ncontext is the reference to the plugin. You can use context.state to access status.\n\nSchema of context.state:\n\n{\n\n  start, progress, message, details, request, hasErrors;\n\n}\n\nCopy to clipboard"
  },
  {
    "title": "uqr · UnJS",
    "url": "https://unjs.io/packages/uqr/",
    "html": "uqr\n\nGenerate QR Code universally, in any runtime, to ANSI, Unicode or SVG.\n\nGenerate QR Code universally, in any runtime, to ANSI, Unicode or SVG. ES module , zero dependency, tree-shakable.\n\nInstall\n# Using npm\n\nnpm install uqr\n\n\n\n# Using yarn\n\nyarn add uqr\n\n\n\n# Using pnpm\n\npnpm add uqr\n\nUsage\nimport {\n\n  encode,\n\n  renderANSI,\n\n  renderSVG,\n\n  renderUnicode,\n\n  renderUnicodeCompact,\n\n} from 'uqr'\n\n\n\nconst svg = renderSVG('Hello, World!')\n\n\n\nconst ansi = renderANSI('https://192.168.1.100:3000', {\n\n  // Error correction level\n\n  ecc: 'L',\n\n  // Border width\n\n  border: 2,\n\n})\n\n\n\n// display QR Code in terminal\n\nconsole.log(ansi)\n\nAPI\nencode\n\nEncode plain text or binary data into QR Code represented by a 2D array.\n\nimport { encode } from 'uqr'\n\n\n\nconst {\n\n  data, // 2D array of boolean, representing the QR Code\n\n  version, // QR Code version\n\n  size, // size of the QR Code\n\n} = encode(text, options)\n\nrenderANSI\n\nRender QR Code to ANSI colored string.\n\nimport { renderANSI } from 'uqr'\n\n\n\nconst string = renderANSI(text, options)\n\n\n\nconsole.log(string)\n\nrenderUnicode\n\nRender QR Code to Unicode string for each pixel. By default it uses █ and ░ to represent black and white pixels, and it can be customizable.\n\nimport { renderUnicode } from 'uqr'\n\n\n\nconst string = renderUnicode(text, {\n\n  blackChar: '█',\n\n  whiteChar: '░',\n\n  // ...other options\n\n})\n\nrenderUnicodeCompact\n\nRender QR Code with two rows into one line with unicode ▀, ▄, █, . It is useful when you want to display QR Code in terminal with limited height.\n\nimport { renderUnicodeCompact } from 'uqr'\n\n\n\nconst string = renderUnicodeCompact(text, options)\n\n\n\nconsole.log(string)\n\nrenderSVG\n\nRender QR Code to SVG string.\n\nimport { renderSVG } from 'uqr'\n\n\n\nconst string = renderSVG(text, options)\n\nCredits\n\nQR Code generation algorithm is modified from nayuki/QR-Code-generator by Project Nayuki.\n\nCLI renders are inspired by qrcode-terminal.\n"
  },
  {
    "title": "untyped · UnJS",
    "url": "https://unjs.io/packages/untyped/",
    "html": "untyped\n\nGenerate types and markdown from a config object.\n\n▶️ Check online playground\n\nInstall\n# npm\n\nnpm i untyped\n\n\n\n# yarn\n\nyarn add untyped\n\n\n\n# pnpm\n\npnpm add untyped\n\nUsage\n\nFirst we have to define a reference object that describes types, defaults, and a $resolve method (normalizer).\n\nconst defaultPlanet = {\n\n  name: \"earth\",\n\n  specs: {\n\n    gravity: {\n\n      $resolve: (val) => parseFloat(val),\n\n      $default: \"9.8\",\n\n    },\n\n    moons: {\n\n      $resolve: (val = [\"moon\"]) => [].concat(val),\n\n      $schema: {\n\n        title: \"planet moons\",\n\n      },\n\n    },\n\n  },\n\n};\n\nAPI\nresolveSchema\nimport { resolveSchema } from \"untyped\";\n\n\n\nconst schema = await resolveSchema(defaultPlanet);\n\n\nOutput:\n\n{\n\n  \"properties\": {\n\n    \"name\": {\n\n      \"type\": \"string\",\n\n      \"default\": \"earth\"\n\n    },\n\n    \"specs\": {\n\n      \"properties\": {\n\n        \"gravity\": {\n\n          \"default\": 9.8,\n\n          \"type\": \"number\"\n\n        },\n\n        \"moons\": {\n\n          \"title\": \"planet moons\",\n\n          \"default\": [\"moon\"],\n\n          \"type\": \"array\",\n\n          \"items\": [\n\n            {\n\n              \"type\": \"string\"\n\n            }\n\n          ]\n\n        }\n\n      },\n\n      \"type\": \"object\"\n\n    }\n\n  },\n\n  \"type\": \"object\"\n\n}\n\ngenerateTypes\nimport { resolveSchema, generateTypes } from \"untyped\";\n\n\n\nconst types = generateTypes(await resolveSchema(defaultPlanet));\n\n\nOutput:\n\ninterface Untyped {\n\n  /** @default \"earth\" */\n\n  name: string;\n\n\n\n  specs: {\n\n    /** @default 9.8 */\n\n    gravity: number;\n\n\n\n    /**\n\n     * planet moons\n\n     * @default [\"moon\"]\n\n     */\n\n    moons: string[];\n\n  };\n\n}\n\ngenerateMarkdown\nimport { resolveSchema, generateMarkdown } from \"untyped\";\n\n\n\nconst markdown = generateMarkdown(await resolveSchema(defaultPlanet));\n\n\nOutput:\n\n# `name`\n\n\n\n- **Type**: `string`\n\n- **Default**: `\"earth\"`\n\n\n\n# `specs`\n\n\n\n## `gravity`\n\n\n\n- **Type**: `number`\n\n- **Default**: `9.8`\n\n\n\n## `moons`\n\n\n\n- **Type**: `array`\n\n- **Default**: `[\"moon\"]`\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev\nUse pnpm web to start playground website\nUse pnpm test before push to ensure all tests and lint checks passing"
  },
  {
    "title": "untun · UnJS",
    "url": "https://unjs.io/packages/untun/",
    "html": "untun\n\nTunnel your local HTTP(s) server to the world! powered by Cloudflare Quick Tunnels.\n\nTunnel your local HTTP(s) server to the world!\n\nPowered by 🔥 Cloudflare Quick Tunnels and used by 👂 unjs/listhen.\n\nUsage (CLI)\n\nGlobally run tunnel with npx:\n\nnpx untun@latest tunnel http://localhost:3000\n\n◐ Starting cloudflared tunnel to http://localhost:3000\nℹ Waiting for tunnel URL...\n✔ Tunnel ready at https://unjs-is-awesome.trycloudflare.com\n\n\nUse npx untun tunnel --help for more usage info.\n\nUsage (API)\n\nInstall package:\n\n# npm\n\nnpm install untun\n\n\n\n# yarn\n\nyarn add untun\n\n\n\n# pnpm\n\npnpm install untun\n\n\nImport:\n\n// ESM\n\nimport { startTunnel } from \"untun\";\n\n\n\n// CommonJS\n\nconst { startTunnel } = require(\"untun\");\n\n\nStart tunnel:\n\nconst tunnel = await startTunnel({ port: 3000 });\n\nOptions\nurl\nDefault: {protocol}://{hostname}:{port}\n\nThe local server URL to tunnel.\n\nport\nDefault: 3000\n\nThe local server PORT (only effective if url is not provided).\n\nhostname\nDefault: localhost\n\nThe local server hostname (only effective if url is not provided).\n\nprotocol\nDefault: http\n\nThe local server protocol (only effective if url is not provided).\n\nverifyTLS\nDefault: false\n\nVerify local server TLS certificate.\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "unstorage · UnJS",
    "url": "https://unjs.io/packages/unstorage/",
    "html": "unstorage\n\nAsync Key-Value storage API with dozens of built-in drivers and a tiny core.\n\nUnstorage provides an async Key-Value storage API with conventional features like multi driver mounting, watching and working with metadata, dozens of built-in drivers and a tiny core.\n\n👉 Documentation\n\nFeatures\nDesigned for all environments: Browser, NodeJS, and Workers\nLots of Built-in drivers\nAsynchronous API\nUnix-style driver mounting to combine storages\nDefault in-memory storage\nTree-shakable utils and tiny core\nAuto JSON value serialization and deserialization\nBinary and raw value support\nState snapshots and hydration\nStorage watcher\nHTTP Storage with built-in server\nUsage\n\nInstall unstorage npm package:\n\n# yarn\n\nyarn add unstorage\n\n\n\n# npm\n\nnpm install unstorage\n\n\n\n# pnpm\n\npnpm add unstorage\n\nimport { createStorage } from \"unstorage\";\n\n\n\nconst storage = createStorage(/* opts */);\n\n\n\nawait storage.getItem(\"foo:bar\"); // or storage.getItem('/foo/bar')\n\n\n👉 Check out the the documentation for usage information.\n\nContribution\nClone repository\nInstall dependencies with pnpm install\nUse pnpm dev to start jest watcher verifying changes\nUse pnpm test before pushing to ensure all tests and lint checks passing"
  },
  {
    "title": "unhead · UnJS",
    "url": "https://unjs.io/packages/unhead",
    "html": "unhead\n\n△ Universal document <head> tag manager. Tiny, adaptable and full-featured.\n\nUniversal document tag manager. Tiny, adaptable and full featured.\n\n\nStatus: v1.7 Released\nPlease report any issues 🐛\nMade possible by my Sponsor Program 💖\nFollow me @harlan_zw 🐦 • Join Discord for help\n\nHighlights\n🌳 Powerful pluggable core with a tiny footprint\n🍣 All the good stuff: deduping, sorting, title templates, template params, etc.\n🪨 Rock-solid DOM updates, fast and tiny (952 bytes minzipped)\n🚀 Add-ons for extra oomph: Capo.js, Hash Hydration and Vite tree-shaking\n💎 Fully typed with MDN docs\n🤝 Used by Nuxt with more framework support coming soon.\nDocs\n\nVisit the documentation site for guides and API references.\n\nInstall\nnpm i unhead\n\nCopy to clipboard\nQuick Setup\n\nCreate the head client somewhere in your root application.\n\nimport { createHead } from 'unhead'\n\n\n\ncreateHead()\n\nCopy to clipboard\n\nThen use the composables anywhere you want.\n\n// pages/about.js\n\nimport { useHead } from 'unhead'\n\n\n\nuseHead({\n\n  title: 'About',\n\n  meta: [\n\n    { name: 'description', content: 'Learn more about us.' },\n\n  ],\n\n})\n\nCopy to clipboard\nDemos\nStackBlitz - Vue SPA\nSponsors\n"
  },
  {
    "title": "unplugin · UnJS",
    "url": "https://unjs.io/packages/unplugin/",
    "html": "unplugin\n\nUnified plugin system for Vite, Rollup, webpack, esbuild, and more\n\nUnified plugin system for build tools.\n\nCurrently supports:\n\nVite\nRollup\nWebpack\nesbuild\nRspack (⚠️ experimental)\nHooks\n\nunplugin extends the excellent Rollup plugin API as the unified plugin interface and provides a compatible layer base on the build tools used with.\n\nSupported\nHook\tRollup\tVite\tWebpack 4\tWebpack 5\tesbuild\tRspack\nenforce\t❌ 1\t✅\t✅\t✅\t❌ 1\t✅\nbuildStart\t✅\t✅\t✅\t✅\t✅\t✅\nresolveId\t✅\t✅\t✅\t✅\t✅\t❌\nloadInclude2\t✅\t✅\t✅\t✅\t✅\t✅\nload\t✅\t✅\t✅\t✅\t✅ 3\t✅\ntransformInclude2\t✅\t✅\t✅\t✅\t✅\t✅\ntransform\t✅\t✅\t✅\t✅\t✅ 3\t✅\nwatchChange\t✅\t✅\t✅\t✅\t❌\t❌\nbuildEnd\t✅\t✅\t✅\t✅\t✅\t✅\nwriteBundle4\t✅\t✅\t✅\t✅\t✅\t✅\nRollup and esbuild do not support using enforce to control the order of plugins. Users need to maintain the order manually.\nWebpack's id filter is outside of loader logic; an additional hook is needed for better perf on Webpack. In Rollup and Vite, this hook has been polyfilled to match the behaviors. See for the following usage examples.\nAlthough esbuild can handle both JavaScript and CSS and many other file formats, you can only return JavaScript in load and transform results.\nCurrently, writeBundle is only serves as a hook for the timing. It doesn't pass any arguments.\n\nWarning: The Rspack support is experimental. Future changes to Rspack integrations might not follow semver, please pin unplugin in your dependency when using. It's not recommended to use in production.\n\nHook Context\nSupported\nHook\tRollup\tVite\tWebpack 4\tWebpack 5\tesbuild\tRspack\nthis.parse\t✅\t✅\t✅\t✅\t✅\t✅\nthis.addWatchFile\t✅\t✅\t✅\t✅\t❌\t❌\nthis.emitFile5\t✅\t✅\t✅\t✅\t✅\t✅\nthis.getWatchFiles\t✅\t✅\t✅\t✅\t❌\t❌\nthis.warn\t✅\t✅\t✅\t✅\t✅\t✅\nthis.error\t✅\t✅\t✅\t✅\t✅\t✅\nCurrently, this.emitFile only supports the EmittedAsset variant.\nUsage\nimport { createUnplugin } from 'unplugin'\n\n\n\nexport const unplugin = createUnplugin((options: UserOptions) => {\n\n  return {\n\n    name: 'unplugin-prefixed-name',\n\n    // webpack's id filter is outside of loader logic,\n\n    // an additional hook is needed for better perf on webpack\n\n    transformInclude(id) {\n\n      return id.endsWith('.vue')\n\n    },\n\n    // just like rollup transform\n\n    transform(code) {\n\n      return code.replace(/<template>/, '<template><div>Injected</div>')\n\n    },\n\n    // more hooks coming\n\n  }\n\n})\n\n\n\nexport const vitePlugin = unplugin.vite\n\nexport const rollupPlugin = unplugin.rollup\n\nexport const webpackPlugin = unplugin.webpack\n\nexport const rspackPlugin = unplugin.rspack\n\nexport const esbuildPlugin = unplugin.esbuild\n\nNested Plugins\n\nSince v0.10.0, unplugin supports constructing multiple nested plugins to behave like a single one. For example:\n\nSupported\nRollup\tVite\tWebpack 4\tWebpack 5\tRspack\tesbuild\n✅ >=3.16\t✅\t✅\t✅\t✅\t⚠️7\nRollup supports nested plugins since v3.1.0. Plugin author should ask users to have a Rollup version of >=3.1.0 when using nested plugins. For single plugin format, unplugin works for any version of Rollup.\nSince esbuild does not have a built-in transform phase, the transform hook of the nested plugin will not work on esbuild yet. Other hooks like load or resolveId work fine. We will try to find a way to support it in the future.\nUsage\nimport { createUnplugin } from 'unplugin'\n\n\n\nexport const unplugin = createUnplugin((options: UserOptions) => {\n\n  return [\n\n    {\n\n      name: 'plugin-a',\n\n      transform(code) {\n\n        // ...\n\n      },\n\n    },\n\n    {\n\n      name: 'plugin-b',\n\n      resolveId(id) {\n\n        // ...\n\n      },\n\n    },\n\n  ]\n\n})\n\nPlugin Installation\nVite\n// vite.config.ts\n\nimport UnpluginFeature from './unplugin-feature'\n\n\n\nexport default {\n\n  plugins: [\n\n    UnpluginFeature.vite({ /* options */ }),\n\n  ],\n\n}\n\nRollup\n// rollup.config.js\n\nimport UnpluginFeature from './unplugin-feature'\n\n\n\nexport default {\n\n  plugins: [\n\n    UnpluginFeature.rollup({ /* options */ }),\n\n  ],\n\n}\n\nWebpack\n// webpack.config.js\n\nmodule.exports = {\n\n  plugins: [\n\n    require('./unplugin-feature').webpack({ /* options */ }),\n\n  ],\n\n}\n\nesbuild\n// esbuild.config.js\n\nimport { build } from 'esbuild'\n\n\n\nbuild({\n\n  plugins: [\n\n    require('./unplugin-feature').esbuild({ /* options */ }),\n\n  ],\n\n})\n\nRspack\n// rspack.config.js\n\nmodule.exports = {\n\n  plugins: [\n\n    require('./unplugin-feature').rspack({ /* options */ }),\n\n  ],\n\n}\n\nFramework-specific Logic\n\nWhile unplugin provides compatible layers for some hooks, the functionality of it is limited to the common subset of the build's plugins capability. For more advanced framework-specific usages, unplugin provides an escape hatch for that.\n\nexport const unplugin = createUnplugin((options: UserOptions, meta) => {\n\n  console.log(meta.framework) // 'vite' | 'rollup' | 'webpack' | 'rspack' | 'esbuild'\n\n\n\n  return {\n\n    // Common unplugin hooks\n\n    name: 'unplugin-prefixed-name',\n\n    transformInclude(id) { /* ... */ },\n\n    transform(code) { /* ... */ },\n\n\n\n    // Framework specific hooks\n\n    vite: {\n\n      // Vite plugin\n\n      configureServer(server) {\n\n        // configure Vite server\n\n      },\n\n      // ...\n\n    },\n\n    rollup: {\n\n      // Rollup plugin\n\n    },\n\n    webpack(compiler) {\n\n      // Configure Webpack compiler\n\n    },\n\n    rspack(compiler) {\n\n      // Configure Rspack compiler\n\n    },\n\n    esbuild: {\n\n      // Change the filter of onResolve and onLoad\n\n      // onResolveFilter?: RegExp,\n\n      // onLoadFilter?: RegExp,\n\n\n\n      // Tell esbuild how to interpret the contents. By default unplugin tries to guess the loader\n\n      // from file extension (eg: .js -> \"js\", .jsx -> 'jsx')\n\n      // loader?: (Loader | (code: string, id: string) => Loader)\n\n\n\n      // Or you can completely replace the setup logic\n\n      // setup?: EsbuildPlugin.setup,\n\n    },\n\n  }\n\n})\n\nCreating platform specific plugins\n\nThe package exports a set of functions in place of createUnplugin that allow for the creation of plugins for specific bundlers. Each of the function takes the same generic factory argument as createUnplugin.\n\nimport {\n\n  createEsbuildPlugin,\n\n  createRollupPlugin,\n\n  createRspackPlugin,\n\n  createVitePlugin,\n\n  createWebpackPlugin\n\n} from 'unplugin'\n\n\n\nconst vitePlugin = createVitePlugin({ /* options */ })\n\nconst rollupPlugin = createRollupPlugin({ /* options */ })\n\nconst esbuildPlugin = createEsbuildPlugin({ /* options */ })\n\nconst webpackPlugin = createWebpackPlugin({ /* options */ })\n\nconst rspackPlugin = createRspackPlugin({ /* options */ })\n\nConventions\nPlugins powered by unplugin should have a clear name with unplugin- prefix.\nInclude unplugin keyword in package.json.\nTo provide better DX, packages could export 2 kinds of entry points:\nDefault export: the returned value of createUnplugin function\nimport UnpluginFeature from 'unplugin-feature'\n\nSubpath exports: properties of the returned value of createUnplugin function for each framework users\nimport VitePlugin from 'unplugin-feature/vite'\n\nRefer to unplugin-starter for more details about this setup.\nStarter Templates\nunplugin/unplugin-starter\njwr12135/create-unplugin\nsxzz/unplugin-starter\nCommunity Showcases\n\nWe have started a GitHub organization to host and collaborate on popular unplugin plugins: github.com/unplugin. You can go there to find more plugins or even join us with your own plugins!\n\nunplugin-auto-import\nunplugin-vue2-script-setup\nunplugin-icons\nunplugin-vue-components\nunplugin-upload-cdn\nunplugin-web-ext\nunplugin-properties\nunplugin-moment-to-dayjs\nunplugin-object-3d\nunplugin-parcel-css\nunplugin-vue\nunplugin-vue-macros\nunplugin-vue-define-options\nunplugin-jsx-string\nunplugin-ast\nunplugin-element-plus\nunplugin-glob\nunplugin-sentry\nunplugin-imagemin\nunplugin-typedotenv\nunplugin-fonts\nsentry-javascript-bundler-plugins\nunplugin-svg-component\nunplugin-vue-cssvars"
  },
  {
    "title": "unpdf · UnJS",
    "url": "https://unjs.io/packages/unpdf/",
    "html": "unpdf\n\nUtilities to work with PDFs in Node.js, browser and workers\n\nA collection of utilities to work with PDFs. Designed specifically for Deno, workers and other nodeless environments.\n\nunpdf ships with a serverless build/redistribution of Mozilla's PDF.js for serverless environments. Apart from some string replacements and mocks, unenv does the heavy lifting by converting Node.js specific code to be platform-agnostic. See pdfjs.rollup.config.ts for all the details.\n\nThis library is also intended as a modern alternative to the unmaintained but still popular pdf-parse.\n\nFeatures\n🏗️ Works in Node.js, browser and workers\n🪭 Includes serverless build of PDF.js (unpdf/pdfjs)\n💬 Extract text and images from PDFs\n🧱 Opt-in to legacy PDF.js build\n💨 Zero dependencies\nPDF.js Compatibility\n\n!NOTE This package is currently using PDF.js v4.0.189.\n\nInstallation\n\nRun the following command to add unpdf to your project.\n\n# pnpm\n\npnpm add unpdf\n\n\n\n# npm\n\nnpm install unpdf\n\n\n\n# yarn\n\nyarn add unpdf\n\nUsage\nExtract Text From PDF\nimport { extractText, getDocumentProxy } from \"unpdf\";\n\n\n\n// Fetch a PDF file from the web\n\nconst buffer = await fetch(\n\n  \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\",\n\n).then((res) => res.arrayBuffer());\n\n\n\n// Or load it from the filesystem\n\nconst buffer = await readFile(\"./dummy.pdf\");\n\n\n\n// Load PDF from buffer\n\nconst pdf = await getDocumentProxy(new Uint8Array(pdf));\n\n// Extract text from PDF\n\nconst { totalPages, text } = await extractText(pdf, { mergePages: true });\n\nAccess the PDF.js API\n\nThis will return the resolved PDF.js module and gives full access to the PDF.js API, like:\n\ngetDocument\nversion\n… and all other methods\n\nEspecially useful for platforms like 🦕 Deno or if you want to use the PDF.js API directly. If no custom build was defined beforehand, the serverless build bundled with unpdf will be initialized.\n\nimport { getResolvedPDFJS } from \"unpdf\";\n\n\n\nconst { getDocument } = await getResolvedPDFJS();\n\nconst data = Deno.readFileSync(\"dummy.pdf\");\n\nconst doc = await getDocument(data).promise;\n\n\n\nconsole.log(await doc.getMetadata());\n\n\n\nfor (let i = 1; i <= doc.numPages; i++) {\n\n  const page = await doc.getPage(i);\n\n  const textContent = await page.getTextContent();\n\n  const contents = textContent.items.map((item) => item.str).join(\" \");\n\n  console.log(contents);\n\n}\n\nUse Official or Legacy PDF.js Build\n\nGenerally speaking, you don't need to worry about the PDF.js build. unpdf ships with a serverless build of the latest PDF.js version. However, if you want to use the official PDF.js version or the legacy build, you can define a custom PDF.js module.\n\n// Before using any other method, define the PDF.js module\n\n// if you need another PDF.js build\n\nimport { configureUnPDF } from \"unpdf\";\n\n\n\nconfigureUnPDF({\n\n  // Use the official PDF.js build (make sure to install it first)\n\n  pdfjs: () => import(\"pdfjs-dist\"),\n\n});\n\n\n\n// Now, you can use the other methods\n\n// …\n\nConfig\ninterface UnPDFConfiguration {\n\n  /**\n\n   * By default, UnPDF will use the latest version of PDF.js compiled for\n\n   * serverless environments. If you want to use a different version, you can\n\n   * provide a custom resolver function.\n\n   *\n\n   * @example\n\n   * // Use the official PDF.js build (make sure to install it first)\n\n   * () => import('pdfjs-dist')\n\n   */\n\n  pdfjs?: () => Promise<PDFJS>;\n\n}\n\nMethods\nconfigureUnPDF\n\nDefine a custom PDF.js module, like the legacy build. Make sure to call this method before using any other methods.\n\nfunction configureUnPDF(config: UnPDFConfiguration): Promise<void>;\n\ngetResolvedPDFJS\n\nReturns the resolved PDF.js module. If no build is defined, the latest version will be initialized.\n\nfunction getResolvedPDFJS(): Promise<PDFJS>;\n\ngetMeta\nfunction getMeta(data: BinaryData | PDFDocumentProxy): Promise<{\n\n  info: Record<string, any>;\n\n  metadata: Record<string, any>;\n\n}>;\n\nextractText\n\nExtracts all text from a PDF. If mergePages is set to true, the text of all pages will be merged into a single string. Otherwise, an array of strings for each page will be returned.\n\nfunction extractText(\n\n  data: BinaryData | PDFDocumentProxy,\n\n  { mergePages }?: { mergePages?: boolean },\n\n): Promise<{\n\n  totalPages: number;\n\n  text: string | string[];\n\n}>;\n\nrenderPageAsImage\n\n!NOTE This method will only work in Node.js and browser environments.\n\nTo render a PDF page as an image, you can use the renderPageAsImage method. This method will return an ArrayBuffer of the rendered image.\n\nIn order to use this method, you have to meet the following requirements:\n\nUse the official PDF.js build\nInstall the canvas package in Node.js environments\n\nExample\n\nimport { configureUnPDF, renderPageAsImage } from \"unpdf\";\n\n\n\nconfigureUnPDF({\n\n  // Use the official PDF.js build\n\n  pdfjs: () => import(\"pdfjs-dist\"),\n\n});\n\n\n\nconst pdf = await readFile(\"./dummy.pdf\");\n\nconst buffer = new Uint8Array(pdf);\n\nconst pageNumber = 1;\n\n\n\nconst result = await renderPageAsImage(buffer, pageNumber, {\n\n  canvas: () => import(\"canvas\"),\n\n});\n\nawait writeFile(\"dummy-page-1.png\", Buffer.from(result));\n\n\nType Declaration\n\ndeclare function renderPageAsImage(\n\n  data: BinaryData | PDFDocumentProxy,\n\n  pageNumber: number,\n\n  options?: {\n\n    canvas?: () => Promise<typeof import(\"canvas\")>;\n\n    /** @default 1 */\n\n    scale?: number;\n\n    width?: number;\n\n    height?: number;\n\n  },\n\n): Promise<ArrayBuffer>;\n\nFAQ\nWhy Is canvas An Optional Dependency?\n\nThe official PDF.js library depends on the canvas module for Node.js environments, which doesn't work inside worker threads. That's why unpdf ships with a serverless build of PDF.js that mocks the canvas module.\n\nHowever, to render PDF pages as images in Node.js environments, you need to install the canvas module. That's why it is a peer dependency.\n"
  },
  {
    "title": "unimport · UnJS",
    "url": "https://unjs.io/packages/unimport/",
    "html": "unimport\n\nUnified utils for auto importing APIs in modules.\n\nUnified utils for auto importing APIs in modules, used in nuxt and unplugin-auto-import\n\nFeatures\nAuto import register APIs for Vite, Webpack or esbuild powered by unplugin\nTypeScript declaration file generation\nAuto import for custom APIs defined under specific directories\nAuto import for Vue template\nInstall\n# npm\n\nnpm install unimport\n\n\n\n# yarn\n\nyarn add unimport\n\n\n\n# pnpm\n\npnpm install unimport\n\nUsage\nPlugin Usage\n\nPowered by unplugin, unimport provides a plugin interface for bundlers.\n\nVite / Rollup\n// vite.config.js / rollup.config.js\n\nimport Unimport from 'unimport/unplugin'\n\n\n\nexport default {\n\n  plugins: [\n\n    Unimport.vite({ /* plugin options */ })\n\n  ]\n\n}\n\nWebpack\n// webpack.config.js\n\nimport Unimport from 'unimport/unplugin'\n\n\n\nmodule.exports = {\n\n  plugins: [\n\n    Unimport.webpack({ /* plugin options */ })\n\n  ]\n\n}\n\nProgrammatic Usage\n// ESM\n\nimport { createUnimport } from 'unimport'\n\n\n\n// CommonJS\n\nconst { createUnimport } = require('unimport')\n\nconst { injectImports } = createUnimport({\n\n  imports: [{ name: 'fooBar', from: 'test-id' }]\n\n})\n\n\n\n// { code: \"import { fooBar } from 'test-id';console.log(fooBar())\" }\n\nconsole.log(injectImports('console.log(fooBar())'))\n\nConfigurations\nImports Item\nNamed import\nimports: [\n\n  { name: 'ref', from: 'vue' },\n\n  { name: 'useState', as: 'useSignal', from: 'react' },\n\n]\n\n\nWill be injected as:\n\nimport { ref } from 'vue'\n\nimport { useState as useSignal } from 'react'\n\nDefault import\nimports: [\n\n  { name: 'default', as: '_', from: 'lodash' }\n\n]\n\n\nWill be injected as:\n\nimport _ from 'lodash'\n\nCustom Presets\n\nPresets are provided as a shorthand for declaring imports from the same package:\n\npresets: [\n\n  {\n\n    from: 'vue',\n\n    imports: [\n\n      'ref',\n\n      'reactive',\n\n      // ...\n\n    ]\n\n  }\n\n]\n\n\nWill be equivalent as:\n\nimports: [\n\n  { name: 'ref', from: 'vue' },\n\n  { name: 'reactive', from: 'vue' },\n\n  // ...\n\n]\n\nBuilt-in Presets\n\nunimport also provides some builtin presets for common libraries:\n\npresets: [\n\n  'vue',\n\n  'pinia',\n\n  'vue-i18n',\n\n  // ...\n\n]\n\n\nYou can check out src/presets for all the options available or refer to the type declaration.\n\nExports Auto Scan\n\nSince unimport v0.7.0, we also support auto scanning the examples from a local installed package, for example:\n\npresets: [\n\n  {\n\n    package: 'h3',\n\n    ignore: ['isStream', /^[A-Z]/, /^[a-z]*$/, r => r.length > 8]\n\n  }\n\n]\n\n\nThis will be expanded into:\n\nimports: [\n\n  {\n\n    from: 'h3',\n\n    name: 'appendHeader',\n\n  },\n\n  {\n\n    from: 'h3',\n\n    name: 'appendHeaders',\n\n  },\n\n  {\n\n    from: 'h3',\n\n    name: 'appendResponseHeader',\n\n  },\n\n  // ...\n\n]\n\n\nThe ignore option is used to filter out the exports, it can be a string, regex or a function that returns a boolean.\n\nBy default, the result is strongly cached by the version of the package. You can disable this by setting cache: false.\n\nType Declarations\nUnimport.vite({\n\n  dts: true // or a path to generated file\n\n})\n\nDirectory Auto Import\ndirs: [\n\n  './composables/*'\n\n]\n\n\nNamed exports for modules under ./composables/* will be registered for auto imports.\n\nOpt-out Auto Import\n\nYou can opt-out auto-import for specific modules by adding a comment:\n\n// @unimport-disable\n\n\nIt can be customized by setting commentsDisable:\n\nUnimport.vite({\n\n  commentsDisable: [\n\n    '@unimport-disable',\n\n    '@custom-imports-disable',\n\n  ]\n\n})\n\nVue Template Auto Import\n\nIn Vue's template, the usage of API is in a different context than plain modules. Thus some custom transformations are required. To enable it, set addons.vueTemplate to true:\n\nUnimport.vite({\n\n  addons: {\n\n    vueTemplate: true\n\n  }\n\n})\n\nCaveats\n\nWhen auto-import a ref, inline operations won't be auto-unwrapped.\n\nexport const counter = ref(0)\n\n<template>\n\n  <!-- this is ok -->\n\n  <div>{{ counter }}</div>\n\n\n\n  <!-- counter here is a ref, this won't work, volar will throw -->\n\n  <div>{{ counter + 1 }}</div>\n\n\n\n  <!-- use this instead -->\n\n  <div>{{ counter.value + 1 }}</div>\n\n</template>\n\n\nWe recommend using Volar for type checking, which will help you to identify the misusage.\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "ungh · UnJS",
    "url": "https://unjs.io/packages/ungh/",
    "html": "ungh\n\nUnlimited access to github API\n\nUnlimited access to GitHub API\n\nWhy UNGH?\n\nAccessing to open source GitHub repository meta-data should be fast, easy, and straightforward. GitHub API is rate limited and requires an authentication token to increase limits. Even by using an API token, we need to share or generate it for each deployment and local development of apps and also deal with (increased) rate limits and deployment caching. GitHub REST API is also complex with (unnecessary) bigger payloads because of backward compatibility.\n\nUNGH provides a simplified, cached, and anonymous layer to make GitHub API more enjoyable!\n\nRoadmap\n Hosted MVP service (powered by cloudflare workers and KV)\n Publish ungh js client to NPM (#4)\n Implement token pool and open token donations (#5)\n Mark API as stable\n\nNote: This project is still under development and API might change.\n\nAPI\n/repos/{owner}/{name}\n\nGitHub repository information.\n\nExample: https://ungh.cc/repos/unjs/h3\n\n{\n\n  \"repo\": {\n\n    \"id\": 313641207,\n\n    \"name\": \"h3\",\n\n    \"repo\": \"unjs/h3\",\n\n    \"description\": \"Minimal h(ttp) framework built for high performance and portability ⚡️\",\n\n    \"createdAt\": \"2020-11-17T14:15:44Z\",\n\n    \"updatedAt\": \"2022-11-05T21:38:43Z\",\n\n    \"pushedAt\": \"2022-11-06T06:48:23Z\",\n\n    \"stars\": 1168,\n\n    \"watchers\": 1168,\n\n    \"forks\": 59,\n\n    \"defaultBranch\": \"main\"\n\n  }\n\n}\n\n/repos/{owner}/{name}/contributors\n\nGet repository contributors.\n\nExample: https://ungh.cc/repos/unjs/h3/contributors\n\n{\n\n  \"contributors\": [\n\n    {\n\n      \"id\": 5158436,\n\n      \"username\": \"pi0\",\n\n      \"contributions\": 243\n\n    },\n\n    {\n\n      \"id\": 29139614,\n\n      \"username\": \"renovate[bot]\",\n\n      \"contributions\": 41\n\n    }\n\n  ]\n\n}\n\n/repos/{owner}/{name}/files/{branch}\n\nGet repository files tree on specific branch.\n\nExample: https://ungh.cc/repos/unjs/h3/files/main\n\n{\n\n  \"meta\": {\n\n    \"sha\": \"501f0c6e623ea827d47691046f3c7319f5ac4651\"\n\n  },\n\n  \"files\": [\n\n    {\n\n      \"path\": \"README.md\",\n\n      \"mode\": \"100644\",\n\n      \"sha\": \"4c2b9ce4bccd6e046cd71be1a8c5e53a62778858\",\n\n      \"size\": 5782\n\n    }\n\n  ]\n\n}\n\n/repos/{owner}/{name}/files/{branch}/{...path}\n\nGet file contents from a repository. If path ends with .md, an additional html field with rendered markup will be appended.\n\nExample: https://ungh.cc/repos/unjs/h3/files/main/README.md\n\n{\n\n  \"meta\": {\n\n    \"url\": \"https://raw.githubusercontent.com/unjs/h3/main/README.md\"\n\n  },\n\n  \"file\": {\n\n    \"contents\": \"...\",\n\n    \"html\": \"...\"\n\n  }\n\n}\n\n/repos/{owner}/{name}/readme\n\nGet repository readme file on main branch (not cached)\n\nExample: https://ungh.cc/repos/unjs/h3/readme\n\n{\n\n  \"html\": \"<p><a href=\\\"https://npmjs.com/package/h3\\\" rel=\\\"nofollow\\\"><img...\",\n\n  \"markdown\": \"[![npm downloads](https://img.shields.io....\"\n\n}\n\n/repos/{owner}/{name}/releases\n\nGet repository releases.\n\nExample: https://ungh.cc/repos/nuxt/framework/releases\n\n{\n\n  \"releases\": [\n\n    {\n\n      \"id\": 82066265,\n\n      \"tag\": \"v3.0.0-rc.13\",\n\n      \"author\": \"pi0\",\n\n      \"name\": \"v3.0.0-rc.13\",\n\n      \"draft\": false,\n\n      \"prerelease\": false,\n\n      \"createdAt\": \"2022-11-04T11:37:49Z\",\n\n      \"publishedAt\": \"2022-11-04T11:41:59Z\",\n\n      \"markdown\": \"....\",\n\n      \"html\": \"...\"\n\n    }\n\n  ]\n\n}\n\n/repos/{owner}/{name}/releases/latest\n\nGet latest repository release.\n\nExample: https://ungh.cc/repos/nuxt/framework/releases/latest\n\n{\n\n  \"release\": {\n\n    \"id\": 82066265,\n\n    \"tag\": \"v3.0.0-rc.13\",\n\n    \"author\": \"pi0\",\n\n    \"name\": \"v3.0.0-rc.13\",\n\n    \"draft\": false,\n\n    \"prerelease\": false,\n\n    \"createdAt\": \"2022-11-04T11:37:49Z\",\n\n    \"publishedAt\": \"2022-11-04T11:41:59Z\",\n\n    \"markdown\": \"....\",\n\n    \"html\": \"...\"\n\n  }\n\n}\n\n/repos/{owner}/{name}/branches\n\nGet all the branches of a repository\n\nExample: https://ungh.cc/repos/unjs/ungh/branches\n\n{\n\n  \"branches\": [\n\n    {\n\n      \"name\": \"main\",\n\n      \"commit\": {\n\n        \"sha\": \"2eb6bff64caf0d18f082adde7606c4702513870b\",\n\n        \"url\": \"https://api.github.com/repos/unjs/ungh/commits/2eb6bff64caf0d18f082adde7606c4702513870b\"\n\n      },\n\n      \"protected\": true\n\n    },\n\n    {\n\n      \"name\": \"renovate/all-minor-patch\",\n\n      \"commit\": {\n\n        \"sha\": \"61140d05f66cd6b217f2475ad84e2d251ed7de05\",\n\n        \"url\": \"https://api.github.com/repos/unjs/ungh/commits/61140d05f66cd6b217f2475ad84e2d251ed7de05\"\n\n      },\n\n      \"protected\": false\n\n    },\n\n    {\n\n      \"name\": \"renovate/typescript-5.x\",\n\n      \"commit\": {\n\n        \"sha\": \"19b23fca2088722bbb41a7238bf8bd5272799718\",\n\n        \"url\": \"https://api.github.com/repos/unjs/ungh/commits/19b23fca2088722bbb41a7238bf8bd5272799718\"\n\n      },\n\n      \"protected\": false\n\n    }\n\n  ]\n\n}\n\n/orgs/{owner}\n\nGitHub organization information.\n\nExample: https://ungh.cc/orgs/unjs\n\n{\n\n  \"org\": {\n\n    \"id\": 80154025,\n\n    \"name\": \"unjs\",\n\n    \"description\": \"Unified JavaScript Tools\"\n\n  }\n\n}\n\n/orgs/{owner}/repos\n\nGitHub organization repositories overview.\n\nExample: https://ungh.cc/orgs/unjs/repos\n\n{\n\n  \"repos\": [\n\n    {\n\n      \"id\": 97751746,\n\n      \"name\": \"redirect-ssl\",\n\n      \"repo\": \"unjs/redirect-ssl\",\n\n      \"description\": \"Connect/Express middleware to enforce https using is-https\",\n\n      \"createdAt\": \"2017-07-19T19:04:11Z\",\n\n      \"updatedAt\": \"2022-09-22T09:47:25Z\",\n\n      \"pushedAt\": \"2022-04-08T20:29:48Z\",\n\n      \"stars\": 93,\n\n      \"watchers\": 93,\n\n      \"forks\": 14\n\n    }\n\n  ]\n\n}\n\n/stars/{repos}\n\nGet star information for one or more repositories or organizations.\n\nMultiple items can be separated by either , or + or (space). Each item can be either {owner}/{org} to specify one repository or {owner}/* to specify all organization repositories.\n\nExample: https://ungh.cc/stars/nuxt/nuxt.js+nuxt/framework\n\n{\n\n  \"totalStars\": 51524,\n\n  \"stars\": {\n\n    \"nuxt/nuxt.js\": 41560,\n\n    \"nuxt/framework\": 9964\n\n  }\n\n}\n\n/users/find/{query}\n\nFind one github user by email or other query.\n\nExample: https://ungh.cc/users/find/pooya@pi0.io\n\n{\n\n  \"user\": {\n\n    \"id\": 5158436,\n\n    \"username\": \"pi0\"\n\n  }\n\n}\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "unenv · UnJS",
    "url": "https://unjs.io/packages/unenv/",
    "html": "unenv\n\nConvert JavaScript code to be runtime agnostic\n\nunenv is a framework agnostic system that allows converting JavaScript code to be platform agnostic and working in any environment including Browsers, Workers, Node.js or pure JavaScript runtime.\n\nInstall\n# Using npm\n\nnpm i -D unenv\n\n\n\n# Using yarn\n\nyarn add --dev unenv\n\n\n\n# Using pnpm\n\npnpm add -D unenv\n\nUsage\n\nUsing env utility and built-in presets (and nodeless), unenv will provide an abstract configuration that can be used in building pipelines (rollup.js, webpack, etc.).\n\nimport { env, node, nodeless } from \"unenv\";\n\n\n\nconst { alias, inject, polyfill, external } = env(...presets);\n\nPresets\nnode\n\nSuitable to convert universal libraries working in Node.js. (preset)\n\nAdd supports for global fetch API\nSet Node.js built-ins as externals\nnodeless\n\nUsing this preset, we can convert a code that is depending on Node.js to work anywhere else.\n\nBuilt-in Node.js modules\n\nunenv provides a replacement for all Node.js built-ins for cross-platform compatiblity.\n\nModule\tStatus\tSource\nnode:assert\tMocked\t-\nnode:async_hooks\tPolyfilled\tunenv/node/async_hooks\nnode:buffer\tPolyfilled\tunenv/node/buffer\nnode:child_process\tMocked\t-\nnode:cluster\tMocked\t-\nnode:console\tMocked\t-\nnode:constants\tMocked\t-\nnode:crypto\tPolyfilled\tunenv/node/crypto\nnode:dgram\tMocked\t-\nnode:diagnostics_channel\tMocked\t-\nnode:dns\tMocked\t-\nnode:domain\tMocked\t-\nnode:events\tPolyfilled\tunenv/node/events\nnode:fs\tPolyfilled\tunenv/node/fs\nnode:fs/promises\tPolyfilled\tunenv/node/fs/promises\nnode:http2\tMocked\t-\nnode:http\tPolyfilled\tunenv/node/http\nnode:https\tPolyfilled\tunenv/node/https\nnode:inspector\tMocked\t-\nnode:module\tPolyfilled\tunenv/node/module -\nnode:net\tPolyfilled\tunenv/node/net\nnode:os\tMocked\t-\nnode:path\tPolyfilled\tunenv/node/path\nnode:perf_hooks\tMocked\t-\nnode:process\tPolyfilled\tunenv/node/process\nnode:punycode\tMocked\t-\nnode:querystring\tMocked\t-\nnode:readline\tMocked\t-\nnode:repl\tMocked\t-\nnode:stream\tPolyfilled\tunenv/node/stream\nnode:stream/consumers\tMocked\tunenv/node/stream/consumers\nnode:stream/promises\tMocked\tunenv/node/stream/promises\nnode:stream/web\tNative\tunenv/node/stream/web\nnode:string_decoder\tPolyfilled\tunenv/node/string_decoder\nnode:sys\tMocked\t-\nnode:timers\tMocked\t-\nnode:timers/promises\tMocked\t-\nnode:tls\tMocked\t-\nnode:trace_events\tMocked\t-\nnode:tty\tMocked\t-\nnode:url\tPolyfilled\tunenv/node/url\nnode:util\tPolyfilled\tunenv/node/util\nnode:util/types\tPolyfilled\tunenv/node/util/types\nnode:v8\tMocked\t-\nnode:vm\tMocked\t-\nnode:wasi\tMocked\t-\nnode:worker_threads\tMocked\t-\nnode:zlib\tMocked\t-\nnpm packages\n\nunenv provides a replacement for common npm packages for cross platform compatibility.\n\nPackage\tStatus\tSource\nnpm/consola\tUse native console\tunenv/runtime/npm/consola\nnpm/cross-fetch\tUse native fetch\tunenv/runtime/npm/cross-fetch\nnpm/debug\tMocked with console.debug\tunenv/runtime/npm/debug\nnpm/fsevents\tMocked\tunenv/runtime/npm/fsevents\nnpm/inherits\tInlined\tunenv/runtime/npm/inherits\nnpm/mime-db\tMinimized\tunenv/runtime/npm/mime-db\nnpm/mime\tMinimized\tunenv/runtime/npm/mime\nnpm/node-fetch\tUse native fetch\tunenv/runtime/npm/node-fetch\nnpm/whatwg-url\tUse native URL\tunenv/runtime/npm/whatwg-url\nAuto-mocking proxy\nimport MockProxy from \"unenv/runtime/mock/proxy\";\n\n\n\nconsole.log(MockProxy().foo.bar()[0]);\n\n\nAbove package doesn't work outside of Node.js and neither we need any platform specific logic! When aliasing os to mock/proxy-cjs, it will be auto mocked using a Proxy Object which can be recursively traversed like an Object, called like a Function, Iterated like an Array, or instantiated like a Class.\n\nWe use this proxy for auto mocking unimplemented internals. Imagine a package does this:\n\nconst os = require(\"os\");\n\nif (os.platform() === \"windows\") {\n\n  /* do some fix */\n\n}\n\nmodule.exports = () => \"Hello world\";\n\n\nBy aliasing os to unenv/runtime/mock/proxy-cjs, code will be compatible with other platforms.\n\nOther polyfills\n\nPlease check https://raw.githubusercontent.com/unjs/unenv/main/src/runtime to discover other polyfills.\n"
  },
  {
    "title": "unctx · UnJS",
    "url": "https://unjs.io/packages/unctx/",
    "html": "unctx\n\nComposables in vanilla JS\n\nComposition-API in Vanilla js\n\nWhat is unctx?\n\nVue.js introduced an amazing pattern called Composition API that allows organizing complex logic by splitting it into reusable functions and grouping in logical order. unctx allows easily implementing composition API pattern in your javascript libraries without hassle.\n\nUsage\n\nIn your awesome library:\n\nyarn add unctx\n\n# or\n\nnpm install unctx\n\nimport { createContext } from \"unctx\";\n\n\n\nconst ctx = createContext();\n\n\n\nexport const useAwesome = ctx.use;\n\n\n\n// ...\n\nctx.call({ test: 1 }, () => {\n\n  // This is similar to the vue setup function\n\n  // Any function called here can use `useAwesome` to get { test: 1 }\n\n});\n\n\nUser code:\n\nimport { useAwesome } from \"awesome-lib\";\n\n\n\n// ...\n\nfunction setup() {\n\n  const ctx = useAwesome();\n\n}\n\n\nNote: When no context is presented ctx.use will throw an error. Use ctx.tryUse for tolerant usages (return nullable context).\n\nUsing Namespaces\n\nTo avoid issues with multiple version of the library, unctx provides a safe global namespace to access context by key (kept in globalThis). Important: Please use a verbose name for the key to avoid conflict with other js libraries. Using the npm package name is recommended. Using symbols has no effect since it still causes multiple context issues.\n\nimport { useContext, getContext } from \"unctx\";\n\n\n\nconst useAwesome = useContext(\"awesome-lib\");\n\n\n\n// or\n\n// const awesomeContext = getContext('awesome-lib')\n\n\nYou can also create your internal namespace with createNamespace utility for more advanced use cases.\n\nAsync Context\n\nUsing context is only possible in non-async usages and only before the first await statement. This is to make sure context is not shared between concurrent calls.\n\nasync function setup() {\n\n  console.log(useAwesome()); // Returns context\n\n  setTimeout(() => {\n\n    console.log(useAwesome());\n\n  }, 1); // Returns null\n\n  await new Promise((resolve) => setTimeout(resolve, 1000));\n\n  console.log(useAwesome()); // Returns null\n\n}\n\n\nA simple workaround is caching context into a local variable:\n\nasync function setup() {\n\n  const ctx = useAwesome(); // We can directly access cached version of ctx\n\n  await new Promise((resolve) => setTimeout(resolve, 1000));\n\n  console.log(ctx);\n\n}\n\n\nThis is not always an elegant and easy way by making a variable and passing it around. After all, this is the purpose of unctx to make sure context is magically available everywhere in composables!\n\nNative Async Context\n\nUnctx supports Node.js AsyncLocalStorage as a native way to preserve and track async contexts. To enable this mode, you need to set asyncContext: true option and also provides an implementation for AsyncLocalStorage (or provide globalThis.AsyncLocalStorage polyfill).\n\nSee tc39 proposal for async context and cloudflare docs for relevant platform specific docs.\n\nimport { createContext } from \"unctx\";\n\nimport { AsyncLocalStorage } from \"node:async_hooks\";\n\n\n\nconst ctx = createContext({\n\n  asyncContext: true,\n\n  AsyncLocalStorage,\n\n});\n\n\n\nctx.call(\"123\", () => {\n\n  setTimeout(() => {\n\n    // Prints 123\n\n    console.log(ctx.use());\n\n  }, 100);\n\n});\n\nAsync Transform\n\nSince native async context is not supported in all platforms yet, unctx provides a build-time solution that transforms async syntax to automatically restore context after each async/await statement. This requires using a bundler such as Rollup, Vite, or Webpack.\n\nImport and register transform plugin:\n\nimport { unctxPlugin } from \"unctx/plugin\";\n\n\n\n// Rollup\n\n// TODO: Add to rollup configuration\n\nunctxPlugin.rollup();\n\n\n\n// Vite\n\n// TODO: Add to vite configuration\n\nunctxPlugin.vite();\n\n\n\n// Webpack\n\n// TODO: Add to webpack configuration\n\nunctxPlugin.webpack();\n\n\nUse ctx.callAsync instead of ctx.call:\n\nawait ctx.callAsync(\"test\", setup);\n\n\nAny async function that requires context, should be wrapped with withAsyncContext:\n\nimport { withAsyncContext } from \"unctx\";\n\n\n\nconst setup = withAsyncContext(async () => {\n\n  console.log(useAwesome()); // Returns context\n\n  await new Promise((resolve) => setTimeout(resolve, 1000));\n\n  console.log(useAwesome()); // Still returns context with dark magic!\n\n});\n\nSingleton Pattern\n\nIf you are sure it is safe to use a shared instance (not depending to request), you can also use ctx.set and ctx.unset for a singleton pattern.\n\nNote: You cannot combine set with call. Always use unset before replacing the instance otherwise you will get Context conflict error.\n\nimport { createContext } from \"unctx\";\n\n\n\nconst ctx = createContext();\n\nctx.set(new Awesome());\n\n\n\n// Replacing instance without unset\n\n// ctx.set(new Awesome(), true)\n\n\n\nexport const useAwesome = ctx.use;\n\nTyped Context\n\nA generic type exists on all utilities to be set for instance/context type for typescript support.\n\n// Return type of useAwesome is Awesome | null\n\nconst { use: useAwesome } = createContext<Awesome>();\n\nUnder the hood\n\nThe composition of functions is possible using temporary context injection. When calling ctx.call(instance, cb), instance argument will be stored in a temporary variable then cb is called. Any function inside cb, can then implicitly access the instance by using ctx.use (or useAwesome)\n\nPitfalls\n\ncontext can be only used before first await:\n\nPlease check Async Context section.\n\nContext conflict error:\n\nIn your library, you should only keep one call() running at a time (unless calling with the same reference for the first argument)\n\nFor instance, this makes an error:\n\nctx.call({ test: 1 }, () => {\n\n  ctx.call({ test: 2 }, () => {\n\n    // Throws error!\n\n  });\n\n});\n"
  },
  {
    "title": "uncrypto · UnJS",
    "url": "https://unjs.io/packages/uncrypto/",
    "html": "uncrypto\n\nSingle API for Web Crypto API and Crypto Subtle working in Node.js, Browsers and other runtimes\n\nThis library provides a single api to use web-crypto and Subtle Crypto in both Node.js using Crypto Module and Web targets using Web Crypto API using Conditional Exports.\n\nRequirements:\n\nNode.js: Version 15 and above (this library provides no polyfills for older versions!)\nBrowser: Secure Context (HTTPS/Localhost) in Supported Browsers\nOther Runtimes: Exposed globalThis.crypto and globalThis.crypto.subtle. (you can polyfill if neeeded)\nUsage\n\nInstall package:\n\n# npm\n\nnpm install uncrypto\n\n\n\n# yarn\n\nyarn add uncrypto\n\n\n\n# pnpm\n\npnpm install uncrypto\n\n\nImport:\n\n// ESM\n\nimport { subtle, randomUUID, getRandomValues } from \"uncrypto\";\n\n\n\n// CommonJS\n\nconst { subtle, randomUUID, getRandomValues } = require(\"uncrypto\");\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "unbuild · UnJS",
    "url": "https://unjs.io/packages/unbuild/",
    "html": "unbuild\n\nAn unified javascript build system.\n\nA unified javascript build system\n\n📦 Optimized bundler\n\nRobust rollup based bundler that supports typescript and generates commonjs and module formats + type declarations.\n\n🪄 Automated config\n\nAutomagically infer build config and entries from package.json.\n\n📁 Bundleless build\n\nIntegration with mkdist for generating bundleless dists with file-to-file transpilation.\n\n✨ Passive watcher\n\nStub dist once using jiti and you can try and link your project without needing to watch and rebuild during development.\n\n✍ Untype Generator\n\nIntegration with untyped.\n\n✔️ Secure builds\n\nAutomatically check for various build issues such as potential missing and unused dependencies and fail CI.\n\nCLI output also includes output size and exports for quick inspection.\n\nUsage\n\nCreate src/index.ts:\n\nexport const log = (...args) => {\n\n  console.log(...args);\n\n};\n\n\nUpdate package.json:\n\n{\n\n  \"type\": \"module\",\n\n  \"exports\": {\n\n    \".\": {\n\n      \"import\": \"./dist/index.mjs\",\n\n      \"require\": \"./dist/index.cjs\"\n\n    }\n\n  },\n\n  \"main\": \"./dist/index.cjs\",\n\n  \"types\": \"./dist/index.d.ts\",\n\n  \"files\": [\"dist\"]\n\n}\n\n\nNote You can find a more complete example in unjs/template for project setup.\n\nBuild with unbuild:\n\nnpx unbuild\n\n\nConfiguration is automatically inferred from fields in package.json mapped to src/ directory. For more control, continue with next section.\n\nConfiguration\n\nCreate build.config.ts:\n\nexport default {\n\n  entries: [\"./src/index\"],\n\n};\n\n\nYou can either use unbuild key in package.json or build.config.{js,cjs,mjs,ts,mts,cts,json} to specify configuration.\n\nSee options here.\n\nExample:\n\nimport { defineBuildConfig } from \"unbuild\";\n\n\n\nexport default defineBuildConfig({\n\n  // If entries is not provided, will be automatically inferred from package.json\n\n  entries: [\n\n    // default\n\n    \"./src/index\",\n\n    // mkdist builder transpiles file-to-file keeping original sources structure\n\n    {\n\n      builder: \"mkdist\",\n\n      input: \"./src/package/components/\",\n\n      outDir: \"./build/components\",\n\n    },\n\n  ],\n\n\n\n  // Change outDir, default is 'dist'\n\n  outDir: \"build\",\n\n\n\n  // Generates .d.ts declaration file\n\n  declaration: true,\n\n});\n\n\nOr with multiple builds you can declare an array of configs:\n\nimport { defineBuildConfig } from \"unbuild\";\n\n\n\nexport default defineBuildConfig([\n\n  {\n\n    // If entries is not provided, will be automatically inferred from package.json\n\n    entries: [\n\n      // default\n\n      \"./src/index\",\n\n      // mkdist builder transpiles file-to-file keeping original sources structure\n\n      {\n\n        builder: \"mkdist\",\n\n        input: \"./src/package/components/\",\n\n        outDir: \"./build/components\",\n\n      },\n\n    ],\n\n\n\n    // Change outDir, default is 'dist'\n\n    outDir: \"build\",\n\n\n\n    /**\n\n     * * `compatible` means \"src/index.ts\" will generate \"dist/index.d.mts\", \"dist/index.d.cts\" and \"dist/index.d.ts\".\n\n     * * `node16` means \"src/index.ts\" will generate \"dist/index.d.mts\" and \"dist/index.d.cts\".\n\n     * * `true` is equivalent to `compatible`.\n\n     * * `false` will disable declaration generation.\n\n     * * `undefined` will auto detect based on \"package.json\". If \"package.json\" has \"types\" field, it will be `\"compatible\"`, otherwise `false`.\n\n     */\n\n    declaration: \"compatible\",\n\n  },\n\n  {\n\n    name: \"minified\",\n\n    entries: [\"./src/index\"],\n\n    outDir: \"build/min\",\n\n    rollup: {\n\n      esbuild: {\n\n        minify: true,\n\n      },\n\n    },\n\n  },\n\n]);\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "ufo · UnJS",
    "url": "https://unjs.io/packages/ufo/",
    "html": "ufo\n\nURL utils for humans.\n\nURL utils for humans.\n\nInstall\n\nInstall using npm or your favourite package manager:\n\nnpm i ufo\n\n\nImport:\n\n// CommonJS\n\nconst { normalizeURL, joinURL } = require('ufo')\n\n\n\n// ESM\n\nimport { normalizeURL, joinURL } from 'ufo'\n\n\n\n// Deno\n\nimport { parseURL } from 'https://unpkg.com/ufo/dist/index.mjs'\n\n\nNotice: You may need to transpile package and add URL polyfill for legacy environments\n\nUsage\nnormalizeURL\nEnsures URL is properly encoded\nEnsures pathname starts with slash\nPreserves protocol/host if provided\nnormalizeURL('test?query=123 123#hash, test')\n\n// test?query=123%20123#hash,%20test\n\n\n\nnormalizeURL('http://localhost:3000')\n\n// http://localhost:3000/\n\njoinURL\njoinURL('a', '/b', '/c')\n\n// a/b/c\n\nresolveURL\nresolveURL('http://foo.com/foo?test=123#token', 'bar', 'baz')\n\n// http://foo.com/foo/bar/baz?test=123#token\n\nparseURL\nparseURL('http://foo.com/foo?test=123#token')\n\n// { protocol: 'http:', auth: '', host: 'foo.com', pathname: '/foo', search: '?test=123', hash: '#token' }\n\n\n\nparseURL('foo.com/foo?test=123#token')\n\n// { pathname: 'foo.com/foo', search: '?test=123', hash: '#token' }\n\n\n\nparseURL('foo.com/foo?test=123#token', 'https://')\n\n// { protocol: 'https:', auth: '', host: 'foo.com', pathname: '/foo', search: '?test=123', hash: '#token' }\n\nstringifyParsedURL\nconst obj = parseURL('http://foo.com/foo?test=123#token')\n\nobj.host = 'bar.com'\n\n\n\nstringifyParsedURL(obj)\n\n// http://bar.com/foo?test=123#token\n\nwithQuery\nwithQuery('/foo?page=a', { token: 'secret' })\n\n// /foo?page=a&token=secret\n\ngetQuery\ngetQuery('http://foo.com/foo?test=123&unicode=%E5%A5%BD')\n\n// { test: '123', unicode: '好' }\n\nparseFilename\n// Result: filename.ext\n\nparseFilename('http://example.com/path/to/filename.ext')\n\n\n\n// Result: undefined\n\nparseFilename('/path/to/.hidden-file', { strict: true })\n\n$URL\n\nImplementing URL interface with improvements:\n\nSupporting schemeless and hostless URLs\nSupporting relative URLs\nPreserving trailing-slash status\nDecoded and mutable class properties (protocol, host, auth, pathname, query, hash)\nConsistent URL parser independent of environment\nConsistent encoding independent of environment\nPunycode support for host encoding\nnew $URL('http://localhost:3000/hello?world=true')\n\n// { protocol: 'http:', host: 'localhost:3000', auth: '', pathname: '/hello', query: { world: 'true' }, hash: '' }\n\nwithTrailingSlash\n\nEnsures url ends with a trailing slash.\n\nwithTrailingSlash('/foo')\n\n// /foo/\n\n\nSet the second option to true to support query parameters:\n\nwithTrailingSlash('/path?query=true', true)\n\n// /path/?query=true\n\nwithoutTrailingSlash\n\nEnsures url does not ends with a trailing slash.\n\nwithoutTrailingSlash('/foo/')\n\n// /foo\n\n\nSet the second option to true to support query parameters:\n\nwithoutTrailingSlash('/path/?query=true', true)\n\n// /path?query=true\n\ncleanDoubleSlashes\n\nEnsures url does not have double slash (except for protocol).\n\ncleanDoubleSlashes('//foo//bar//')\n\n// /foo/bar/\n\n\n\ncleanDoubleSlashes('http://example.com/analyze//http://localhost:3000//')\n\n// http://example.com/analyze/http://localhost:3000/\n\nisSamePath\n\nCheck two paths are equal or not. Trailing slash and encoding are normalized before comparison.\n\nisSamePath('/foo', '/foo/')\n\n// true\n\nisRelative\n\nCheck if a path starts with ./ or ../.\n\nisRelative('./foo')\n\n// true\n\nwithHttp\n\nEnsures url protocol is http\n\nwithHttp('https://example.com')\n\n// http://example.com\n\nwithHttps\n\nEnsures url protocol is https\n\nwithHttps('http://example.com')\n\n// https://example.com\n\nwithProtocol\n\nChanges url protocol passed as second argument\n\nwithProtocol('http://example.com', 'ftp://')\n\n// ftp://example.com\n\nwithoutProtocol\n\nRemoves url protocol\n\nwithoutProtocol('http://example.com')\n\n// example.com\n\nisEqual\n\nCompare two URLs regardless of their slash condition or encoding:\n\nisEqual('/foo', 'foo')\n\n// true\n\nisEqual('foo/', 'foo')\n\n// true\n\nisEqual('/foo bar', '/foo%20bar')\n\n// true\n\n\n\n// Strict compare\n\nisEqual('/foo', 'foo', { leadingSlash: true })\n\n// false\n\nisEqual('foo/', 'foo', { trailingSlash: true })\n\n// false\n\nisEqual('/foo bar', '/foo%20bar', { encoding: true })\n\n// false\n"
  },
  {
    "title": "theme-colors · UnJS",
    "url": "https://unjs.io/packages/theme-colors/",
    "html": "theme-colors\n\nEasily generate color shades for themes\n\nEasily generate color shades for themes\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install theme-colors\n\n\n\n# yarn\n\nyarn add theme-colors\n\n\n\n# pnpm\n\npnpm install theme-colors\n\n\n\n# bun\n\nbun install theme-colors\n\n\nImport:\n\n// ESM\n\nimport { getColors } from \"theme-colors\";\n\n\n\n// CommonJS\n\nconst { getColors } = require(\"theme-colors\");\n\n\n\nconst theme = getColors(\"#ABABAB\");\n\n// Or using RGB\n\nconst theme = getColors(\"172,172,172\");\n\n\nThis will generate the following shades:\n\n{\n\n  50: '#FBFBFB',\n\n  100: '#F7F7F7',\n\n  200: '#EAEAEA',\n\n  300: '#DDDDDD',\n\n  400: '#C4C4C4',\n\n  500: '#ABABAB',\n\n  600: '#9A9A9A',\n\n  700: '#676767',\n\n  800: '#4D4D4D',\n\n  900: '#333333',\n\n  950: '#222222',\n\n}\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "std-env · UnJS",
    "url": "https://unjs.io/packages/std-env/",
    "html": "std-env\n\nRuntime agnostic JS utils\n\nRuntime agnostic JS utils\n\nInstallation\n# Using npm\n\nnpm i std-env\n\n\n\n# Using pnpm\n\npnpm i std-env\n\n\n\n# Using yarn\n\nyarn add std-env\n\nUsage\n// ESM\n\nimport { env, isDevelopment, isProduction } from \"std-env\";\n\n\n\n// CommonJS\n\nconst { env, isDevelopment, isProduction } = require(\"std-env\");\n\nFlags\nhasTTY\nhasWindow\nisDebug\nisDevelopment\nisLinux\nisMacOS\nisMinimal\nisProduction\nisTest\nisWindows\nplatform\nisColorSupported\nnodeVersion\nnodeMajorVersion\n\nYou can read more about how each flag works from https://raw.githubusercontent.com/unjs/std-env/main/src/flags.ts.\n\nProvider Detection\n\nstd-env can automatically detect the current runtime provider based on environment variables.\n\nYou can use isCI and platform exports to detect it:\n\nimport { isCI, provider, providerInfo } from \"std-env\";\n\n\n\nconsole.log({\n\n  isCI, // true\n\n  provider, // \"github_actions\"\n\n  providerInfo, // { name: \"github_actions\", isCI: true }\n\n});\n\n\nList of well known providers can be found from https://raw.githubusercontent.com/unjs/std-env/main/src/providers.ts.\n\nRuntime Detection\n\nstd-env can automatically detect the current JavaScript runtime based on global variables, following the WinterCG Runtime Keys proposal:\n\nimport { runtime, runtimeInfo } from \"std-env\";\n\n\n\n// \"\" | \"node\" | \"deno\" | \"bun\" | \"workerd\" | \"lagon\" ...\n\nconsole.log(runtime);\n\n\n\n// { name: \"node\" }\n\nconsole.log(runtimeInfo);\n\n\nYou can also use individual named exports for each runtime detection:\n\nisNetlify\nisEdgeLight\nisWorkerd\nisDeno\nisLagon\nisNode\nisBun\nisFastly\n\nList of well known providers can be found from https://raw.githubusercontent.com/unjs/std-env/main/src/runtimes.ts.\n\nPlatform-Agnostic env\n\nstd-env provides a lightweight proxy to access environment variables in a platform agnostic way.\n\nimport { env } from \"std-env\";\n\nPlatform-Agnostic process\n\nstd-env provides a lightweight proxy to access process object in a platform agnostic way.\n\nimport { process } from \"std-env\";\n"
  },
  {
    "title": "serve-placeholder · UnJS",
    "url": "https://unjs.io/packages/serve-placeholder/",
    "html": "serve-placeholder\n\nSmart placeholder for missing assets\n\nSmart placeholder for missing assets\n\nWhy?\n\n💵 Rendering Errors is costly\n\nServing each 404 page for assets adds extra load to the server and increases crashing chances. This is crucial for setups with server-side-rendering and removes additional SSR loads when assets like robots.txt or favicon.ico don't exist.\n\n👌 Meaningful Responses\n\nWe can always send a better 404 response than an HTML page by knowing file extensions. For example, we send a fallback transparent 1x1 image for image extensions.\n\n🔍 SEO Friendly\n\nInstead of indexing invalid URLs with HTML pages, we properly send 404 and the right content type.\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install serve-placeholder\n\n\n\n# yarn\n\nyarn install serve-placeholder\n\n\n\n# pnpm\n\npnpm install serve-placeholder\n\n\nImport:\n\n// ESM\n\nimport { servePlaceholder } from 'serve-placeholder'\n\n\n\n// CommonJS\n\nconst { servePlaceholder } = require('serve-placeholder')\n\n\nCreate and add server middleware between serve-static and router middleware:\n\napp.use('/assets', serveStatic(..))\n\n++ app.use('/assets', servePlaceholder())\n\napp.use('/', router)\n\n\nAdditionally, we can have a default placeholder for arbitrary routes which handles known extensions assuming other routes have no extension:\n\napp.use('/assets', serveStatic(..))\n\napp.use('/assets', servePlaceholder())\n\n++ app.use('/', placeholder({ skipUnknown: true }))\n\napp.use('/', router)\n\nOptions\nhandlers\n\nA mapping from file extensions to the handler. Extensions should start with dot like .js.\n\nYou can disable any of the handlers by setting the value to null\n\nIf the value of a handler is set to false, the middleware will be ignored for that extension.\n\nstatusCode\nDefault: 404\n\nSets statusCode for all handled responses. Set to false to disable overriding statusCode.\n\nskipUnknown\nDefault: false\n\nSkip middleware when no handler is defined for the current request.\n\nPlease note that if this option is set to true, then default handler will be disabled!\n\nplaceholders\nType: Object\n\nA mapping from handler to placeholder. Values can be String or Buffer. You can disable any of the placeholders by setting the value to false.\n\nmimes\nType: Object\n\nA mapping from handler to the mime type. Mime type will be set as Content-Type header. You can disable sending any of the mimes by setting the value to false.\n\ncacheHeaders\nDefault: true\n\nSet headers to prevent accidentally caching 404 resources.\n\nWhen enabled, these headers will be sent:\n\n{\n\n  'cache-control': 'no-cache, no-store, must-revalidate',\n\n  'expires': '0',\n\n  'pragma': 'no-cache'\n\n}\n\nplaceholderHeader\nDefault: true\n\nSets an X-Placeholder header with value of handler name.\n\nDefaults\n\nThese are default handlers. You can override every of them using provided options.\n\nHandler\tExtensions\tMime type\tPlaceholder\ndefault\tany unknown extension\t-\t-\ncss\t.css\ttext/css\t/* style not found */\nhtml\t.html, .htm\ttext/html\t<!-- page not found -->\njs\t.js\tapplication/javascript\t/* script not found */\njson\t.json\tapplication/json\t{}\nmap\t.map\tapplication/json\tempty sourcemap v3 json\nplain\t.txt, .text, .md\ttext/plain\tempty\nimage\t.png, .jpg, .jpeg, .gif, .svg, .webp, .bmp, .ico\timage/gif\ttransparent 1x1 image\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "scule · UnJS",
    "url": "https://unjs.io/packages/scule/",
    "html": "scule\n\nString Case Utils\n\nInstall\n\nInstall using npm or yarn:\n\nnpm i scule\n\n\nImport:\n\n// CommonJS\n\nconst { pascalCase } = require(\"scule\");\n\n\n\n// ESM\n\nimport { pascalCase } from \"scule\";\n\n\nNotice: You may need to transpile package for legacy environments.\n\nUtils\npascalCase(str)\n\nSplits string and joins by PascalCase convention:\n\npascalCase(\"foo-bar_baz\");\n\n// FooBarBaz\n\n\nNotice: If an uppercase letter is followed by other uppercase letters (like FooBAR), they are preserved.\n\ncamelCase\n\nSplits string and joins by camelCase convention:\n\ncamelCase(\"foo-bar_baz\");\n\n// fooBarBaz\n\nkebabCase(str)\n\nSplits string and joins by kebab-case convention:\n\nkebabCase(\"fooBar_Baz\");\n\n// foo-bar-baz\n\n\nNotice: It does not preserve case.\n\nsnakeCase\n\nSplits string and joins by snake_case convention:\n\nsnakeCase(\"foo-barBaz\");\n\n// foo_bar_baz\n\nupperFirst(str)\n\nConverts first character to upper case:\n\nupperFirst(\"hello world!\");\n\n// Hello world!\n\nlowerFirst(str)\n\nConverts first character to lower case:\n\nlowerFirst(\"Hello world!\");\n\n// hello world!\n\nsplitByCase(str, splitters?)\nSplits string by the splitters provided (default: ['-', '_', '/', '.'])\nSplits when case changes from lower to upper or upper to lower\nIgnores numbers for case changes\nCase is preserved in returned value\nIs an irreversible function since splitters are omitted\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "rc9 · UnJS",
    "url": "https://unjs.io/packages/rc9/",
    "html": "rc9\n\nRead/Write config couldn't be easier!\n\nRead/Write config couldn't be easier!\n\nInstall\n\nInstall using npm or yarn:\n\nnpm i rc9\n\n# or\n\nyarn add rc9\n\n\nImport into your Node.js project:\n\n// CommonJS\n\nconst { read, write, update } = require('rc9')\n\n\n\n// ESM\n\nimport { read, write, update } from 'rc9'\n\nUsage\n\n.conf:\n\ndb.username=db username\n\ndb.password=db pass\n\ndb.enabled=true\n\n\nUpdate config:\n\nupdate({ 'db.enabled': true }) // or update(..., { name: '.conf' })\n\n\nPush to an array:\n\nupdate({ 'modules[]': 'test' })\n\n\nRead/Write config:\n\nconst config = read() // or read('.conf')\n\n\n\n// config = {\n\n//   db: {\n\n//     username: 'db username',\n\n//     password: 'db pass',\n\n//     enabled: true\n\n//   }\n\n// }\n\n\n\nconfig.enabled = false\n\nwrite(config) // or write(config, '.conf')\n\n\nUser Config:\n\nIt is common to keep config in user home directory (MacOS: /Users/{name}, Linux: /home/{name}, Windows: C:\\users\\{name})\n\nyou can use readUser/writeuser/updateUser shortcuts to quickly do this:\n\nwriteUser({ token: 123 }, '.zoorc') // Will be saved in {home}/.zoorc\n\n\n\nconst conf = readUser('.zoorc') // { token: 123 }\n\nUnflatten\n\nRC uses flat to automatically flat/unflat when writing and reading rcfile.\n\nIt means that you can use . for keys to define objects. Some examples:\n\nhello.world = true <=> { hello: { world: true }\ntest.0 = A <=> tags: [ 'A' ]\n\nNote: If you use keys that can override like x= and x.y=, you can disable this feature by passing flat: true option.\n\nTip: You can use keys ending with [] to push to an array like test[]=A\n\nNative Values\n\nRC uses destr to convert values into native javascript values.\n\nSo reading count=123 results { count: 123 } (instead of { count: \"123\" }) if you want to preserve strings as is, can use count=\"123\".\n\nExports\nconst defaults: RCOptions;\n\nfunction parse(contents: string, options?: RCOptions): RC\n\nfunction parseFile(path: string, options?: RCOptions): RC\n\nfunction read(options?: RCOptions | string): RC;\n\nfunction readUser(options?: RCOptions | string): RC;\n\nfunction serialize(config: RC): string;\n\nfunction write(config: RC, options?: RCOptions | string): void;\n\nfunction writeUser(config: RC, options?: RCOptions | string): void;\n\nfunction update(config: RC, options?: RCOptions | string): RC;\n\nfunction updateUser(config: RC, options?: RCOptions | string): RC;\n\n\nTypes:\n\ntype RC = Record<string, any>;\n\ninterface RCOptions {\n\n    name?: string;\n\n    dir?: string;\n\n    flat?: boolean;\n\n}\n\n\nDefaults:\n\n{\n\n  name: '.conf',\n\n  dir: process.cwd(),\n\n  flat: false\n\n}\n\nWhy RC9?\n\nBe the first one to guess 🐇\n"
  },
  {
    "title": "radix3 · UnJS",
    "url": "https://unjs.io/packages/radix3/",
    "html": "radix3\n\nLightweight and fast router for JavaScript based on Radix Tree\n\nLightweight and fast router for JavaScript based on Radix Tree.\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm i radix3\n\n\n\n# yarn\n\nyarn add radix3\n\n\n\n# pnpm\n\npnpm i radix3\n\n\nImport:\n\n// ESM\n\nimport { createRouter } from \"radix3\";\n\n\n\n// CJS\n\nconst { createRouter } = require(\"radix3\");\n\n\nCreate a router instance and insert routes:\n\nconst router = createRouter(/* options */);\n\n\n\nrouter.insert(\"/path\", { payload: \"this path\" });\n\nrouter.insert(\"/path/:name\", { payload: \"named route\" });\n\nrouter.insert(\"/path/foo/**\", { payload: \"wildcard route\" });\n\nrouter.insert(\"/path/foo/**:name\", { payload: \"named wildcard route\" });\n\n\nMatch route to access matched data:\n\nrouter.lookup(\"/path\");\n\n// { payload: 'this path' }\n\n\n\nrouter.lookup(\"/path/fooval\");\n\n// { payload: 'named route', params: { name: 'fooval' } }\n\n\n\nrouter.lookup(\"/path/foo/bar/baz\");\n\n// { payload: 'wildcard route' }\n\n\n\nrouter.lookup(\"/\");\n\n// null (no route matched for/)\n\nMethods\nrouter.insert(path, data)\n\npath can be static or using :placeholder or ** for wildcard paths.\n\nThe data object will be returned on matching params. It should be an object like { handler } and not containing reserved keyword params.\n\nrouter.lookup(path)\n\nReturns matched data for path with optional params key if mached route using placeholders.\n\nrouter.remove(path)\n\nRemove route matching path.\n\nOptions\n\nYou can initialize router instance with options:\n\nconst router = createRouter({\n\n  strictTrailingSlash: true,\n\n  routes: {\n\n    \"/foo\": {},\n\n  },\n\n});\n\nroutes: An object specifying initial routes to add\nstrictTrailingSlash: By default router ignored trailing slash for matching and adding routes. When set to true, matching with trailing slash is different.\nRoute Matcher\n\nCreates a multi matcher from router tree that can match all routes matching path:\n\nimport { createRouter, toRouteMatcher } from \"radix3\";\n\n\n\nconst router = createRouter({\n\n  routes: {\n\n    \"/foo\": { m: \"foo\" }, // Matches /foo only\n\n    \"/foo/**\": { m: \"foo/**\" }, // Matches /foo/<any>\n\n    \"/foo/bar\": { m: \"foo/bar\" }, // Matches /foo/bar only\n\n    \"/foo/bar/baz\": { m: \"foo/bar/baz\" }, // Matches /foo/bar/baz only\n\n    \"/foo/*/baz\": { m: \"foo/*/baz\" }, // Matches /foo/<any>/baz\n\n  },\n\n});\n\n\n\nconst matcher = toRouteMatcher(router);\n\n\n\nconst matches = matcher.matchAll(\"/foo/bar/baz\");\n\n\n\n// [\n\n//   {\n\n//     \"m\": \"foo/**\",\n\n//   },\n\n//   {\n\n//     \"m\": \"foo/*/baz\",\n\n//   },\n\n//   {\n\n//     \"m\": \"foo/bar/baz\",\n\n//   },\n\n// ]\n\nRoute Matcher Export\n\nIt is also possible to export and then rehydrate a matcher from pre-compiled rules.\n\nimport { exportMatcher, createMatcherFromExport } from \"radix3\";\n\n\n\n// Assuming you already have a matcher\n\n// you can export this to a JSON-type object\n\nconst json = exportMatcher(matcher);\n\n\n\n// and then rehydrate this later\n\nconst newMatcher = createMatcherFromExport(json);\n\n\n\nconst matches = newMatcher.matchAll(\"/foo/bar/baz\");\n\nPerformance\n\nSee benchmark.\n"
  },
  {
    "title": "pathe · UnJS",
    "url": "https://unjs.io/packages/pathe",
    "html": "pathe\n\nDrop-in replacement of the Node.js's path module module that ensures paths are normalized\n\nUniversal filesystem path utils\n\n❓ Why\n\nFor historical reasons, windows followed MS-DOS and using backslash for separating paths rather than slash used for macOS, Linux, and other Posix operating systems. Nowadays, Windows supports both Slash and Backslash for paths. Node.js's built in path module in the default operation of the path module varies based on the operating system on which a Node.js application is running. Specifically, when running on a Windows operating system, the path module will assume that Windows-style paths are being used. This makes inconsistent code behavior between Windows and POSIX. Compared to popular upath, pathe is providing identical exports of Node.js with normalization on all operations and written in modern ESM/Typescript and has no dependency on Node.js!\n\nThis package is a drop-in replacement of the Node.js's path module module and ensures paths are normalized with slash / and work in environments including Node.js.\n\n💿 Usage\n\nInstall using npm or yarn:\n\n# npm\n\nnpm i pathe\n\n\n\n# yarn\n\nyarn add pathe\n\n\n\n# pnpm\n\npnpm i pathe\n\nCopy to clipboard\n\nImport:\n\n// ESM / Typescript\n\nimport { resolve } from 'pathe'\n\n\n\n// CommonJS\n\nconst { resolve } = require('pathe')\n\nCopy to clipboard\n\nRead more about path utils from Node.js documentation and rest assured behavior is ALWAYS like POSIX regardless of your input paths format and running platform!\n\nExtra utilties\n\nPathe exports some extra utilities that do not exist in standard Node.js path module. In order to use them, you can import from pathe/utils subpath:\n\nimport { filename, normalizeAliases, resolveAlias } from 'pathe/utils'\n\nCopy to clipboard"
  },
  {
    "title": "pkg-types · UnJS",
    "url": "https://unjs.io/packages/pkg-types/",
    "html": "pkg-types\n\nNode.js utilities and TypeScript definitions for package.json and tsconfig.json\n\nNode.js utilities and TypeScript definitions for package.json and tsconfig.json\n\n＼⍩⃝／\n\nInstall\n# npm\n\nnpm i pkg-types\n\n\n\n# yarn\n\nyarn add pkg-types\n\n\n\n# pnpm\n\npnpm add pkg-types\n\nUsage\nreadPackageJSON\nimport { readPackageJSON } from 'pkg-types'\n\nconst localPackageJson = await readPackageJSON()\n\n// or\n\nconst packageJson = await readPackageJSON('/fully/resolved/path/to/folder')\n\nwritePackageJSON\nimport { writePackageJSON } from 'pkg-types'\n\n\n\nawait writePackageJSON('path/to/package.json', pkg)\n\nresolvePackageJSON\nimport { resolvePackageJSON } from 'pkg-types'\n\nconst filename = await resolvePackageJSON()\n\n// or\n\nconst packageJson = await resolvePackageJSON('/fully/resolved/path/to/folder')\n\nreadTSConfig\nimport { readTSConfig } from 'pkg-types'\n\nconst tsconfig = await readTSConfig()\n\n// or\n\nconst tsconfig = await readTSConfig('/fully/resolved/path/to/folder')\n\nwriteTSConfig\nimport { writeTSConfig } from 'pkg-types'\n\n\n\nawait writeTSConfig('path/to/tsconfig.json', tsconfig)\n\nresolveTSConfig\nimport { resolveTSConfig } from 'pkg-types'\n\nconst filename = await resolveTSConfig()\n\n// or\n\nconst tsconfig = await resolveTSConfig('/fully/resolved/path/to/folder')\n\nresolveFile\nimport { resolveFile } from 'pkg-types'\n\nconst filename = await resolveFile('README.md', {\n\n  startingFrom: id,\n\n  rootPattern: /^node_modules$/,\n\n  matcher: filename => filename.endsWith('.md'),\n\n})\n\nresolveLockFile\n\nFind path to the lock file (yarn.lock, package-lock.json, pnpm-lock.yaml, npm-shrinkwrap.json) or throws an error.\n\nimport { resolveLockFile } from 'pkg-types'\n\nconst lockfile = await resolveLockFile('.')\n\nfindWorkspaceDir\n\nTry to detect workspace dir by in order:\n\nNearest .git directory\nFarthest lockfile\nFarthest package.json file\n\nIf fails, throws an error.\n\nimport { findWorkspaceDir } from 'pkg-types'\n\nconst workspaceDir = await findWorkspaceDir('.')\n\nTypes\n\nNote: In order to make types working, you need to install typescript as a devDependency.\n\nYou can directly use typed interfaces:\n\nimport type { TSConfig, PackageJSON } from 'pkg-types'\n\n\nYou can also use define utils for type support for using in plain .js files and auto-complete in IDE.\n\nimport type { definePackageJSON } from 'pkg-types'\n\n\n\nconst pkg = definePackageJSON({})\n\nimport type { defineTSConfig } from 'pkg-types'\n\n\n\nconst pkg = defineTSConfig({})\n\nAlternatives\ndominikg/tsconfck"
  },
  {
    "title": "perfect-debounce · UnJS",
    "url": "https://unjs.io/packages/perfect-debounce/",
    "html": "perfect-debounce\n\nDebounce promise-returning & async functions.\n\nImproved debounce function with Promise support.\n\nFeatures\nWell tested debounce implementation\nNative Promise support\nAvoid duplicate calls while promise is being resolved\nConfigurable trailing and leading behavior\nUsage\n\nInstall package:\n\n# npm\n\nnpm install perfect-debounce\n\n\n\n# yarn\n\nyarn add perfect-debounce\n\n\n\n# pnpm\n\npnpm add perfect-debounce\n\n\nImport:\n\n// ESM\n\nimport { debounce } from 'perfect-debounce'\n\n\n\n// CommonJS\n\nconst { debounce } = require('perfect-debounce')\n\n\nDebounce function:\n\nconst debounced = debounce(async () => {\n\n  // Some heavy stuff\n\n}, 25)\n\n\nWhen calling debounced, it will wait at least for 25ms as configured before actually calling our function. This helps to avoid multiple calls.\n\nTo avoid initial wait, we can set leading: true option. It will cause function to be immediately called if there is no other call:\n\nconst debounced = debounce(async () => {\n\n  // Some heavy stuff\n\n}, 25, { leading: true })\n\n\nIf executing async function takes longer than debounce value, duplicate calls will be still prevented a last call will happen. To disable this behavior, we can set trailing: false option:\n\nconst debounced = debounce(async () => {\n\n  // Some heavy stuff\n\n}, 25, { trailing: false })\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "nitro · UnJS",
    "url": "https://unjs.io/packages/nitro",
    "html": "nitro\n\nCreate web servers that run anywhere.\n\nCreate web servers that run anywhere. The open engine powering Nuxt and open to everyone.\n\n🐇 Rapid development with HMR\n😌 Provider agnostic deployments with 15+ built-in presets\n💼 Portable and compact output\n📁 Directory structure conventions\n🤏 Minimal design\n🚀 Code-splitting\n👕 TypeScript support\n💾 Universal storage\n💰 Route caching\n🐱 Hackable\n✨ Auto Imports\n\n📖 Read the documentation to learn more or directly jump to the getting started.\n\nContribution\n\nSee contribution guide.\n"
  },
  {
    "title": "ohash · UnJS",
    "url": "https://unjs.io/packages/ohash/",
    "html": "ohash\n\nSuper fast hashing library based on murmurhash3 written in Vanilla JS\n\nSuper fast hashing library written in Vanilla JS\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install ohash\n\n\n\n# yarn\n\nyarn add ohash\n\n\n\n# pnpm\n\npnpm install ohash\n\n\nImport:\n\n// ESM\n\nimport { hash, objectHash, murmurHash, sha256 } from \"ohash\";\n\n\n\n// CommonJS\n\nconst { hash, objectHash, murmurHash, sha256 } = require(\"ohash\");\n\nhash(object, options?)\n\nConverts object value into a string hash using objectHash and then applies sha256 with Base64 encoding (trimmed by length of 10).\n\nUsage:\n\nimport { hash } from \"ohash\";\n\n\n\n// \"dZbtA7f0lK\"\n\nconsole.log(hash({ foo: \"bar\" }));\n\nobjectHash(object, options?)\n\nConverts a nest object value into a stable and safe string for hashing.\n\nUsage:\n\nimport { objectHash } from \"ohash\";\n\n\n\n// \"object:1:string:3:foo:string:3:bar,\"\n\nconsole.log(objectHash({ foo: \"bar\" }));\n\nisEqual(obj1, obj2, options?)\n\nCompare two objects using reference equality and stable object hashing.\n\nUsage:\n\nimport { isEqual } from \"ohash\";\n\n\n\n// true\n\nconsole.log(isEqual({ a: 1, b: 2 }, { b: 2, a: 1 }));\n\ndiff(obj1, obj2, options?)\n\nCompare two objects with nested hashing. Returns an array of changes.\n\nReturned value is an array of diff entries with $key, $hash, $value and $props. When logging, a string version of changelog is displayed.\n\nUsage:\n\nimport { diff } from \"ohash\";\n\n\n\nconst createObject = () => ({\n\n  foo: \"bar\",\n\n  nested: {\n\n    y: 123,\n\n    bar: {\n\n      baz: \"123\",\n\n    },\n\n  },\n\n});\n\n\n\nconst obj1 = createObject();\n\nconst obj2 = createObject();\n\n\n\nobj2.nested.x = 123;\n\ndelete obj2.nested.y;\n\nobj2.nested.bar.baz = 123;\n\n\n\nconst diff = diff(obj1, obj2);\n\n\n\n// [-] Removed nested.y\n\n// [~] Changed nested.bar.baz from \"123\" to 123\n\n// [+] Added   nested.x\n\nconsole.log(diff(obj1, obj2));\n\nmurmurHash(str)\n\nConverts input string (of any length) into a 32-bit positive integer using MurmurHash3.\n\nUsage:\n\nimport { murmurHash } from \"ohash\";\n\n\n\n// \"2708020327\"\n\nconsole.log(murmurHash(\"Hello World\"));\n\nsha256\n\nCreate a secure SHA 256 digest from input string.\n\nimport { sha256 } from \"ohash\";\n\n\n\n// \"a591a6d40bf420404a011733cfb7b190d62c65bf0bcda32b57b277d9ad9f146e\"\n\nconsole.log(sha256(\"Hello World\"));\n\nsha256base64\n\nCreate a secure SHA 256 digest in Base64 encoding from input string.\n\nimport { sha256base64 } from \"ohash\";\n\n\n\n// \"pZGm1Av0IEBKARczz7exkNYsZb8LzaMrV7J32a2fFG4\"\n\nconsole.log(sha256base64(\"Hello World\"));\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "nypm · UnJS",
    "url": "https://unjs.io/packages/nypm/",
    "html": "nypm\n\nUnified Package Manager for Node.js\n\nUnified Package Manager for Node.js\n\n🚧 This project is under development. Please follow issues for the roadmap. 🚧\n\nWhat does nypm do?\n\n✅ Supports npm, yarn, pnpm and bun out of the box with a unified API\n\n✅ Provides an API interface to interact with package managers\n\n✅ Autodetects project's package manager using package.json and known lockfiles\n\n✅ Auto-installs and use exactly expected version of supported package managers using nodejs/corepack\n\n✅ Minimal implementation\n\nnypm, detects package manager type and version and converts command into package manager CLI arguments. It then uses corepack to execute package manager's command (and download it if necessary).\n\n  +------------------------------------------------+\n  |                nypm                            |\n  +------------------------------------------------+\n  +-----------------------------------+\n  |              Corepack             |\n  +-----------------------------------+\n  +---------+  +---------+  +---------+  +---------+\n  |   npm   |  |  yarn   |  |  pnpm   |  |  bun    |\n  +---------+  +---------+  +---------+  +---------+\n  +------------------------------------------------+\n  |                Node.js project                 |\n  +------------------------------------------------+\n\nCLI Usage\n\nInstall dependencies:\n\nnpx nypm@latest i\n\n\nAdd a dependency:\n\nnpx nypm@latest add defu\n\n\nRemove a dependency:\n\nnpx nypm@latest remove defu\n\nAPI Usage\n\nInstall package:\n\n# npm\n\nnpm install nypm\n\n\n\n# pnpm\n\npnpm install nypm\n\n\n\n# yarn\n\nyarn add nypm\n\n\n\n# bun\n\nbun install nypm\n\n\nImport:\n\n// ESM\n\nimport {\n\n  detectPackageManager,\n\n  installDependencies,\n\n  addDependency,\n\n  addDevDependency,\n\n  removeDependency,\n\n} from \"nypm\";\n\n\n\n// CommonJS\n\nconst {\n\n  detectPackageManager,\n\n  installDependencies,\n\n  addDependency,\n\n  addDevDependency,\n\n  removeDependency,\n\n} = require(\"nypm\");\n\n💻 Development\nClone this repository\nPlay Nyan Cat in the background (really important!)\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev\nRelated Projects\n\nNYPM is inspired from previous attempts and projects for unifying package manager exeperience.\n\npi0/yarnpm\nunjs/lmify\nantfu/ni\nantfu/install-pkg\negoist/dum\nnodejs/corepack"
  },
  {
    "title": "ofetch · UnJS",
    "url": "https://unjs.io/packages/ofetch/",
    "html": "ofetch\n\nA better fetch API. Works on node, browser and workers.\n\nA better fetch API. Works on node, browser, and workers.\n\n🚀 Quick Start\n\nInstall:\n\n# npm\n\nnpm i ofetch\n\n\n\n# yarn\n\nyarn add ofetch\n\n\nImport:\n\n// ESM / Typescript\n\nimport { ofetch } from \"ofetch\";\n\n\n\n// CommonJS\n\nconst { ofetch } = require(\"ofetch\");\n\n✔️ Works with Node.js\n\nWe use conditional exports to detect Node.js and automatically use unjs/node-fetch-native. If globalThis.fetch is available, will be used instead. To leverage Node.js 17.5.0 experimental native fetch API use --experimental-fetch flag.\n\nkeepAlive support\n\nBy setting the FETCH_KEEP_ALIVE environment variable to true, an HTTP/HTTPS agent will be registered that keeps sockets around even when there are no outstanding requests, so they can be used for future requests without having to re-establish a TCP connection.\n\nNote: This option can potentially introduce memory leaks. Please check node-fetch/node-fetch#1325.\n\n✔️ Parsing Response\n\nofetch will smartly parse JSON and native values using destr, falling back to the text if it fails to parse.\n\nconst { users } = await ofetch(\"/api/users\");\n\n\nFor binary content types, ofetch will instead return a Blob object.\n\nYou can optionally provide a different parser than destr, or specify blob, arrayBuffer, or text to force parsing the body with the respective FetchResponse method.\n\n// Use JSON.parse\n\nawait ofetch(\"/movie?lang=en\", { parseResponse: JSON.parse });\n\n\n\n// Return text as is\n\nawait ofetch(\"/movie?lang=en\", { parseResponse: (txt) => txt });\n\n\n\n// Get the blob version of the response\n\nawait ofetch(\"/api/generate-image\", { responseType: \"blob\" });\n\n✔️ JSON Body\n\nIf an object or a class with a .toJSON() method is passed to the body option, ofetch automatically stringifies it.\n\nofetch utilizes JSON.stringify() to convert the passed object. Classes without a .toJSON() method have to be converted into a string value in advance before being passed to the body option.\n\nFor PUT, PATCH, and POST request methods, when a string or object body is set, ofetch adds the default content-type: \"application/json\" and accept: \"application/json\" headers (which you can always override).\n\nAdditionally, ofetch supports binary responses with Buffer, ReadableStream, Stream, and compatible body types. ofetch will automatically set the duplex: \"half\" option for streaming support!\n\nExample:\n\nconst { users } = await ofetch(\"/api/users\", {\n\n  method: \"POST\",\n\n  body: { some: \"json\" },\n\n});\n\n✔️ Handling Errors\n\nofetch Automatically throws errors when response.ok is false with a friendly error message and compact stack (hiding internals).\n\nA parsed error body is available with error.data. You may also use FetchError type.\n\nawait ofetch(\"https://google.com/404\");\n\n// FetchError: [GET] \"https://google/404\": 404 Not Found\n\n//     at async main (/project/playground.ts:4:3)\n\n\nTo catch error response:\n\nawait ofetch(\"/url\").catch((err) => err.data);\n\n\nTo bypass status error catching you can set ignoreResponseError option:\n\nawait ofetch(\"/url\", { ignoreResponseError: true });\n\n✔️ Auto Retry\n\nofetch Automatically retries the request if an error happens and if the response status code is included in retryStatusCodes list:\n\nRetry status codes:\n\n408 - Request Timeout\n409 - Conflict\n425 - Too Early\n429 - Too Many Requests\n500 - Internal Server Error\n502 - Bad Gateway\n503 - Service Unavailable\n504 - Gateway Timeout\n\nYou can specify the amount of retry and delay between them using retry and retryDelay options and also pass a custom array of codes using retryStatusCodes option.\n\nThe default for retry is 1 retry, except for POST, PUT, PATCH, and DELETE methods where ofetch does not retry by default to avoid introducing side effects. If you set a custom value for retry it will always retry for all requests.\n\nThe default for retryDelay is 0 ms.\n\nawait ofetch(\"http://google.com/404\", {\n\n  retry: 3,\n\n  retryDelay: 500, // ms\n\n});\n\n✔️ Timeout\n\nYou can specify timeout in milliseconds to automatically abort a request after a timeout (default is disabled).\n\nawait ofetch(\"http://google.com/404\", {\n\n  timeout: 3000, // Timeout after 3 seconds\n\n});\n\n✔️ Type Friendly\n\nThe response can be type assisted:\n\nconst article = await ofetch<Article>(`/api/article/${id}`);\n\n// Auto complete working with article.id\n\n✔️ Adding baseURL\n\nBy using baseURL option, ofetch prepends it for trailing/leading slashes and query search params for baseURL using ufo:\n\nawait ofetch(\"/config\", { baseURL });\n\n✔️ Adding Query Search Params\n\nBy using query option (or params as alias), ofetch adds query search params to the URL by preserving the query in the request itself using ufo:\n\nawait ofetch(\"/movie?lang=en\", { query: { id: 123 } });\n\n✔️ Interceptors\n\nProviding async interceptors to hook into lifecycle events of ofetch call is possible.\n\nYou might want to use ofetch.create to set shared interceptors.\n\nonRequest({ request, options })\n\nonRequest is called as soon as ofetch is called, allowing you to modify options or do simple logging.\n\nawait ofetch(\"/api\", {\n\n  async onRequest({ request, options }) {\n\n    // Log request\n\n    console.log(\"[fetch request]\", request, options);\n\n\n\n    // Add `?t=1640125211170` to query search params\n\n    options.query = options.query || {};\n\n    options.query.t = new Date();\n\n  },\n\n});\n\nonRequestError({ request, options, error })\n\nonRequestError will be called when the fetch request fails.\n\nawait ofetch(\"/api\", {\n\n  async onRequestError({ request, options, error }) {\n\n    // Log error\n\n    console.log(\"[fetch request error]\", request, error);\n\n  },\n\n});\n\nonResponse({ request, options, response })\n\nonResponse will be called after fetch call and parsing body.\n\nawait ofetch(\"/api\", {\n\n  async onResponse({ request, response, options }) {\n\n    // Log response\n\n    console.log(\"[fetch response]\", request, response.status, response.body);\n\n  },\n\n});\n\nonResponseError({ request, options, response })\n\nonResponseError is the same as onResponse but will be called when fetch happens but response.ok is not true.\n\nawait ofetch(\"/api\", {\n\n  async onResponseError({ request, response, options }) {\n\n    // Log error\n\n    console.log(\n\n      \"[fetch response error]\",\n\n      request,\n\n      response.status,\n\n      response.body\n\n    );\n\n  },\n\n});\n\n✔️ Create fetch with default options\n\nThis utility is useful if you need to use common options across several fetch calls.\n\nNote: Defaults will be cloned at one level and inherited. Be careful about nested options like headers.\n\nconst apiFetch = ofetch.create({ baseURL: \"/api\" });\n\n\n\napiFetch(\"/test\"); // Same as ofetch('/test', { baseURL: '/api' })\n\n💡 Adding headers\n\nBy using headers option, ofetch adds extra headers in addition to the request default headers:\n\nawait ofetch(\"/movies\", {\n\n  headers: {\n\n    Accept: \"application/json\",\n\n    \"Cache-Control\": \"no-cache\",\n\n  },\n\n});\n\n💡 Adding HTTP(S) Agent\n\nIf you need use HTTP(S) Agent, can add agent option with https-proxy-agent (for Node.js only):\n\nimport { HttpsProxyAgent } from \"https-proxy-agent\";\n\n\n\nawait ofetch(\"/api\", {\n\n  agent: new HttpsProxyAgent(\"http://example.com\"),\n\n});\n\n🍣 Access to Raw Response\n\nIf you need to access raw response (for headers, etc), can use ofetch.raw:\n\nconst response = await ofetch.raw(\"/sushi\");\n\n\n\n// response._data\n\n// response.headers\n\n// ...\n\nNative fetch\n\nAs a shortcut, you can use ofetch.native that provides native fetch API\n\nconst json = await ofetch.native(\"/sushi\").then((r) => r.json());\n\n📦 Bundler Notes\nAll targets are exported with Module and CommonJS format and named exports\nNo export is transpiled for the sake of modern syntax\nYou probably need to transpile ofetch, destr, and ufo packages with Babel for ES5 support\nYou need to polyfill fetch global for supporting legacy browsers like using unfetch\n❓ FAQ\n\nWhy export is called ofetch instead of fetch?\n\nUsing the same name of fetch can be confusing since API is different but still, it is a fetch so using the closest possible alternative. You can, however, import { fetch } from ofetch which is auto-polyfill for Node.js and using native otherwise.\n\nWhy not have default export?\n\nDefault exports are always risky to be mixed with CommonJS exports.\n\nThis also guarantees we can introduce more utils without breaking the package and also encourage using ofetch name.\n\nWhy not transpiled?\n\nBy transpiling libraries, we push the web backward with legacy code which is unneeded for most of the users.\n\nIf you need to support legacy users, you can optionally transpile the library in your build pipeline.\n"
  },
  {
    "title": "node-fetch-native · UnJS",
    "url": "https://unjs.io/packages/node-fetch-native/",
    "html": "node-fetch-native\n\nA better redistribution of node-fetch\n\nA redistribution of node-fetch v3 for better backward and forward compatibility.\n\nWhy this package?\n\nWe can no longer require('node-fetch') with latest version. This stopped popular libraries from upgrading and dependency conflicts between node-fetch@2 and node-fetch@3.\nWith upcoming versions of Node.js, native fetch is being supported. We are prepared for native fetch support using this package yet keep supporting older Node versions.\n\nFeatures:\n\n✅ Prefer to native globals when available (See Node.js experimental fetch).\n\n✅ Compact build and less install size with zero dependencies vs\n\n✅ Support both CommonJS (require) and ESM (import) usage\n\n✅ Use native version if imported without node condition using conditional exports with zero bundle overhead\n\n✅ Polyfill support for Node.js\n\nUsage\n\nInstall node-fetch-native dependency:\n\n# npm\n\nnpm i node-fetch-native\n\n\n\n# yarn\n\nyarn add node-fetch-native\n\n\n\n# pnpm\n\npnpm i node-fetch-native\n\n\nYou can now either import or require the dependency:\n\n// ESM\n\nimport fetch from 'node-fetch-native'\n\n\n\n// CommonJS\n\nconst fetch = require('node-fetch-native')\n\n\nMore named exports:\n\n// ESM\n\nimport { fetch, Blob, FormData, Headers, Request, Response, AbortController } from 'node-fetch-native'\n\n\n\n// CommonJS\n\nconst { fetch, Blob, FormData, Headers, Request, Response, AbortController } = require('node-fetch-native')\n\nForce using non-native version\n\nSometimes you want to explicitly use none native (node-fetch) implementation of fetch in case of issues with native/polyfill version of globalThis.fetch with Node.js or runtime environment.\n\nYou have two ways to do this:\n\nSet FORCE_NODE_FETCH environment variable before starting application.\nImport from node-fetch-native/node\nPolyfill support\n\nUsing the polyfill method, we can once ensure global fetch is available in the environment and all files. Natives are always preferred.\n\nNote: I don't recommand this if you are authoring a library! Please prefer explicit methods.\n\n// ESM\n\nimport 'node-fetch-native/polyfill'\n\n\n\n// CJS\n\nrequire('node-fetch-native/polyfill')\n\n\n\n// You can now use fetch() without any import!\n\nAlias to node-fetch\n\nUsing this method, you can ensure all project dependencies and usages of node-fetch can benefit from improved node-fetch-native and won't conflict between node-fetch@2 and node-fetch@3.\n\nnpm\n\nUsing npm overrides:\n\n// package.json\n\n{\n\n  \"overrides\": {\n\n    \"node-fetch\": \"npm:node-fetch-native@latest\"\n\n  }\n\n}\n\nyarn\n\nUsing yarn selective dependency resolutions:\n\n// package.json\n\n{\n\n  \"resolutions\": {\n\n    \"node-fetch\": \"npm:node-fetch-native@latest\"\n\n  }\n\n}\n\npnpm\n\nUsing pnpm.overrides:\n\n// package.json\n\n{\n\n  \"pnpm\": {\n\n    \"overrides\": {\n\n      \"node-fetch\": \"npm:node-fetch-native@latest\"\n\n    }\n\n  }\n\n}\n"
  },
  {
    "title": "mlly · UnJS",
    "url": "https://unjs.io/packages/mlly/",
    "html": "mlly\n\nMissing ECMAScript module utils for Node.js\n\nMissing ECMAScript module utils for Node.js\n\nWhile ESM Modules are evolving in Node.js ecosystem, there are still many required features that are still experimental or missing or needed to support ESM. This package tries to fill in the gap.\n\nUsage\n\nInstall npm package:\n\n# using yarn\n\nyarn add mlly\n\n\n\n# using npm\n\nnpm install mlly\n\n\nNote: Node.js 14+ is recommended.\n\nImport utils:\n\n// ESM\n\nimport {} from \"mlly\";\n\n\n\n// CommonJS\n\nconst {} = require(\"mlly\");\n\nResolving ESM modules\n\nSeveral utilities to make ESM resolution easier:\n\nRespecting ECMAScript Resolver algorithm\nExposed from Node.js implementation\nWindows paths normalized\nSupporting custom extensions and /index resolution\nSupporting custom conditions\nSupport resolving from multiple paths or urls\nresolve / resolveSync\n\nResolve a module by respecting ECMAScript Resolver algorithm (using wooorm/import-meta-resolve).\n\nAdditionally supports resolving without extension and /index similar to CommonJS.\n\nimport { resolve, resolveSync } from \"mlly\";\n\n\n\n// file:///home/user/project/module.mjs\n\nconsole.log(await resolve(\"./module.mjs\", { url: import.meta.url }));\n\n\nResolve options:\n\nurl: URL or string to resolve from (default is pwd())\nconditions: Array of conditions used for resolution algorithm (default is ['node', 'import'])\nextensions: Array of additional extensions to check if import failed (default is ['.mjs', '.cjs', '.js', '.json'])\nresolvePath / resolvePathSync\n\nSimilar to resolve but returns a path instead of URL using fileURLToPath.\n\nimport { resolvePath, resolveSync } from \"mlly\";\n\n\n\n// /home/user/project/module.mjs\n\nconsole.log(await resolvePath(\"./module.mjs\", { url: import.meta.url }));\n\ncreateResolve\n\nCreate a resolve function with defaults.\n\nimport { createResolve } from \"mlly\";\n\n\n\nconst _resolve = createResolve({ url: import.meta.url });\n\n\n\n// file:///home/user/project/module.mjs\n\nconsole.log(await _resolve(\"./module.mjs\"));\n\n\nExample: Ponyfill import.meta.resolve:\n\nimport { createResolve } from \"mlly\";\n\n\n\nimport.meta.resolve = createResolve({ url: import.meta.url });\n\nresolveImports\n\nResolve all static and dynamic imports with relative paths to full resolved path.\n\nimport { resolveImports } from \"mlly\";\n\n\n\n// import foo from 'file:///home/user/project/bar.mjs'\n\nconsole.log(\n\n  await resolveImports(`import foo from './bar.mjs'`, { url: import.meta.url }),\n\n);\n\nSyntax Analyzes\nisValidNodeImport\n\nUsing various syntax detection and heuristics, this method can determine if import is a valid import or not to be imported using dynamic import() before hitting an error!\n\nWhen result is false, we usually need a to create a CommonJS require context or add specific rules to the bundler to transform dependency.\n\nimport { isValidNodeImport } from \"mlly\";\n\n\n\n// If returns true, we are safe to use `import('some-lib')`\n\nawait isValidNodeImport(\"some-lib\", {});\n\n\nAlgorithm:\n\nCheck import protocol - If is data: return true (✅ valid) - If is not node:, file: or data:, return false ( ❌ invalid)\nResolve full path of import using Node.js Resolution algorithm\nCheck full path extension\nIf is .mjs, .cjs, .node or .wasm, return true (✅ valid)\nIf is not .js, return false (❌ invalid)\nIf is matching known mixed syntax (.esm.js, .es.js, etc) return false ( ❌ invalid)\nRead closest package.json file to resolve path\nIf type: 'module' field is set, return true (✅ valid)\nRead source code of resolved path\nTry to detect CommonJS syntax usage\nIf yes, return true (✅ valid)\nTry to detect ESM syntax usage\nif yes, return false ( ❌ invalid)\n\nNotes:\n\nThere might be still edge cases algorithm cannot cover. It is designed with best-efforts.\nThis method also allows using dynamic import of CommonJS libraries considering Node.js has Interoperability with CommonJS.\nhasESMSyntax\n\nDetect if code, has usage of ESM syntax (Static import, ESM export and import.meta usage)\n\nimport { hasESMSyntax } from \"mlly\";\n\n\n\nhasESMSyntax(\"export default foo = 123\"); // true\n\nhasCJSSyntax\n\nDetect if code, has usage of CommonJS syntax (exports, module.exports, require and global usage)\n\nimport { hasCJSSyntax } from \"mlly\";\n\n\n\nhasCJSSyntax(\"export default foo = 123\"); // false\n\ndetectSyntax\n\nTests code against both CJS and ESM.\n\nisMixed indicates if both are detected! This is a common case with legacy packages exporting semi-compatible ESM syntax meant to be used by bundlers.\n\nimport { detectSyntax } from \"mlly\";\n\n\n\n// { hasESM: true, hasCJS: true, isMixed: true }\n\ndetectSyntax('export default require(\"lodash\")');\n\nCommonJS Context\ncreateCommonJS\n\nThis utility creates a compatible CommonJS context that is missing in ECMAScript modules.\n\nimport { createCommonJS } from \"mlly\";\n\n\n\nconst { __dirname, __filename, require } = createCommonJS(import.meta.url);\n\n\nNote: require and require.resolve implementation are lazy functions. createRequire will be called on first usage.\n\nImport/Export Analyzes\n\nTools to quickly analyze ESM syntax and extract static import/export\n\nSuper fast Regex based implementation\nHandle most edge cases\nFind all static ESM imports\nFind all dynamic ESM imports\nParse static import statement\nFind all named, declared and default exports\nfindStaticImports\n\nFind all static ESM imports.\n\nExample:\n\nimport { findStaticImports } from \"mlly\";\n\n\n\nconsole.log(\n\n  findStaticImports(`\n\n// Empty line\n\nimport foo, { bar /* foo */ } from 'baz'\n\n`),\n\n);\n\n\nOutputs:\n\n[\n\n  {\n\n    type: \"static\",\n\n    imports: \"foo, { bar /* foo */ } \",\n\n    specifier: \"baz\",\n\n    code: \"import foo, { bar /* foo */ } from 'baz'\",\n\n    start: 15,\n\n    end: 55,\n\n  },\n\n];\n\nparseStaticImport\n\nParse a dynamic ESM import statement previously matched by findStaticImports.\n\nExample:\n\nimport { findStaticImports, parseStaticImport } from \"mlly\";\n\n\n\nconst [match0] = findStaticImports(`import baz, { x, y as z } from 'baz'`);\n\nconsole.log(parseStaticImport(match0));\n\n\nOutputs:\n\n{\n\n  type: 'static',\n\n  imports: 'baz, { x, y as z } ',\n\n  specifier: 'baz',\n\n  code: \"import baz, { x, y as z } from 'baz'\",\n\n  start: 0,\n\n  end: 36,\n\n  defaultImport: 'baz',\n\n  namespacedImport: undefined,\n\n  namedImports: { x: 'x', y: 'z' }\n\n}\n\nfindDynamicImports\n\nFind all dynamic ESM imports.\n\nExample:\n\nimport { findDynamicImports } from \"mlly\";\n\n\n\nconsole.log(\n\n  findDynamicImports(`\n\nconst foo = await import('bar')\n\n`),\n\n);\n\nfindExports\nimport { findExports } from \"mlly\";\n\n\n\nconsole.log(\n\n  findExports(`\n\nexport const foo = 'bar'\n\nexport { bar, baz }\n\nexport default something\n\n`),\n\n);\n\n\nOutputs:\n\n[\n\n  {\n\n    type: \"declaration\",\n\n    declaration: \"const\",\n\n    name: \"foo\",\n\n    code: \"export const foo\",\n\n    start: 1,\n\n    end: 17,\n\n  },\n\n  {\n\n    type: \"named\",\n\n    exports: \" bar, baz \",\n\n    code: \"export { bar, baz }\",\n\n    start: 26,\n\n    end: 45,\n\n    names: [\"bar\", \"baz\"],\n\n  },\n\n  { type: \"default\", code: \"export default \", start: 46, end: 61 },\n\n];\n\nfindExportNames\n\nSame as findExports but returns array of export names.\n\nimport { findExportNames } from \"mlly\";\n\n\n\n// [ \"foo\", \"bar\", \"baz\", \"default\" ]\n\nconsole.log(\n\n  findExportNames(`\n\nexport const foo = 'bar'\n\nexport { bar, baz }\n\nexport default something\n\n`),\n\n);\n\nresolveModuleExportNames\n\nResolves module and reads its contents to extract possible export names using static analyzes.\n\nimport { resolveModuleExportNames } from \"mlly\";\n\n\n\n// [\"basename\", \"dirname\", ... ]\n\nconsole.log(await resolveModuleExportNames(\"pathe\"));\n\nEvaluating Modules\n\nSet of utilities to evaluate ESM modules using data: imports\n\nAutomatic import rewrite to resolved path using static analyzes\nAllow bypass ESM Cache\nStack-trace support\n.json loader\nevalModule\n\nTransform and evaluates module code using dynamic imports.\n\nimport { evalModule } from \"mlly\";\n\n\n\nawait evalModule(`console.log(\"Hello World!\")`);\n\n\n\nawait evalModule(\n\n  `\n\n  import { reverse } from './utils.mjs'\n\n  console.log(reverse('!emosewa si sj'))\n\n`,\n\n  { url: import.meta.url },\n\n);\n\n\nOptions:\n\nall resolve options\nurl: File URL\nloadModule\n\nDynamically loads a module by evaluating source code.\n\nimport { loadModule } from \"mlly\";\n\n\n\nawait loadModule(\"./hello.mjs\", { url: import.meta.url });\n\n\nOptions are same as evalModule.\n\ntransformModule\nResolves all relative imports will be resolved\nAll usages of import.meta.url will be replaced with url or from option\nimport { transformModule } from \"mlly\";\n\nconsole.log(transformModule(`console.log(import.meta.url)`), {\n\n  url: \"test.mjs\",\n\n});\n\n\nOptions are same as evalModule.\n\nOther Utils\nfileURLToPath\n\nSimilar to url.fileURLToPath but also converts windows backslash \\ to unix slash / and handles if input is already a path.\n\nimport { fileURLToPath } from \"mlly\";\n\n\n\n// /foo/bar.js\n\nconsole.log(fileURLToPath(\"file:///foo/bar.js\"));\n\n\n\n// C:/path\n\nconsole.log(fileURLToPath(\"file:///C:/path/\"));\n\nnormalizeid\n\nEnsures id has either of node:, data:, http:, https: or file: protocols.\n\nimport { ensureProtocol } from \"mlly\";\n\n\n\n// file:///foo/bar.js\n\nconsole.log(normalizeid(\"/foo/bar.js\"));\n\nloadURL\n\nRead source contents of a URL. (currently only file protocol supported)\n\nimport { resolve, loadURL } from \"mlly\";\n\n\n\nconst url = await resolve(\"./index.mjs\", { url: import.meta.url });\n\nconsole.log(await loadURL(url));\n\ntoDataURL\n\nConvert code to data: URL using base64 encoding.\n\nimport { toDataURL } from \"mlly\";\n\n\n\nconsole.log(\n\n  toDataURL(`\n\n  // This is an example\n\n  console.log('Hello world')\n\n`),\n\n);\n\ninteropDefault\n\nReturn the default export of a module at the top-level, alongside any other named exports.\n\n// Assuming the shape { default: { foo: 'bar' }, baz: 'qux' }\n\nimport myModule from \"my-module\";\n\n\n\n// Returns { foo: 'bar', baz: 'qux' }\n\nconsole.log(interopDefault(myModule));\n\nsanitizeURIComponent\n\nReplace reserved characters from a segment of URI to make it compatible with rfc2396.\n\nimport { sanitizeURIComponent } from \"mlly\";\n\n\n\n// foo_bar\n\nconsole.log(sanitizeURIComponent(`foo:bar`));\n\nsanitizeFilePath\n\nSanitize each path of a file name or path with sanitizeURIComponent for URI compatibility.\n\nimport { sanitizeFilePath } from \"mlly\";\n\n\n\n// C:/te_st/_...slug_.jsx'\n\nconsole.log(sanitizeFilePath(\"C:\\\\te#st\\\\[...slug].jsx\"));\n\nparseNodeModulePath\n\nParses an absolute file path in node_modules to three segments:\n\ndir: Path to main directory of package\nname: Package name\nsubpath: The optional package subpath\n\nIt returns an empty object (with partial keys) if parsing fails.\n\nimport { parseNodeModulePath } from \"mlly\";\n\n\n\n// dir: \"/src/a/node_modules/\"\n\n// name: \"lib\"\n\n// subpath: \"./dist/index.mjs\"\n\nconst { dir, name, subpath } = parseNodeModulePath(\n\n  \"/src/a/node_modules/lib/dist/index.mjs\",\n\n);\n\nlookupNodeModuleSubpath\n\nParses an absolute file path in node_modules and tries to reverse lookup (or guess) the original package exports subpath for it.\n\nimport { lookupNodeModuleSubpath } from \"mlly\";\n\n\n\n// subpath: \"./utils\"\n\nconst subpath = lookupNodeModuleSubpath(\n\n  \"/src/a/node_modules/lib/dist/utils.mjs\",\n\n);\n"
  },
  {
    "title": "mongoz · UnJS",
    "url": "https://unjs.io/packages/mongoz/",
    "html": "mongoz\n\nZero Config MongoDB Server\n\nZero Config MongoDB Server for Node.js\n\nWhy?\n\nMongoDB is fantastic but setup for small projects can be lots of trouble.\n\nThis little package does everything necessary to download and start a fresh MongoDB server!\n\nUsage\n\nNote: You need to have Node.js and npm already installed!\n\nNote: Make sure there is not already a local mongodb server listening on default port (2701). If you do, either stop it or use MONGO_PORT environment variable to change the port.\n\nStandalone Server\n\nLet's start a fresh db shall we?\n\nnpx mongoz\n\n\nIt will take few seconds on first time of usage to install and extract mongo server.\n\nProgrammatic usage\n\nDo you need a MongoDB server programmatically? No problems!\n\n// CommonJS\n\nconst { startMongo } = require('mongoz')\n\n\n\n// ESM\n\nimport { startMongo } from 'mongoz'\n\n\n\n// Install and start listening MongoDB on 127.0.0.1:27017 in background\n\nawait startMongo()\n\n\n\n// Or with options\n\nawait startMongo({ port: 27018 })\n\n\nWhen closing server, mongo will also gracefully shutdown with node-graceful-shutdown.\n\nOptions\nname: Unique instance name. Default is default (env var: MONGO_NAME)\ndir: Data directory to store logs and data. Default is ${os.tmpDir}/mongo. (env var: MONGO_DIR)\nport: Listening port. Default is 27017 (env var: MONGO_PORT or PORT)\nargs Additional arguments passed to mongod (should be Array)\nplatform: OS to download binraries for.\nIn parallel with script\n\nYou can also use concurrently to start mongo alongside with server:.\n\nVia package.json:\n\n{\n\n  \"scripts\": {\n\n    \"start\": \"concurrently 'npx mongoz' 'node ./server.mjs'\"\n\n  }\n\n}\n\n\nOr directly with npx:\n\nnpx concurrently 'npx mongoz' 'node ./server.mjs'\n\nSupported platforms\n\nWindows, Linux and Darwin (Mac) are supported. Check formula for details.\n\nChanging data dir\n\nBy default, we use a temporary directory to store data and logs. You can customize it with MONGO_DIR environment variable.\n"
  },
  {
    "title": "listhen · UnJS",
    "url": "https://unjs.io/packages/listhen",
    "html": "listhen\n\nElegant HTTP Listener\n\nElegant HTTP listener!\n\n👉 Online Playground\n\nFeatures\n\n✅ Dev server with HMR, static, and typescript support with unjs/jiti\n\n\n✅ Works with Node.js, express, and unjs/h3 out of the box\n\n\n✅ Show the QR code of the public URL with unjs/uqr\n\n\n✅ Tunnel your local server to the world with unjs/untun\n\n\n✅ Assign a port or fallback to a nicer alternative with unjs/get-port-please\n\n✅ Gracefully shutdown Server with http-shutdown\n\n\n✅ Copy the URL to the clipboard\n\n\n✅ HTTPS support with self-signed certificates\n\n\n✅ Open URL in browser\n\n\n✅ Detect test and production environments to auto-adjust behavior\n\n\n✅ Close on the exit signal\n\n\nQuick Usage (CLI)\n\nYou can run your applications in localhost with typescript support and watch mode using listhen CLI:\n\nCreate index.ts:\n\nexport default (req, res) => {\n\n  res.end(\"Hello World!\");\n\n};\n\nCopy to clipboard\n\nor using unjs/h3:\n\nimport { createApp, eventHandler } from \"h3\";\n\n\n\nexport const app = createApp();\n\n\n\napp.use(\"/\", () => \"Hello world!\");\n\nCopy to clipboard\n\nor use npx to invoke listhen command:\n\nnpx listhen -w ./index.ts\n\nCopy to clipboard\nUsage (API)\n\nInstall package:\n\n# pnpm\n\npnpm i listhen\n\n\n\n# npm\n\nnpm i listhen\n\n\n\n# yarn\n\nyarn add listhen\n\nCopy to clipboard\n\nImport into your Node.js project:\n\n// CommonJS\n\nconst { listen, listenAndWatch } = require(\"listhen\");\n\n\n\n// ESM\n\nimport { listen, listenAndWatch } from \"listhen\";\n\nCopy to clipboard\nconst handler = (req, res) => {\n\n  res.end(\"Hi!\")\n\n}\n\n\n\n// listener: { url, getURL, server, close, ... }\n\nconst listener = await listen(handler, options?)\n\nCopy to clipboard\nOptions\nport\nDefault: process.env.PORT or 3000 or memorized random (see get-port-please)\n\nPort to listen.\n\nhostname\nDefault: process.env.HOST || '0.0.0.0'\n\nDefault hostname to listen.\n\nhttps\nType: Boolean | Object\nDefault: false\n\nListen on HTTPS with SSL enabled.\n\nSelf-Signed Certificate\n\nBy setting https: true, listhen will use an auto-generated self-signed certificate.\n\nYou can set https to an object for custom options. Possible options:\n\ndomains: (Array) Default is ['localhost', '127.0.0.1', '::1'].\nvalidityDays: (Number) Default is 1.\nUser-Provided Certificate\n\nSet https: { cert, key } where the cert and key are paths to the SSL certificates. With an encrypted private key, you also need to set passphrase on the https object.\n\nTo provide a certificate stored in a keystore set https: { pfx } with a path to the keystore. When the keystore is password protected also set passphrase.\n\nYou can also provide an inline cert and key instead of reading from the filesystem. In this case, they should start with --.\n\nshowURL\nDefault: true (force disabled on a test environment)\n\nShow a CLI message for the listening URL.\n\nbaseURL\nDefault: /\nopen\nDefault: false (force disabled on test and production environments)\n\nOpen the URL in the browser. Silently ignores errors.\n\nclipboard\nDefault: false (force disabled on test and production environments)\n\nCopy the URL to the clipboard. Silently ignores errors.\n\nisTest\nDefault: process.env.NODE_ENV === 'test'\n\nDetect if running in a test environment to disable some features.\n\nautoClose\nDefault: true\n\nAutomatically close when an exit event, SIGTERM, SIGINT or SIGHUP signal is received in the process.\n\npublicURL\nDefault: (the first public URL listening)\n\nThe public URL to show in the CLI output\n\nqr\nDefault: true\n\nPrint QR Code for public address.\n\npublic\nDefault: false for development or when hostname is localhost and true for production\n\nWhen enabled, listhen tries to listen to all network interfaces. You can also enable this option using --host CLI flag.\n"
  },
  {
    "title": "mkdist · UnJS",
    "url": "https://unjs.io/packages/mkdist/",
    "html": "mkdist\n\nLightweight file-to-file transpiler.\n\nLightweight file-to-file transformer\n\n✅ Copies all assets\n\n✅ Supports Vue Single File Components\n\n✅ Fast and minimal transform by esbuild\n\n✅ .d.ts generation for .ts, .js and .vue files\n\n✅ Support postcss (autoprefixer, cssnano and postcss-nested enabled out of the box!)\n\n❓ Why?\n\nBundling libraries isn't always the best choice:\n\nWe lose original file structure\nWe lose modern syntax by transpiling in bundle\nWe lose critical-css by extracting css to a global dist (vue)\nDependencies will be always imported from bundle even if not used (a second bundling step might fix this but it usually won't happen in development and for dependencies with side-effects)\n\nWhile there are tools like tsc and @babel/cli, they mostly focus on transpiling rather than keeping source level quality. Also they lack support for handling custom extensions like .vue and copying assets.\n\n🚀 Usage\nnpx mkdist [rootDir] [--src=src] [--dist=dist] [--pattern=glob [--pattern=more-glob]] [--format=cjs|esm] [-d|--declaration] [--ext=mjs|js|ts]\n"
  },
  {
    "title": "magicast · UnJS",
    "url": "https://unjs.io/packages/magicast/",
    "html": "magicast\n\nProgrammatically modify JavaScript and TypeScript source codes.\n\nProgrammatically modify JavaScript and TypeScript source codes with a simplified, elegant and familiar syntax. Built on top of the AST parsed by recast and babel.\n\n❯ 🧙🏼 Magical modify a JS/TS file and write back magically just like JSON!\n❯ 🔀 Exports/Import manipulate module's imports and exports at ease\n❯ 💼 Function Arguments easily manipulate arguments passed to a function call, like defineConfig()\n❯ 🎨 Smart Formatting preseves the formatting style (quotes, tabs, etc.) from the original code\n❯ 🧑‍💻 Readable get rid of the complexity of AST manipulation and make your code super readable\n\n\nInstall\n\nInstall npm package:\n\n# using yarn\n\nyarn add --dev magicast\n\n\n\n# using npm\n\nnpm install -D magicast\n\n\n\n# using pnpm\n\npnpm add -D magicast\n\n\nImport utilities:\n\n// ESM / Bundler\n\nimport { parseModule, generateCode, builders, createNode } from \"magicast\";\n\n\n\n// CommonJS\n\nconst { parseModule, generateCode, builders, createNode } = require(\"magicast\");\n\nExamples\n\nExample: Modify a file:\n\nconfig.js:\n\nexport default {\n\n  foo: [\"a\"],\n\n};\n\n\nCode to modify and append b to foo prop of defaultExport:\n\nimport { loadFile, writeFile } from \"magicast\";\n\n\n\nconst mod = await loadFile(\"config.js\");\n\n\n\nmod.exports.default.foo.push(\"b\");\n\n\n\nawait writeFile(mod, \"config.js\");\n\n\nUpdated config.js:\n\nexport default {\n\n  foo: [\"a\", \"b\"],\n\n};\n\n\nExample: Directly use AST utils:\n\nimport { parseModule, generateCode } from \"magicast\";\n\n\n\n// Parse to AST\n\nconst mod = parseModule(`export default { }`);\n\n\n\n// Ensure foo is an array\n\nmod.exports.default.foo ||= [];\n\n// Add a new array member\n\nmod.exports.default.foo.push(\"b\");\n\nmod.exports.default.foo.unshift(\"a\");\n\n\n\n// Generate code\n\nconst { code, map } = generateCode(mod);\n\n\nGenerated code:\n\nexport default {\n\n  foo: [\"a\", \"b\"],\n\n};\n\n\nExample: Get the AST directly:\n\nimport { parseModule, generateCode } from \"magicast\";\n\n\n\nconst mod = parseModule(`export default { }`);\n\n\n\nconst ast = mod.exports.default.$ast\n\n// do something with ast\n\n\nExample: Function parameters:\n\nimport { parseModule, generateCode } from \"magicast\";\n\n\n\nconst mod = parseModule(`export default defineConfig({ foo: 'bar' })`);\n\n\n\n// Support for both bare object export and `defineConfig` wrapper\n\nconst options = mod.exports.default.$type === 'function-call'\n\n  ? mod.exports.default.$args[0]\n\n  : mod.exports.default;\n\n\n\nconsole.log(options.foo) // bar\n\n\nExample: Create a function call:\n\nimport { parseModule, generateCode, builders } from \"magicast\";\n\n\n\nconst mod = parseModule(`export default {}`);\n\n\n\nconst options = mod.exports.default.list = builders.functionCall('create', [1, 2, 3])\n\n\n\nconsole.log(mod.generateCode()) // export default { list: create([1, 2, 3]) }\n\nNotes\n\nAs JavaScript is a very dynamic language, you should be aware that Magicast's convention CAN NOT cover all possible cases. Magicast serves as a simple and maintainable interface to update static-ish JavaScript code. When interacting with Magicast node, be aware that every option might have chance to throw an error depending on the input code. We recommend to always wrap the code in a try/catch block (even better to do some defensive coding), for example:\n\nimport { loadFile, writeFile } from \"magicast\";\n\n\n\nfunction updateConfig() {\n\n  try {\n\n    const mod = await loadFile(\"config.js\");\n\n\n\n    mod.exports.default.foo.push(\"b\");\n\n\n\n    await writeFile(mod);\n\n  } catch (e) {\n\n    console.error('Unable to update config.js')\n\n    console.error('Please update it manually with the following instructions: ...')\n\n    // handle error\n\n  }\n\n}\n\nHigh Level Helpers\n\nWe also experiment to provide a few high level helpers to make common tasks easier. You could import them from magicast/helpers. They might be moved to a separate package in the future.\n\nimport {\n\n  deepMergeObject,\n\n  addNuxtModule,\n\n  addVitePlugin,\n\n  // ...\n\n} from \"magicast/helpers\";\n\n\nWe recommend to check out the source code and test cases for more details.\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "jiti · UnJS",
    "url": "https://unjs.io/packages/jiti/",
    "html": "jiti\n\nRuntime TypeScript and ESM support for Node.js\n\nRuntime Typescript and ESM support for Node.js\n\n!IMPORTANT This is the development branch for jiti v2. Check out jiti/v1 for latest stable docs and unjs/jiti#174 for the v2 roadmap.\n\nFeatures\nSeamless typescript and ESM syntax support\nSeamless interoperability between ESM and CommonJS\nSynchronous API to replace require\nSuper slim and zero dependency\nSmart syntax detection to avoid extra transforms\nCommonJS cache integration\nFilesystem transpile hard cache\nV8 compile cache\nCustom resolve alias\nUsage\nProgrammatic\nconst jiti = require(\"jiti\")(__filename);\n\n\n\njiti(\"./path/to/file.ts\");\n\n\nYou can also pass options as second argument:\n\nconst jiti = require(\"jiti\")(__filename, { debug: true });\n\nCLI\njiti index.ts\n\n# or npx jiti index.ts\n\nRegister require hook\nnode -r jiti/register index.ts\n\n\nAlternatively, you can register jiti as a require hook programmatically:\n\nconst jiti = require(\"jiti\")();\n\nconst unregister = jiti.register();\n\nOptions\ndebug\nType: Boolean\nDefault: false\nEnvironment Variable: JITI_DEBUG\n\nEnable debug to see which files are transpiled\n\ncache\nType: Boolean | String\nDefault: true\nEnvironment Variable: JITI_CACHE\n\nUse transpile cache\n\nIf set to true will use node_modules/.cache/jiti (if exists) or {TMP_DIR}/node-jiti\n\nesmResolve\nType: Boolean | String\nDefault: false\nEnvironment Variable: JITI_ESM_RESOLVE\n\nUsing esm resolution algorithm to support import condition.\n\ntransform\nType: Function\nDefault: Babel (lazy loaded)\n\nTransform function. See src/babel for more details\n\nsourceMaps\nType: Boolean\nDefault false\nEnvironment Variable: JITI_SOURCE_MAPS\n\nAdd inline source map to transformed source for better debugging.\n\ninteropDefault\nType: Boolean\nDefault: false\n\nReturn the .default export of a module at the top-level.\n\nalias\nType: Object\nDefault: -\nEnvironment Variable: JITI_ALIAS\n\nCustom alias map used to resolve ids.\n\nnativeModules\nType: Array\nDefault: 'typescript`\nEnvironment Variable: JITI_NATIVE_MODULES\n\nList of modules (within node_modules) to always use native require for them.\n\ntransformModules\nType: Array\nDefault:\nEnvironment Variable: JITI_TRANSFORM_MODULES\n\nList of modules (within node_modules) to transform them regardless of syntax.\n\nexperimentalBun\nType: Boolean\nDefault: Enabled if process.versions.bun exists (Bun runtime)\nEnvironment Variable: JITI_EXPERIMENTAL_BUN\n\nEnable experimental native Bun support for transformations.\n\nDevelopment\nClone this repository\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun pnpm dev\nRun pnpm jiti ./test/path/to/file.ts"
  },
  {
    "title": "knitwork · UnJS",
    "url": "https://unjs.io/packages/knitwork/",
    "html": "knitwork\n\nUtilities to generate JavaScript code.\n\nUtilities to generate JavaScript code.\n\nInstall\n# npm\n\nnpm install knitwork\n\n\n\n# yarn\n\nyarn add knitwork\n\n\n\n# pnpm\n\npnpm install knitwork\n\nUsage\n\nGenerating ESM syntax:\n\nimport { genImport, genExport } from 'knitwork'\n\n\n\n// import foo from \"pkg\"\n\nconsole.log(genImport('pkg', 'foo'))\n\n\n\n// import { foo } from \"pkg\"\n\nconsole.log(genImport('pkg', ['foo']))\n\n\n\n// import { a, b } from \"pkg\"\n\nconsole.log(genImport('pkg', ['a', 'b']))\n\n\n\n// import foo as bar from \"pkg\";\n\nconsole.log(genImport('pkg', { name: 'foo', as: 'bar' }))\n\n\n\n// import { foo as bar } from \"pkg\";\n\nconsole.log(genImport('pkg', [{ name: 'foo', as: 'bar' }]))\n\n\n\n// import foo from \"pkg\" assert { type: \"json\" };\n\nconsole.log(genImport('pkg', 'foo', { assert: { type: 'json' } }))\n\n\n\n// export foo from \"pkg\"\n\nconsole.log(genExport('pkg', 'foo'))\n\n\n\n// export { a, b } from \"pkg\"\n\nconsole.log(genExport('pkg', ['a', 'b']))\n\n\n\n// export * as bar from \"pkg\"\n\nconsole.log(genExport('pkg', { name: '*', as: 'bar' }))\n\n\n\n// export foo from \"pkg\" assert { type: \"json\" };\n\nconsole.log(genExport('pkg', 'foo', { assert: { type: 'json' } }))\n\n\nGenerating TS:\n\nimport { genInterface, genAugmentation, genInlineTypeImport, genTypeImport, genTypeExport } from 'knitwork'\n\n\n\n// interface FooInterface extends A, B {\n\n//   name: boolean\n\n//   optional?: string\n\n// }\n\nconsole.log(genInterface('FooInterface', { name: 'boolean', 'optional?': 'string' }, { extends: ['A', 'B'] }))\n\n// declare module \"my-module\" {\n\n//   interface MyInterface {}\n\n// }\n\nconsole.log(genAugmentation('my-module', { MyInterface: {} }))\n\n// typeof import(\"my-module\").genString'\n\nconsole.log(genInlineTypeImport('my-module', 'genString'))\n\n// typeof import(\"my-module\").default'\n\nconsole.log(genInlineTypeImport('my-module'))\n\n// import type { test as value } from \"my-module\";\n\nconsole.log(genTypeImport('my-module', [{ name: 'test', as: 'value' }]))\n\n// export type { test } from \"my-module\";\n\nconsole.log(genTypeExport('my-module', ['test']))\n\n\nSerializing JS objects:\n\nimport { genObjectFromRaw, genObjectFromRawEntries, genArrayFromRaw } from 'knitwork'\n\n\n\n// { test: () => import(\"pkg\") }\n\nconsole.log(genObjectFromRaw({ test: '() => import(\"pkg\")' }))\n\n\n\n// { 0: [ test, () => import(\"pkg\") ] }\n\nconsole.log(genObjectFromRaw([ ['test', '() => import(\"pkg\")'] ]))\n\n\n\nconst entries = Object.entries({\n\n  a: 1, b: null, c: '\"c\"', nest: { hello: '\"world\"', fn: () => 1 }\n\n})\n\n// { a: 1, b: null, c: \"c\", nest: { hello: \"world\", fn: () => 1 } }\n\nconsole.log(genObjectFromRawEntries(entries))\n\n\n\n// [ 1, 2, () => import(\"pkg\") ]\n\nconsole.log(genArrayFromRaw(['1', '2', '() => import(\"pkg\")']))\n\n\nGenerating safe variable names:\n\nimport { genSafeVariableName } from 'knitwork'\n\n\n\n// _123_32foo\n\ngenSafeVariableName('123 foo')\n\n// _for\n\ngenSafeVariableName('for')\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "jimp-compact · UnJS",
    "url": "https://unjs.io/packages/jimp-compact/",
    "html": "jimp-compact\n\nLightweight version of Jimp -- An image processing library written entirely in JavaScript for Node.js\n\nLightweight version of Jimp compiled with vercel/ncc\n\nWhy?\n\nThis package has 27x smaller install size with all features of original jimp (Jimp install size is ~33.8MB) by bundling all node_modules and removing extra files.\n\nUsage\n\nInstall and import/require jimp-compact instead of jimp npm package.\n\n# npm\n\nnpm i jimp-compact\n\n\n\n# yarn\n\nyarn add jimp-compact\n\n// ESM\n\nimport Jimp from 'jimp-compact'\n\n\n\n// CJS\n\nconst Jimp = require('jimp-compact')\n\n\nSee jimp docs for full usage.\n\nKnown Issues\n\nIn order to make typescript working, you need to (also) install jimp in devDependencies! Track issue via #39 and #42.\n"
  },
  {
    "title": "ipx · UnJS",
    "url": "https://unjs.io/packages/ipx/",
    "html": "ipx\n\nHigh performance, secure and easy to use image proxy based on Sharp and libvips.\n\n!NOTE This is the active branch for IPX v2. Check out ipx/v1 for v1 docs.\n\nHigh performance, secure and easy-to-use image optimizer powered by sharp and svgo.\n\nUsed by Nuxt Image and Netlify and open to everyone!\n\nUsing CLI\n\nYou can use ipx command to start server.\n\nUsing npx:\n\nnpx ipx serve --dir ./\n\n\nUsin bun\n\nbun x npx ipx serve --dir ./\n\n\nThe default serve directory is the current working directory.\n\nProgramatic API\n\nYou can use IPX as a middleware or directly use IPX interface.\n\nimport { createIPX, ipxFSStorage, ipxHttpStorage } from \"ipx\";\n\n\n\nconst ipx = createIPX({\n\n  storage: ipxFSStorage({ dir: \"./public\" }),\n\n  httpStorage: ipxHttpStorage({ domains: [\"picsum.photos\"] }),\n\n});\n\n\nExample: Using with unjs/h3:\n\nimport { listen } from \"listhen\";\n\nimport { createApp, toNodeListener } from \"h3\";\n\nimport {\n\n  createIPX,\n\n  ipxFSStorage,\n\n  ipxHttpStorage,\n\n  createIPXH3Handler,\n\n} from \"ipx\";\n\n\n\nconst ipx = createIPX({\n\n  storage: ipxFSStorage({ dir: \"./public\" }),\n\n  httpStorage: ipxHttpStorage({ domains: [\"picsum.photos\"] }),\n\n});\n\n\n\nconst app = createApp().use(\"/\", createIPXH3Handler(ipx));\n\n\n\nlisten(toNodeListener(app));\n\n\nExample: Using express:\n\nimport { listen } from \"listhen\";\n\nimport express from \"express\";\n\nimport {\n\n  createIPX,\n\n  ipxFSStorage,\n\n  ipxHttpStorage,\n\n  createIPXNodeServer,\n\n} from \"ipx\";\n\n\n\nconst ipx = createIPX({\n\n  storage: ipxFSStorage({ dir: \"./public\" }),\n\n  httpStorage: ipxHttpStorage({ domains: [\"picsum.photos\"] }),\n\n});\n\n\n\nconst app = express().use(\"/\", createIPXNodeServer(ipx));\n\n\n\nlisten(app);\n\nURL Examples\n\nGet original image:\n\n/_/static/buffalo.png\n\nChange format to webp and keep other things same as source:\n\n/f_webp/static/buffalo.png\n\nKeep original format (png) and set width to 200:\n\n/w_200/static/buffalo.png\n\nResize to 200x200px using embed method and change format to webp:\n\n/embed,f_webp,s_200x200/static/buffalo.png\n\nConfig\n\nYou can universally customize IPX configuration using IPX_* environment variables.\n\nIPX_ALIAS\nDefault: {}\nFilesystem Source Options\n\n(enabled by default with CLI only)\n\nIPX_FS_DIR\nDefault: . (current working directory)\nIPX_FS_MAX_AGE\nDefault: 300\nHTTP(s) Source Options\n\n(enabled by default with CLI only)\n\nIPX_HTTP_DOMAINS\nDefault: []\nIPX_HTTP_MAX_AGE\nDefault: 300\nIPX_HTTP_FETCH_OPTIONS\nDefault: {}\nIPX_HTTP_ALLOW_ALL_DOMAINS\nDefault: false\nModifiers\nProperty\tDocs\tExample\tComments\nwidth / w\tDocs\t/width_200/buffalo.png\t\nheight / h\tDocs\t/height_200/buffalo.png\t\nresize / s\tDocs\t/s_200x200/buffalo.png\t\nkernel\tDocs\t/s_200x200,kernel_nearest/buffalo.png\tSupported kernel: nearest, cubic, mitchell, lanczos2 and lanczos3 (default).\nfit\tDocs\t/s_200x200,fit_outside/buffalo.png\tSets fit option for resize.\nposition / pos\tDocs\t/s_200x200,pos_top/buffalo.png\tSets position option for resize.\ntrim\tDocs\t/trim_100/buffalo.png\t\nextend\tDocs\t/extend_{top}_{right}_{bottom}_{left}/buffalo.png\tExtend / pad / extrude one or more edges of the image with either the provided background colour or pixels derived from the image.\nbackground / b\t_\t/r_45,b_00ff00/buffalo.png\t\nextract\tDocs\t/extract_{left}_{top}_{width}_{height}/buffalo.png\tExtract/crop a region of the image.\nformat / f\tDocs\t/format_webp/buffalo.png\tSupported format: jpg, jpeg, png, webp, avif, gif, heif, tiff and auto (experimental only with middleware)\nquality / q\t_\t/quality_50/buffalo.png\tAccepted values: 0 to 100\nrotate\tDocs\t/rotate_45/buffalo.png\t\nenlarge\t_\t/enlarge,s_2000x2000/buffalo.png\tAllow the image to be upscaled. By default the returned image will never be larger than the source in any dimension, while preserving the requested aspect ratio.\nflip\tDocs\t/flip/buffalo.png\t\nflop\tDocs\t/flop/buffalo.png\t\nsharpen\tDocs\t/sharpen_30/buffalo.png\t\nmedian\tDocs\t/median_10/buffalo.png\t\nblur\tDocs\t/blur_5/buffalo.png\t\ngamma\tDocs\t/gamma_3/buffalo.png\t\nnegate\tDocs\t/negate/buffalo.png\t\nnormalize\tDocs\t/normalize/buffalo.png\t\nthreshold\tDocs\t/threshold_10/buffalo.png\t\ntint\tDocs\t/tint_1098123/buffalo.png\t\ngrayscale\tDocs\t/grayscale/buffalo.png\t\nanimated\t-\t/animated/buffalo.gif\tExperimental"
  },
  {
    "title": "image-meta · UnJS",
    "url": "https://unjs.io/packages/image-meta/",
    "html": "image-meta\n\nDetect image type and size using pure javascript.\n\nDetect image type and size using pure javascript.\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install image-meta\n\n\n\n# yarn\n\nyarn add image-meta\n\n\n\n# pnpm\n\npnpm install image-meta\n\n\n\n# bun\n\nbun install image-meta\n\nimport { imageMeta } from \"image-meta\";\n\n\n\nconst data = await fetch(url).then((res) => res.buffer());\n\n\n\n// Meta contains { type, width?, height?, orientation? }\n\nconst meta = imageMeta(data);\n\n\nNote: imageMeta throws an error if either data is not a Buffer/Uint8Array, or data is invalid or type cannot be determined. You should wrap it into a try/catch statement to handle errors.\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "httpxy · UnJS",
    "url": "https://unjs.io/packages/httpxy/",
    "html": "httpxy\n\nA Full-Featured HTTP and WebSocket Proxy for Node.js\n\nA Full-Featured HTTP and WebSocket Proxy for Node.js forked from http-party/node-http-proxy with modern Typescript rewrite.\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install httpxy\n\n\n\n# yarn\n\nyarn add httpxy\n\n\n\n# pnpm\n\npnpm install httpxy\n\n\nCreate proxy:\n\nimport { createServer } from \"node:http\";\n\n\n\nimport { createProxyServer } from \"httpxy\";\n\n\n\nconst proxy = createProxyServer({});\n\n\n\nconst server = createServer(async (req, res) => {\n\n  try {\n\n    await httpProxy.web(req, res, {\n\n      target: main.url,\n\n    });\n\n  } catch (error) {\n\n    console.error(error);\n\n    res.statusCode = 500;\n\n    res.end(\"Proxy error: \" + error.toString());\n\n  }\n\n});\n\n\n\nserver.listen(3000, () => {\n\n  console.log(\"Proxy is listening on http://localhost:3000\");\n\n});\n\n\nCheckout http-party/node-http-proxy for more options and examples.\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "hookable · UnJS",
    "url": "https://unjs.io/packages/hookable/",
    "html": "hookable\n\nAwaitable Hooks\n\nAwaitable hooks system.\n\nInstall\n\nUsing yarn:\n\nyarn add hookable\n\n\nUsing npm:\n\nnpm install hookable\n\nUsage\n\nMethod A: Create a hookable instance:\n\nimport { createHooks } from 'hookable'\n\n\n\n// Create a hookable instance\n\nconst hooks = createHooks()\n\n\n\n// Hook on 'hello'\n\nhooks.hook('hello', () => { console.log('Hello World' )})\n\n\n\n// Call 'hello' hook\n\nhooks.callHook('hello')\n\n\nMethod B: Extend your base class from Hookable:\n\nimport { Hookable } from 'hookable'\n\n\n\nexport default class FooLib extends Hookable {\n\n  constructor() {\n\n    // Call to parent to initialize\n\n    super()\n\n    // Initialize Hookable with custom logger\n\n    // super(consola)\n\n  }\n\n\n\n  async someFunction() {\n\n    // Call and wait for `hook1` hooks (if any) sequential\n\n    await this.callHook('hook1')\n\n  }\n\n}\n\n\nInside plugins, register for any hook:\n\nconst lib = new FooLib()\n\n\n\n// Register a handler for `hook2`\n\nlib.hook('hook2', async () => { /* ... */ })\n\n\n\n// Register multiply handlers at once\n\nlib.addHooks({\n\n  hook1: async () => { /* ... */ },\n\n  hook2: [ /* can be also an array */ ]\n\n})\n\n\nUnregistering hooks:\n\nconst lib = new FooLib()\n\n\n\nconst hook0 = async () => { /* ... */ }\n\nconst hook1 = async () => { /* ... */ }\n\nconst hook2 = async () => { /* ... */ }\n\n\n\n// The hook() method returns an \"unregister\" function\n\nconst unregisterHook0 = lib.hook('hook0', hook0)\n\nconst unregisterHooks1and2 = lib.addHooks({ hook1, hook2 })\n\n\n\n/* ... */\n\n\n\nunregisterHook0()\n\nunregisterHooks1and2()\n\n\n\n// or\n\n\n\nlib.removeHooks({ hook0, hook1 })\n\nlib.removeHook('hook2', hook2)\n\n\nTriggering a hook handler once:\n\nconst lib = new FooLib()\n\n\n\nconst unregister = lib.hook('hook0', async () => {\n\n  // Unregister as soon as the hook is executed\n\n  unregister()\n\n\n\n  /* ... */\n\n})\n\nHookable class\nconstructor()\nhook (name, fn)\n\nRegister a handler for a specific hook. fn must be a function.\n\nReturns an unregister function that, when called, will remove the registered handler.\n\nhookOnce (name, fn)\n\nSimilar to hook but unregisters hook once called.\n\nReturns an unregister function that, when called, will remove the registered handler before first call.\n\naddHooks(configHooks)\n\nFlatten and register hooks object.\n\nExample:\n\nhookable.addHooks({\n\n  test: {\n\n    before: () => {},\n\n    after: () => {}\n\n  }\n\n})\n\n\nThis registers test:before and test:after hooks at bulk.\n\nReturns an unregister function that, when called, will remove all the registered handlers.\n\nasync callHook (name, ...args)\n\nUsed by class itself to sequentially call handlers of a specific hook.\n\ncallHookWith (name, callerFn)\n\nIf you need custom control over how hooks are called, you can provide a custom function that will receive an array of handlers of a specific hook.\n\ncallerFn if a callback function that accepts two arguments, hooks and args:\n\nhooks: Array of user hooks to be called\nargs: Array of arguments that should be passed each time calling a hook\ndeprecateHook (old, name)\n\nDeprecate hook called old in favor of name hook.\n\ndeprecateHooks (deprecatedHooks)\n\nDeprecate all hooks from an object (keys are old and values or newer ones).\n\nremoveHook (name, fn)\n\nRemove a particular hook handler, if the fn handler is present.\n\nremoveHooks (configHooks)\n\nRemove multiple hook handlers.\n\nExample:\n\nconst handler = async () => { /* ... */ }\n\n\n\nhookable.hook('test:before', handler)\n\nhookable.addHooks({ test: { after: handler } })\n\n\n\n// ...\n\n\n\nhookable.removeHooks({\n\n  test: {\n\n    before: handler,\n\n    after: handler\n\n  }\n\n})\n\nremoveAllHooks\n\nRemove all hook handlers.\n\nbeforeEach (syncCallback)\n\nRegisters a (sync) callback to be called before each hook is being called.\n\nhookable.beforeEach((event) => { console.log(`${event.name} hook is being called with ${event.args}`)}`)\n\nhookable.hook('test', () => { console.log('running test hook') })\n\n\n\n// test hook is being called with []\n\n// running test hook\n\nawait hookable.callHook('test')\n\nafterEach (syncCallback)\n\nRegisters a (sync) callback to be called after each hook is being called.\n\nhookable.afterEach((event) => { console.log(`${event.name} hook called with ${event.args}`)}`)\n\nhookable.hook('test', () => { console.log('running test hook') })\n\n\n\n// running test hook\n\n// test hook called with []\n\nawait hookable.callHook('test')\n\ncreateDebugger\n\nAutomatically logs each hook that is called and how long it takes to run.\n\nconst debug = hookable.createDebugger(hooks, { tag: 'something' })\n\n\n\nhooks.callHook('some-hook', 'some-arg')\n\n// [something] some-hook: 0.21ms\n\n\n\ndebug.close()\n\nMigration\nFrom 4.x to 5.x\nType checking improved. You can use Hookable<T> or createHooks<T>() to provide types interface (c2e1e22)\nWe no longer provide an IE11 compatible umd build. Instead, you should use an ESM-aware bundler such as webpack or rollup to transpile if needed.\nLogger param is dropped. We use console.warn by default for deprecated hooks.\nPackage now uses named exports. You should import { Hookable } instead of Hookable or use new createHooks util\nmergeHooks util is exported standalone. You should replace Hookable.mergeHooks and this.mergeHooks with new { mergeHooks } export\nIn versions < 5.0.0 when using callHook if an error happened by one of the hook callbacks, we was handling errors globally and call global error hook + console.error instead and resolve callHook promise! This sometimes makes confusing behavior when we think code worked but it didn't. v5 introduced a breaking change that when a hook throws an error, callHook also rejects instead of a global error event. This means you should be careful to handle all errors when using callHook now.\nCredits\n\nExtracted from Nuxt hooks system originally introduced by Sébastien Chopin\n\nThanks to Joe Paice for donating hookable package name.\n"
  },
  {
    "title": "h3 · UnJS",
    "url": "https://unjs.io/packages/h3/",
    "html": "h3\n\nA minimal h(ttp) framework built for high performance and portability.\n\nH3 (pronounced as /eɪtʃθriː/, like h-3) is a minimal h(ttp) framework built for high performance and portability.\n\n👉 Online Playground\n\nFeatures\n\n✔️  Portable: Works perfectly in Serverless, Workers, and Node.js\n\n✔️  Minimal: Small and tree-shakable\n\n✔️  Modern: Native promise support\n\n✔️  Extendable: Ships with a set of composable utilities but can be extended\n\n✔️  Router: Super fast route matching using unjs/radix3\n\n✔️  Compatible: Compatibility layer with node/connect/express middleware\n\nInstall\n# Using npm\n\nnpm install h3\n\n\n\n# Using yarn\n\nyarn add h3\n\n\n\n# Using pnpm\n\npnpm add h3\n\nUsing Nightly Releases\nUsage\nimport { createServer } from \"node:http\";\n\nimport { createApp, eventHandler, toNodeListener } from \"h3\";\n\n\n\nconst app = createApp();\n\napp.use(\n\n  \"/\",\n\n  eventHandler(() => \"Hello world!\"),\n\n);\n\n\n\ncreateServer(toNodeListener(app)).listen(process.env.PORT || 3000);\n\n\nExample using listhen for an elegant listener:\n\nimport { createApp, eventHandler, toNodeListener } from \"h3\";\n\nimport { listen } from \"listhen\";\n\n\n\nconst app = createApp();\n\napp.use(\n\n  \"/\",\n\n  eventHandler(() => \"Hello world!\"),\n\n);\n\n\n\nlisten(toNodeListener(app));\n\nRouter\n\nThe app instance created by h3 uses a middleware stack (see how it works) with the ability to match route prefix and apply matched middleware.\n\nTo opt-in using a more advanced and convenient routing system, we can create a router instance and register it to app instance.\n\nimport { createApp, eventHandler, createRouter } from \"h3\";\n\n\n\nconst app = createApp();\n\n\n\nconst router = createRouter()\n\n  .get(\n\n    \"/\",\n\n    eventHandler(() => \"Hello World!\"),\n\n  )\n\n  .get(\n\n    \"/hello/:name\",\n\n    eventHandler((event) => `Hello ${event.context.params.name}!`),\n\n  );\n\n\n\napp.use(router);\n\n\nTip: We can register the same route more than once with different methods.\n\nRoutes are internally stored in a Radix Tree and matched using unjs/radix3.\n\nFor using nested routers, see this example\n\nMore app usage examples\n// Handle can directly return object or Promise<object> for JSON response\n\napp.use(\n\n  \"/api\",\n\n  eventHandler((event) => ({ url: event.node.req.url })),\n\n);\n\n\n\n// We can have better matching other than quick prefix match\n\napp.use(\n\n  \"/odd\",\n\n  eventHandler(() => \"Is odd!\"),\n\n  { match: (url) => url.substr(1) % 2 },\n\n);\n\n\n\n// Handle can directly return string for HTML response\n\napp.use(eventHandler(() => \"<h1>Hello world!</h1>\"));\n\n\n\n// We can chain calls to .use()\n\napp\n\n  .use(\n\n    \"/1\",\n\n    eventHandler(() => \"<h1>Hello world!</h1>\"),\n\n  )\n\n  .use(\n\n    \"/2\",\n\n    eventHandler(() => \"<h1>Goodbye!</h1>\"),\n\n  );\n\n\n\n// We can proxy requests and rewrite cookie's domain and path\n\napp.use(\n\n  \"/api\",\n\n  eventHandler((event) =>\n\n    proxyRequest(event, \"https://example.com\", {\n\n      // f.e. keep one domain unchanged, rewrite one domain and remove other domains\n\n      cookieDomainRewrite: {\n\n        \"example.com\": \"example.com\",\n\n        \"example.com\": \"somecompany.co.uk\",\n\n        \"*\": \"\",\n\n      },\n\n      cookiePathRewrite: {\n\n        \"/\": \"/api\",\n\n      },\n\n    }),\n\n  ),\n\n);\n\n\n\n// Legacy middleware with 3rd argument are automatically promisified\n\napp.use(\n\n  fromNodeMiddleware((req, res, next) => {\n\n    req.setHeader(\"x-foo\", \"bar\");\n\n    next();\n\n  }),\n\n);\n\n\n\n// Lazy loaded routes using { lazy: true }\n\napp.use(\"/big\", () => import(\"./big-handler\"), { lazy: true });\n\nUtilities\n\nH3 has a concept of composable utilities that accept event (from eventHandler((event) => {})) as their first argument. This has several performance benefits over injecting them to event or app instances in global middleware commonly used in Node.js frameworks, such as Express. This concept means only required code is evaluated and bundled, and the rest of the utilities can be tree-shaken when not used.\n\n👉 You can check list of exported built-in utils from JSDocs Documentation.\n\nBody\nreadRawBody(event, encoding?)\nreadBody(event)\nreadValidatedBody(event, validate)\nreadMultipartFormData(event)\nRequest\ngetQuery(event)\ngetValidatedQuery(event, validate)\ngetRouterParams(event, { decode? })\ngetRouterParam(event, name, { decode? })\ngetValidatedRouterParams(event, validate, { decode? })\ngetMethod(event, default?)\nisMethod(event, expected, allowHead?)\nassertMethod(event, expected, allowHead?)\ngetRequestHeaders(event, headers) (alias: getHeaders)\ngetRequestHeader(event, name) (alias: getHeader)\ngetRequestURL(event)\ngetRequestHost(event)\ngetRequestProtocol(event)\ngetRequestPath(event)\ngetRequestIP(event, { xForwardedFor: boolean })\nResponse\nsend(event, data, type?)\nsendNoContent(event, code = 204)\nsetResponseStatus(event, status)\ngetResponseStatus(event)\ngetResponseStatusText(event)\ngetResponseHeaders(event)\ngetResponseHeader(event, name)\nsetResponseHeaders(event, headers) (alias: setHeaders)\nsetResponseHeader(event, name, value) (alias: setHeader)\nappendResponseHeaders(event, headers) (alias: appendHeaders)\nappendResponseHeader(event, name, value) (alias: appendHeader)\ndefaultContentType(event, type)\nsendRedirect(event, location, code=302)\nisStream(data)\nsendStream(event, data)\nwriteEarlyHints(event, links, callback)\nSanitize\nsanitizeStatusMessage(statusMessage)\nsanitizeStatusCode(statusCode, default = 200)\nError\nsendError(event, error, debug?)\ncreateError({ statusCode, statusMessage, data? })\nRoute\nuseBase(base, handler)\nProxy\nsendProxy(event, { target, ...options })\nproxyRequest(event, { target, ...options })\nfetchWithEvent(event, req, init, { fetch? }?)\ngetProxyRequestHeaders(event)\nCookie\nparseCookies(event)\ngetCookie(event, name)\nsetCookie(event, name, value, opts?)\ndeleteCookie(event, name, opts?)\nsplitCookiesString(cookiesString)\nSession\nuseSession(event, config = { password, maxAge?, name?, cookie?, seal?, crypto? })\ngetSession(event, config)\nupdateSession(event, config, update)\nsealSession(event, config)\nunsealSession(event, config, sealed)\nclearSession(event, config)\nCache\nhandleCacheHeaders(event, opts)\nCors\nhandleCors(options) (see h3-cors for more detail about options)\nisPreflightRequest(event)\nisCorsOriginAllowed(event)\nappendCorsHeaders(event, options) (see h3-cors for more detail about options)\nappendCorsPreflightHeaders(event, options) (see h3-cors for more detail about options)\nCommunity Packages\n\nYou can use more H3 event utilities made by the community.\n\nPlease check their READMEs for more details.\n\nPRs are welcome to add your packages.\n\nh3-typebox\nvalidateBody(event, schema)\nvalidateQuery(event, schema)\nh3-zod\nuseValidatedBody(event, schema)\nuseValidatedQuery(event, schema)\nh3-valibot\nuseValidateBody(event, schema)\nuseValidateParams(event, schema)\n@intlify/h3\ndefineI18nMiddleware(options)\nuseTranslation(event)\ngetHeaderLocale(event, options)\ngetHeaderLocales(event, options)\ngetCookieLocale(event, options)\nsetCookieLocale(event, options)\ngetPathLocale(event, options)\ngetQueryLocale(event, options)"
  },
  {
    "title": "giget · UnJS",
    "url": "https://unjs.io/packages/giget/",
    "html": "giget\n\nDownload templates and git repositories with pleasure!\n\nDownload templates and git repositories with pleasure!\n\nFeatures\n\n✔ Support popular git providers (GitHub, GitLab, Bitbucket, Sourcehut) out of the box.\n\n✔ Built-in and custom template registry.\n\n✔ Fast cloning using tarball gzip without depending on local git and tar.\n\n✔ Works online and offline with disk cache support.\n\n✔ Custom template provider support with programmatic usage.\n\n✔ Support extracting with a subdir.\n\n✔ Authorization support to download private templates\n\nUsage (CLI)\nnpx giget@latest <template> [<dir>] [...options]\n\nArguments\ntemplate: Template name or a a URI describing provider, repository, subdir, and branch/ref. (See Examples)\ndir: A relative or absolute path where to extract the template.\nOptions\n--force: Clone to existing directory even if exists.\n--offline: Do not attempt to download and use cached version.\n--prefer-offline: Use cache if exists otherwise try to download.\n--force-clean: ⚠️ Remove any existing directory or file recusively before cloning.\n--shell: ⚠️ Open a new shell with current working directory in cloned dir. (Experimental).\n--registry: URL to a custom registry. (Can be overriden with GIGET_REGISTRY environment variable).\n--no-registry: Disable registry lookup and functionality.\n--verbose: Show verbose debugging info.\n--cwd: Set current working directory to resolve dirs relative to it.\n--auth: Custom Authorization token to use for downloading template. (Can be overriden with GIGET_AUTH environment variable).\nExamples\n# Clone nuxt starter from giget template registry\n\nnpx giget@latest nuxt\n\n\n\n# Clone the main branch of github.com/unjs/template to unjs-template directory\n\nnpx giget@latest gh:unjs/template\n\n\n\n# Clone to myProject directory\n\nnpx giget@latest gh:unjs/template myProject\n\n\n\n# Clone dev branch\n\nnpx giget@latest gh:unjs/template#dev\n\n\n\n# Clone /test directory from main branch\n\nnpx giget@latest gh:unjs/template/test\n\n\n\n# Clone from gitlab\n\nnpx giget@latest gitlab:unjs/template\n\n\n\n# Clone from bitbucket\n\nnpx giget@latest bitbucket:unjs/template\n\n\n\n# Clone from sourcehut\n\nnpx giget@latest sourcehut:pi0/unjs-template\n\nTemplate Registry\n\nGiget has a built-in HTTP registry system for resolving templates. This way you can support template name shortcuts and meta-data. Default registry is served from unjs/giget/templates.\n\nIf you want to add your template to the built-in registry, just drop a PR to add it to the https://raw.githubusercontent.com/unjs/giget/main/templates directory. Slugs are added on first-come first-served basis but this might change in the future.\n\nCustom Registry\n\nA custom registry should provide an endpoint with dynamic path /:template.json that returns a JSON response with keys same as custom providers.\n\nname: (required) Name of the template.\ntar (required) Link to the tar download link.\ndefaultDir: (optional) Default cloning directory.\nurl: (optional) Webpage of the template.\nsubdir: (optional) Directory inside the tar file.\nheaders: (optional) Custom headers to send while downloading template.\n\nBecause of the simplicity, you can even use a GitHub repository as template registry but also you can build something more powerful by bringing your own API.\n\nUsage (Programmatic)\n\nInstall package:\n\n# npm\n\nnpm install giget\n\n\n\n# yarn\n\nyarn install giget\n\n\n\n# pnpm\n\npnpm install giget\n\n\nImport:\n\n// ESM\n\nimport { downloadTemplate } from \"giget\";\n\n\n\n// CommonJS\n\nconst { downloadTemplate } = require(\"giget\");\n\ndownloadTemplate(source, options?)\n\nExample:\n\nconst { source, dir } = await downloadTemplate(\"github:unjs/template\");\n\n\nOptions:\n\nsource: (string) Input source in format of [provider]:repo[/subpath][#ref].\noptions: (object) Options are usually inferred from the input string. You can customize them.\ndir: (string) Destination directory to clone to. If not provided, user-name will be used relative to the current directory.\nprovider: (string) Either github, gitlab, bitbucket or sourcehut. The default is github.\nrepo: (string) Name of repository in format of {username}/{reponame}.\nref: (string) Git ref (branch or commit or tag). The default value is main.\nsubdir: (string) Directory of the repo to clone from. The default value is none.\nforce: (boolean) Extract to the exisiting dir even if already exsists.\nforceClean: (boolean) ⚠️ Clean ups any existing directory or file before cloning.\noffline: (boolean) Do not attempt to download and use cached version.\npreferOffline: (boolean) Use cache if exists otherwise try to download.\nproviders: (object) A map from provider name to custom providers. Can be used to override built-ins too.\nregistry: (string or false) Set to false to disable registry. Set to a URL string (without trailing slash) for custom registry. (Can be overriden with GIGET_REGISTRY environment variable).\ncwd: (string) Current working directory to resolve dirs relative to it.\nauth: (string) Custom Authorization token to use for downloading template. (Can be overriden with GIGET_AUTH environment variable).\n\nReturn value:\n\nThe return value is a promise that resolves to the resolved template.\n\ndir: (string) Path to extracted dir.\nsource: (string) Normalized version of the input source without provider.\nother provider template keys\nurl: (string) URL of repostiroy that can be opened in browser. Useful for logging.\nCustom Providers\n\nUsing programmatic method, you can make your own custom template providers.\n\nimport type { TemplateProvider } from \"giget\";\n\n\n\nconst rainbow: TemplateProvider = async (input, { auth }) => {\n\n  return {\n\n    name: \"rainbow\",\n\n    version: input,\n\n    headers: { authorization: auth },\n\n    url: `https://rainbow.template/?variant=${input}`,\n\n    tar: `https://rainbow.template/dl/rainbow.${input}.tar.gz`,\n\n  };\n\n};\n\n\n\nconst { source, dir } = await downloadRepo(\"rainbow:one\", {\n\n  providers: { rainbow },\n\n});\n\nCustom Registry Providers\n\nYou can define additional custom registry providers using registryProvider utility and register to providers.\n\nimport { registryProvider } from \"giget\";\n\n\n\nconst themes = registryProvider(\n\n  \"https://raw.githubusercontent.com/unjs/giget/main/templates\",\n\n);\n\n\n\nconst { source, dir } = await downloadRepo(\"themes:test\", {\n\n  providers: { themes },\n\n});\n\nRelated projects\n\nGiget wouldn't be possible without inspiration from former projects. In comparison, giget does not depend on any local command which increases stability and performance, supports custom template providers, auth and many more features out of the box.\n\nhttps://github.com/samsonjs/gitter\nhttps://github.com/tiged/tiged\nhttps://github.com/Rich-Harris/degit\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "consola · UnJS",
    "url": "https://unjs.io/packages/consola",
    "html": "consola\n\nElegant Console Wrapper.\n\nElegant Console Wrapper\n\nWhy Consola?\n\n👌  Easy to use\n💅  Fancy output with fallback for minimal environments\n🔌  Pluggable reporters\n💻  Consistent command line interface (CLI) experience\n🏷  Tag support\n🚏  Redirect console and stdout/stderr to consola and easily restore redirect.\n🌐  Browser support\n⏯  Pause/Resume support\n👻  Mocking support\n👮‍♂️  Spam prevention by throttling logs\n❯  Interactive prompt support powered by clack\n\n\nInstallation\n\nUsing npm:\n\nnpm i consola\n\nCopy to clipboard\n\nUsing yarn:\n\nyarn add consola\n\nCopy to clipboard\n\nUsing pnpm:\n\npnpm i consola\n\nCopy to clipboard\nGetting Started\n// ESM\n\nimport { consola, createConsola } from \"consola\";\n\n\n\n// CommonJS\n\nconst { consola, createConsola } = require(\"consola\");\n\n\n\nconsola.info(\"Using consola 3.0.0\");\n\nconsola.start(\"Building project...\");\n\nconsola.warn(\"A new version of consola is available: 3.0.1\");\n\nconsola.success(\"Project built!\");\n\nconsola.error(new Error(\"This is an example error. Everything is fine!\"));\n\nconsola.box(\"I am a simple box\");\n\nawait consola.prompt(\"Deploy to the production?\", {\n\n  type: \"confirm\",\n\n});\n\nCopy to clipboard\n\nWill display in the terminal:\n\nYou can use smaller core builds without fancy reporter to save 80% of the bundle size:\n\nimport { consola, createConsola } from \"consola/basic\";\n\nimport { consola, createConsola } from \"consola/browser\";\n\nimport { createConsola } from \"consola/core\";\n\nCopy to clipboard\nConsola Methods\n<type>(logObject) <type>(args...)\n\nLog to all reporters.\n\nExample: consola.info('Message')\n\nawait prompt(message, { type })\n\nShow an input prompt. Type can either of text, confirm, select or multiselect.\n\nSee examples/prompt.ts for usage examples.\n\naddReporter(reporter)\nAliases: add\n\nRegister a custom reporter instance.\n\nremoveReporter(reporter?)\nAliases: remove, clear\n\nRemove a registered reporter.\n\nIf no arguments are passed all reporters will be removed.\n\nsetReporters(reporter|reporter[])\n\nReplace all reporters.\n\ncreate(options)\n\nCreate a new Consola instance and inherit all parent options for defaults.\n\nwithDefaults(defaults)\n\nCreate a new Consola instance with provided defaults\n\nwithTag(tag)\nAliases: withScope\n\nCreate a new Consola instance with that tag.\n\nwrapConsole() restoreConsole()\n\nGlobally redirect all console.log, etc calls to consola handlers.\n\nwrapStd() restoreStd()\n\nGlobally redirect all stdout/stderr outputs to consola.\n\nwrapAll() restoreAll()\n\nWrap both, std and console.\n\nconsole uses std in the underlying so calling wrapStd redirects console too. Benefit of this function is that things like console.info will be correctly redirected to the corresponding type.\n\npauseLogs() resumeLogs()\nAliases: pause/resume\n\nGlobally pause and resume logs.\n\nConsola will enqueue all logs when paused and then sends them to the reported when resumed.\n\nmockTypes\nAliases: mock\n\nMock all types. Useful for using with tests.\n\nThe first argument passed to mockTypes should be a callback function accepting (typeName, type) and returning the mocked value:\n\nconsola.mockTypes((typeName, type) => jest.fn());\n\nCopy to clipboard\n\nPlease note that with the example above, everything is mocked independently for each type. If you need one mocked fn create it outside:\n\nconst fn = jest.fn();\n\nconsola.mockTypes(() => fn);\n\nCopy to clipboard\n\nIf callback function returns a falsy value, that type won't be mocked.\n\nFor example if you just need to mock consola.fatal:\n\nconsola.mockTypes((typeName) => typeName === \"fatal\" && jest.fn());\n\nCopy to clipboard\n\nNOTE: Any instance of consola that inherits the mocked instance, will apply provided callback again. This way, mocking works for withTag scoped loggers without need to extra efforts.\n\nCustom Reporters\n\nConsola ships with 3 built-in reporters out of the box. A fancy colored reporter by default and fallsback to a basic reporter if running in a testing or CI environment detected using unjs/std-env and a basic browser reporter.\n\nYou can create a new reporter object that implements { log(logObject): () => { } } interface.\n\nExample: Simple JSON reporter\n\nimport { createConsola } from \"consola\";\n\n\n\nconst consola = createConsola({\n\n  reporters: [\n\n    {\n\n      log: (logObj) => {\n\n        console.log(JSON.stringify(logObj));\n\n      },\n\n    },\n\n  ],\n\n});\n\n\n\n// Prints {\"date\":\"2023-04-18T12:43:38.693Z\",\"args\":[\"foo bar\"],\"type\":\"log\",\"level\":2,\"tag\":\"\"}\n\nconsola.log(\"foo bar\");\n\nCopy to clipboard\nLog Level\n\nConsola only shows logs with configured log level or below. (Default is 3)\n\nAvailable log levels:\n\n0: Fatal and Error\n1: Warnings\n2: Normal logs\n3: Informational logs, success, fail, ready, start, ...\n4: Debug logs\n5: Trace logs\n-999: Silent\n+999: Verbose logs\n\nYou can set the log level by either:\n\nPassing level option to createConsola\nSetting consola.level on instance\nUsing the CONSOLA_LEVEL environment variable (not supported for browser and core builds).\nLog Types\n\nLog types are exposed as consola.[type](https://raw.githubusercontent.com/unjs/consola/main/...) and each is a preset of styles and log level.\n\nA list of all available built-in types is available here.\n\nCreating a new instance\n\nConsola has a global instance and is recommended to use everywhere. In case more control is needed, create a new instance.\n\nimport { createConsola } from \"consola\";\n\n\n\nconst logger = createConsola({\n\n  // level: 4,\n\n  // fancy: true | false\n\n  // formatOptions: {\n\n  //     columns: 80,\n\n  //     colors: false,\n\n  //     compact: false,\n\n  //     date: false,\n\n  // },\n\n});\n\nCopy to clipboard\nIntegrations\nWith jest or vitest\ndescribe(\"your-consola-mock-test\", () => {\n\n  beforeAll(() => {\n\n    // Redirect std and console to consola too\n\n    // Calling this once is sufficient\n\n    consola.wrapAll();\n\n  });\n\n\n\n  beforeEach(() => {\n\n    // Re-mock consola before each test call to remove\n\n    // calls from before\n\n    consola.mockTypes(() => jest.fn());\n\n  });\n\n\n\n  test(\"your test\", async () => {\n\n    // Some code here\n\n\n\n    // Let's retrieve all messages of `consola.log`\n\n    // Get the mock and map all calls to their first argument\n\n    const consolaMessages = consola.log.mock.calls.map((c) => c[0]);\n\n    expect(consolaMessages).toContain(\"your message\");\n\n  });\n\n});\n\nCopy to clipboard\nWith jsdom\n{\n\n  virtualConsole: new jsdom.VirtualConsole().sendTo(consola);\n\n}\n\nCopy to clipboard\nConsole Utils\n// ESM\n\nimport {\n\n  stripAnsi,\n\n  centerAlign,\n\n  rightAlign,\n\n  leftAlign,\n\n  align,\n\n  box,\n\n  colors,\n\n  getColor,\n\n  colorize,\n\n} from \"consola/utils\";\n\n\n\n// CommonJS\n\nconst { stripAnsi } = require(\"consola/utils\");\n\nCopy to clipboard"
  },
  {
    "title": "get-port-please · UnJS",
    "url": "https://unjs.io/packages/get-port-please/",
    "html": "get-port-please\n\nGet an available open port\n\nGet an available TCP port to listen\n\nUsage\n\nInstall package:\n\nnpm i get-port-please\n\n// ESM\n\nimport {\n\n  getPort,\n\n  checkPort,\n\n  getRandomPort,\n\n  waitForPort,\n\n} from \"get-port-please\";\n\n\n\n// CommonJS\n\nconst {\n\n  getPort,\n\n  checkPort,\n\n  getRandomPort,\n\n  waitForPort,\n\n} = require(\"get-port-please\");\n\ngetPort(options?: GetPortOptions): Promise<number>\n\ncheckPort(port: number, host?: string): Promise<number | false>\n\nwaitForPort(port: number, options): Promise<number | false>\n\n\nTry sequence is: port > ports > random\n\nOptions\ninterface GetPortOptions {\n\n  name?: string;\n\n\n\n  random?: boolean;\n\n  port?: number;\n\n  portRange?: [from: number, to: number];\n\n  ports?: number[];\n\n  host?: string;\n\n\n\n  memoDir?: string;\n\n  memoName?: string;\n\n}\n\nname\n\nUnique name for port memorizing. Default is default.\n\nrandom\n\nIf enabled, port and ports will be ignored. Default is false.\n\nport\n\nFirst port to check. Default is process.env.PORT || 3000\n\nports\n\nExtended ports to check.\n\nportRange\n\nExtended port range to check.\n\nalternativePortRange\n\nAlternative port range to check as fallback when non of the ports are available. Default is [3000, 3100] (only when port in unspecified.)\n\nhost\n\nThe host to check. Default is process.env.HOST otherwise all available hosts will be checked.\n"
  },
  {
    "title": "fs-memo · UnJS",
    "url": "https://unjs.io/packages/fs-memo/",
    "html": "fs-memo\n\nEasy persisted memo object for Node.js\n\nEasy persisted memo object for Node.js\n\nUsage\n\nInstall package:\n\nyarn add fs-memo\n\n# or\n\nor npm install fs-memo\n\nconst { getMemo, setMemo } = require('fs-memo')\n\n// or\n\nimport { getMemo, setMemo } from 'fs-memo'\n\ngetMemo(options)\ngetMemo(options: MemoOptions): Promise<any>\n\n\nLoad latest memo from file-system and combine with local state from CJS cache.\n\nFS loading silently bails if:\n\nThe process that made memo is still alive with different pid\nAny fs error happens (like permission denied)\nsetMemo(options)\nsetMemo(memo: object, options: MemoOptions): Promise<void>\n\n\nUpdate local state from CJS cache and persist memo object to file-system.\n\nFS persistence silently bails if any error happens.\n\nOptions\ndir\n\nSpecify directory where memo file should be stored. Default dir is node_modules/.cache/fs-memo\n\nname\n\nName of memo file. Default name is default (.json is appended to file name)\n\nfile\n\nOptionally provide full path to file (discards dir and name options)\n"
  },
  {
    "title": "destr · UnJS",
    "url": "https://unjs.io/packages/destr/",
    "html": "destr\n\nA faster, secure and convenient alternative for JSON.parse.\n\nA faster, secure and convenient alternative for JSON.parse.\n\nUsage\nNode.js\n\nInstall dependency:\n\n# npm\n\nnpm i destr\n\n\n\n# yarn\n\nyarn add destr\n\n\n\n# pnpm\n\npnpm i destr\n\n\nImport into your Node.js project:\n\n// ESM\n\nimport { destr, safeDestr } from \"destr\";\n\n\n\n// CommonJS\n\nconst { destr, safeDestr } = require(\"destr\");\n\nDeno\nimport { destr, safeDestr } from \"https://deno.land/x/destr/src/index.ts\";\n\n\n\nconsole.log(destr('{ \"deno\": \"yay\" }'));\n\nWhy?\n✅ Type Safe\nconst obj = JSON.parse(\"{}\"); // obj type is any\n\n\n\nconst obj = destr(\"{}\"); // obj type is unknown by default\n\n\n\nconst obj = destr<MyInterface>(\"{}\"); // obj is well-typed\n\n✅ Fast fallback to input if is not string\n\n🚀 Up to 500 times faster than JSON.parse!\n\n// Uncaught SyntaxError: Unexpected token u in JSON at position 0\n\nJSON.parse();\n\n\n\n// undefined\n\ndestr();\n\n✅ Fast lookup for known string values\n\n🚀 Up to 900 times faster than JSON.parse!\n\n// Uncaught SyntaxError: Unexpected token T in JSON at position 0\n\nJSON.parse(\"TRUE\");\n\n\n\n// true\n\ndestr(\"TRUE\");\n\n✅ Fallback to original value if parse fails (empty or any plain string)\n\n🚀 Up to 900 times faster than JSON.parse!\n\n// Uncaught SyntaxError: Unexpected token s in JSON at position 0\n\nJSON.parse(\"salam\");\n\n\n\n// \"salam\"\n\ndestr(\"salam\");\n\n\nNote: This fails in safe/strict mode with safeDestr.\n\n✅ Avoid prototype pollution\nconst input = '{ \"user\": { \"__proto__\": { \"isAdmin\": true } } }';\n\n\n\n// { user: { __proto__: { isAdmin: true } } }\n\nJSON.parse(input);\n\n\n\n// { user: {} }\n\ndestr(input);\n\n✅ Strict Mode\n\nWhen using safeDestr it will throw an error if the input is not a valid JSON string or parsing fails. (non string values and built-ins will be still returned as-is)\n\n// Returns \"[foo\"\n\ndestr(\"[foo\");\n\n\n\n// Throws an error\n\nsafeDestr(\"[foo\");\n\nBenchmarks\n\ndestr is sometimes little bit slower than JSON.parse when parsing a valid JSON string mainly because of transform to avoid prototype pollution which can lead to serious security issues if not being sanitized. In the other words, destr is better when input is not always a JSON string or from untrusted source like request body.\n\nCheck Benchmarks\n"
  },
  {
    "title": "defu · UnJS",
    "url": "https://unjs.io/packages/defu/",
    "html": "defu\n\nAssign default properties, recursively. Lightweight and Fast.\n\nAssign default properties, recursively. Lightweight and Fast.\n\nInstall\n\nInstall package:\n\n# yarn\n\nyarn add defu\n\n# npm\n\nnpm install defu\n\n# pnpm\n\npnpm install defu\n\nUsage\nimport { defu } from \"defu\";\n\n\n\nconst options = defu(object, ...defaults);\n\n\nLeftmost arguments have more priority when assigning defaults.\n\nArguments\nobject (Object): The destination object.\nsource (Object): The source object.\nimport { defu } from \"defu\";\n\n\n\nconsole.log(defu({ a: { b: 2 } }, { a: { b: 1, c: 3 } }));\n\n// => { a: { b: 2, c: 3 } }\n\nUsing with CommonJS\nconst { defu } = require(\"defu\");\n\nCustom Merger\n\nSometimes default merging strategy is not desirable. Using createDefu we can create a custom instance with different merging strategy.\n\nThis function accepts obj (source object), key and value (current value) and should return true if applied custom merging.\n\nExample: Sum numbers instead of overriding\n\nimport { createDefu } from \"defu\";\n\n\n\nconst ext = createDefu((obj, key, value) => {\n\n  if (typeof obj[key] === \"number\" && typeof value === \"number\") {\n\n    obj[key] += value;\n\n    return true;\n\n  }\n\n});\n\n\n\next({ cost: 15 }, { cost: 10 }); // { cost: 25 }\n\nFunction Merger\n\nUsing defuFn, if user provided a function, it will be called with default value instead of merging.\n\nIt can be useful for default values manipulation.\n\nExample: Filter some items from defaults (array) and add 20 to the count default value.\n\nimport { defuFn } from \"defu\";\n\n\n\ndefuFn(\n\n  {\n\n    ignore: (val) => val.filter((item) => item !== \"dist\"),\n\n    count: (count) => count + 20,\n\n  },\n\n  {\n\n    ignore: [\"node_modules\", \"dist\"],\n\n    count: 10,\n\n  },\n\n);\n\n/*\n\n {\n\n    ignore: ['node_modules'],\n\n    count: 30\n\n  }\n\n  */\n\n\nNote: if the default value is not defined, the function defined won't be called and kept as value.\n\nArray Function Merger\n\ndefuArrayFn is similar to defuFn but only applies to array values defined in defaults.\n\nExample: Filter some items from defaults (array) and add 20 to the count default value.\n\nimport { defuArrayFn } from 'defu'\n\n\n\ndefuArrayFn({\n\n  ignore: (val) => val.filter(i => i !== 'dist'),\n\n  count: () => 20\n\n }, {\n\n   ignore: [\n\n     'node_modules',\n\n     'dist'\n\n   ],\n\n   count: 10\n\n })\n\n /*\n\n  {\n\n    ignore: ['node_modules'],\n\n    count: () => 20\n\n  }\n\n  */\n\n\nNote: the function is called only if the value defined in defaults is an aray.\n\nRemarks\nobject and defaults are not modified\nNullish values (null and undefined) are skipped. Please use defaults-deep or omit-deep or lodash.defaultsdeep if you need to preserve or different behavior.\nAssignment of __proto__ and constructor keys will be skipped to prevent security issues with object pollution.\nWill concat array values (if default property is defined)\nconsole.log(defu({ array: [\"b\", \"c\"] }, { array: [\"a\"] }));\n\n// => { array: ['b', 'c', 'a'] }\n\nType\n\nWe expose Defu as a type utility to return a merged type that follows the rules that defu follows.\n\nimport type { Defu } from 'defu'\n\n\n\ntype Options = Defu<{ foo: 'bar' }, [{}, { bar: 'baz' }, { something: 42 }]>\n\n// returns { foo: 'bar', bar: 'baz', 'something': 42 }\n"
  },
  {
    "title": "cookie-es · UnJS",
    "url": "https://unjs.io/packages/cookie-es/",
    "html": "cookie-es\n\nESM cookie serializer and deserializer\n\nESM build of cookie with bundled types.\n\nUsage\n\nInstall:\n\n# npm\n\nnpm i cookie-es\n\n\n\n# yarn\n\nyarn add cookie-es\n\n\nImport:\n\n// ESM\n\nimport { parse, serialize } from 'cookie-es'\n\n\n\n// CommonJS\n\nconst { parse, serialize } = require('cookie-es')\n"
  },
  {
    "title": "citty · UnJS",
    "url": "https://unjs.io/packages/citty/",
    "html": "citty\n\nElegant CLI Builder.\n\nElegant CLI Builder\n\nFast and lightweight argument parser based on mri\nSmart value parsing with typecast, boolean shortcuts and unknown flag handling\nNested sub-commands\nLazy and Async commands\nPlugable and composable API\nAuto generated usage and help\n\n🚧 This project is under heavy development. More features are coming soon!\n\nUsage\n\nInstall package:\n\n# npm\n\nnpm install citty\n\n\n\n# yarn\n\nyarn add citty\n\n\n\n# pnpm\n\npnpm install citty\n\n\nImport:\n\n// ESM\n\nimport { defineCommand, runMain } from \"citty\";\n\n\n\n// CommonJS\n\nconst { defineCommand, runMain } = require(\"citty\");\n\n\nDefine main command to run:\n\nimport { defineCommand, runMain } from \"citty\";\n\n\n\nconst main = defineCommand({\n\n  meta: {\n\n    name: \"hello\",\n\n    version: \"1.0.0\",\n\n    description: \"My Awesome CLI App\",\n\n  },\n\n  args: {\n\n    name: {\n\n      type: \"positional\",\n\n      description: \"Your name\",\n\n      required: true,\n\n    },\n\n    friendly: {\n\n      type: \"boolean\",\n\n      description: \"Use friendly greeting\",\n\n    },\n\n  },\n\n  run({ args }) {\n\n    console.log(`${args.friendly ? \"Hi\" : \"Greetings\"} ${args.name}!`);\n\n  },\n\n});\n\n\n\nrunMain(main);\n\nUtils\ndefineCommand\n\ndefineCommand is a type helper for defining commands.\n\nrunMain\n\nRuns a command with usage support and graceful error handling.\n\ncreateMain\n\nCreate a wrapper around command that calls runMain when called.\n\nrunCommand\n\nParses input args and runs command and sub-commands (unsupervised). You can access result key from returnd/awaited value to access command's result.\n\nparseArgs\n\nParses input arguments and applies defaults.\n\nrenderUsage\n\nRenders command usage to a string value.\n\nshowUsage\n\nRenders usage and prints to the console\n\nDevelopment\nClone this repository\nInstall latest LTS version of Node.js\nEnable Corepack using corepack enable\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "changelogen · UnJS",
    "url": "https://unjs.io/packages/changelogen/",
    "html": "changelogen\n\nGenerate Beautiful Changelogs using Conventional Commits.\n\nGenerate Beautiful Changelogs using Conventional Commits\n\nQuick Start\n\nGenerate a changelog in Markdown format and display in the console:\n\nnpx changelogen@latest\n\n\nGenerate a changelog, bump the version in package.json and update CHANGELOG.md (without commit):\n\nnpx changelogen@latest --bump\n\n\nBump the version, update CHANGELOG.md and make a git commit and tag:\n\nnpx changelogen@latest --release\n\nCLI Usage\nnpx changelogen@latest [...args] [--dir <dir>]\n\n\nArguments:\n\n--from: Start commit reference. When not provided, latest git tag will be used as default.\n--to: End commit reference. When not provided, latest commit in HEAD will be used as default.\n--dir: Path to git repository. When not provided, current working directory will be used as as default.\n--clean: Determine if the working directory is clean and if it is not clean, exit.\n--output: Changelog file name to create or update. Defaults to CHANGELOG.md and resolved relative to dir. Use --no-output to write to console only.\n--bump: Determine semver change and update version in package.json.\n--release. Bumps version in package.json and creates commit and git tags using local git. You can disable commit using --no-commit and tag using --no-tag. You can enable the automatic push of the new tag and release commit to your git repository by adding --push.\n--publish. Publishes package as a new version on npm. You will need to set authorisation tokens separately via .npmrc or environment variables.\n--publishTag Use custom npm tag for publishing (Default is latest)\n--nameSuffix: Adds suffix to package name (Example: --nameSuffix canary renames foo to foo-canary)\n--versionSuffix: Adds suffix to package version. When set without value or to true, uses date + commit hash as commit\n--canary. Shortcut to --bump --versionSuffix (--nameSuffix will be also added if arg has a string value).\n-r: Release as specific version.\n--major: Bump as a semver-major version\n--minor: Bump as a semver-minor version\n--patch: Bump as a semver-patch version\n--premajor: Bump as a semver-premajor version, can set id with string.\n--preminor: Bump as a semver-preminor version, can set id with string.\n--prepatch: Bump as a semver-prepatch version, can set id with string.\n--prerelease: Bump as a semver-prerelease version, can set id with string.\nchangelogen gh release\n\nChangelogen has built-in functionality to sync with with Github releases.\n\nIn order to manually sync a release, you can use changelogen gh release. It will parse current CHANGELOG.md from current repository (local, then remote) and create or update releases.\n\nUsage:\n\nnpx changelogen@latest gh release [all|versions...] [--dir] [--token]\n\n\nTo enable this integration, make sure there is a valid repository field in package.json or repo is set in .changelogenrc.\n\nBy default in unauthenticated mode, changelogen will open a browser link to make manual release. By providing github token, it can be automated.\n\nUsing environment variables or .env, use CHANGELOGEN_TOKENS_GITHUB or GITHUB_TOKEN or GH_TOKEN\nUsing CLI args, use --token <token>\nUsing global configuration, put tokens.github=<token> inside ~/.changlogenrc\nUsing GitHub CLI token when authenticated with gh auth login\nConfiguration\n\nConfiguration is loaded by unjs/c12 from cwd. You can use either changelog.config.json, changelog.config.{ts,js,mjs,cjs}, .changelogrc or use the changelog field in package.json.\n\nSee https://raw.githubusercontent.com/unjs/changelogen/main/src/config.ts for available options and defaults.\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "c12 · UnJS",
    "url": "https://unjs.io/packages/c12/",
    "html": "c12\n\nSmart Configuration Loader.\n\nSmart Configuration Loader.\n\nFeatures\nJSON, CJS, Typescript, and ESM config loader with unjs/jiti\nRC config support with unjs/rc9\nMultiple sources merged with unjs/defu\n.env support with dotenv\nReads config from the nearest package.json file\nExtends configurations from multiple local or git sources\nOverwrite with environment-specific configuration\nConfig watcher with auto-reload and HMR support\nUsage\n\nInstall package:\n\n# npm\n\nnpm install c12\n\n\n\n# yarn\n\nyarn add c12\n\n\n\n# pnpm\n\npnpm install c12\n\n\nImport:\n\n// ESM\n\nimport { loadConfig, watchConfig } from \"c12\";\n\n\n\n// CommonJS\n\nconst { loadConfig, watchConfig } = require(\"c12\");\n\n\nLoad configuration:\n\n// Get loaded config\n\nconst { config } = await loadConfig({});\n\n\n\n// Get resolved config and extended layers\n\nconst { config, configFile, layers } = await loadConfig({});\n\nLoading priority\n\nc12 merged config sources with unjs/defu by below order:\n\nConfig overrides passed by options\nConfig file in CWD\nRC file in CWD\nGlobal RC file in the user's home directory\nConfig from package.json\nDefault config passed by options\nExtended config layers\nOptions\ncwd\n\nResolve configuration from this working directory. The default is process.cwd()\n\nname\n\nConfiguration base name. The default is config.\n\nconfigFile\n\nConfiguration file name without extension. Default is generated from name (f.e., if name is foo, the config file will be => foo.config).\n\nSet to false to avoid loading the config file.\n\nrcFile\n\nRC Config file name. Default is generated from name (name=foo => .foorc).\n\nSet to false to disable loading RC config.\n\nglobalRC\n\nLoad RC config from the workspace directory and the user's home directory. Only enabled when rcFile is provided. Set to false to disable this functionality.\n\ndotenv\n\nLoads .env file if enabled. It is disabled by default.\n\npackageJson\n\nLoads config from nearest package.json file. It is disabled by default.\n\nIf true value is passed, c12 uses name field from package.json.\n\nYou can also pass either a string or an array of strings as a value to use those fields.\n\ndefaults\n\nSpecify default configuration. It has the lowest priority and is applied after extending config.\n\ndefaultConfig\n\nSpecify default configuration. It is applied before extending config.\n\noverrides\n\nSpecify override configuration. It has the highest priority and is applied before extending config.\n\njiti\n\nCustom unjs/jiti instance used to import configuration files.\n\njitiOptions\n\nCustom unjs/jiti options to import configuration files.\n\ngiget\n\nOptions passed to unjs/giget when extending layer from git source.\n\nenvName\n\nEnvironment name used for environment specific configuration.\n\nThe default is process.env.NODE_ENV. You can set envName to false or an empty string to disable the feature.\n\nExtending configuration\n\nIf resolved config contains a extends key, it will be used to extend the configuration.\n\nExtending can be nested and each layer can extend from one base or more.\n\nThe final config is merged result of extended options and user options with unjs/defu.\n\nEach item in extends is a string that can be either an absolute or relative path to the current config file pointing to a config file for extending or the directory containing the config file. If it starts with either github:, gitlab:, bitbucket:, or https:, c12 automatically clones it.\n\nFor custom merging strategies, you can directly access each layer with layers property.\n\nExample:\n\n// config.ts\n\nexport default {\n\n  colors: {\n\n    primary: \"user_primary\",\n\n  },\n\n  extends: [\"./theme\"],\n\n};\n\n// config.dev.ts\n\nexport default {\n\n  dev: true,\n\n};\n\n// theme/config.ts\n\nexport default {\n\n  extends: \"../base\",\n\n  colors: {\n\n    primary: \"theme_primary\",\n\n    secondary: \"theme_secondary\",\n\n  },\n\n};\n\n// base/config.ts\n\nexport default {\n\n  colors: {\n\n    primary: 'base_primary'\n\n    text: 'base_text'\n\n  }\n\n}\n\n\nThe loaded configuration would look like this:\n\n{\n\n  dev: true,\n\n  colors: {\n\n    primary: 'user_primary',\n\n    secondary: 'theme_secondary',\n\n    text: 'base_text'\n\n  }\n\n}\n\n\nLayers:\n\n[\n\n { config: /* theme config */, configFile: /* path/to/theme/config.ts */, cwd: /* path/to/theme */ },\n\n { config: /* base  config */, configFile: /* path/to/base/config.ts  */, cwd: /* path/to/base */ },\n\n { config: /* dev   config */, configFile: /* path/to/config.dev.ts  */, cwd: /* path/ */ },\n\n]\n\nExtending Config Layer from Remote Sources\n\nYou can also extend configuration from remote sources such as npm or github.\n\nIn the repo, there should be a config.ts (or config.{name}.ts) file to be considered as a valid config layer.\n\nExample: Extend from a github repository\n\n// config.ts\n\nexport default {\n\n  extends: \"gh:user/repo\",\n\n};\n\n\nExample: Extend from a github repository with branch and subpath\n\n// config.ts\n\nexport default {\n\n  extends: \"gh:user/repo/theme#dev\",\n\n};\n\n\nExample: Extend with clone configuration\n\n// config.ts\n\nexport default {\n\n  extends: [\"gh:user/repo\", { giget: { auth: process.env.GITHUB_TOKEN } }],\n\n};\n\n\nRefer to unjs/giget for more information.\n\nEnvironment-specific configuration\n\nUsers can define environment-specific configuration using these config keys:\n\n$test: {...}\n$development: {...}\n$production: {...}\n$env: { [env]: {...} }\n\nc12 tries to match envName and override environment config if specified.\n\nNote: Environment will be applied when extending each configuration layer. This way layers can provide environment-specific configuration.\n\nExample:\n\n{\n\n  // Default configuration\n\n  logLevel: 'info',\n\n\n\n  // Environment overrides\n\n  $test: { logLevel: 'silent' },\n\n  $development: { logLevel: 'warning' },\n\n  $production: { logLevel: 'error' },\n\n  $env: {\n\n    staging: { logLevel: 'debug' }\n\n  }\n\n}\n\nWatching Configuration\n\nyou can use watchConfig instead of loadConfig to load config and watch for changes, add and removals in all expected configuration paths and auto reload with new config.\n\nLifecycle hooks\nonWatch: This function is always called when config is updated, added, or removed before attempting to reload the config.\nacceptHMR: By implementing this function, you can compare old and new functions and return true if a full reload is not needed.\nonUpdate: This function is always called after the new config is updated. If acceptHMR returns true, it will be skipped.\nimport { watchConfig } from \"c12\";\n\n\n\nconst config = watchConfig({\n\n  cwd: \".\",\n\n  // chokidarOptions: {}, // Default is { ignoreInitial: true }\n\n  // debounce: 200 // Default is 100. You can set it to false to disable debounced watcher\n\n  onWatch: (event) => {\n\n    console.log(\"[watcher]\", event.type, event.path);\n\n  },\n\n  acceptHMR({ oldConfig, newConfig, getDiff }) {\n\n    const diff = getDiff();\n\n    if (diff.length === 0) {\n\n      console.log(\"No config changed detected!\");\n\n      return true; // No changes!\n\n    }\n\n  },\n\n  onUpdate({ oldConfig, newConfig, getDiff }) {\n\n    const diff = getDiff();\n\n    console.log(\"Config updated:\\n\" + diff.map((i) => i.toJSON()).join(\"\\n\"));\n\n  },\n\n});\n\n\n\nconsole.log(\"watching config files:\", config.watchingFiles);\n\nconsole.log(\"initial config\", config.config);\n\n\n\n// Stop watcher when not needed anymore\n\n// await config.unwatch();\n\n💻 Development\nClone this repository\nEnable Corepack using corepack enable (use npm i -g corepack for Node.js < 16.10)\nInstall dependencies using pnpm install\nRun interactive tests using pnpm dev"
  },
  {
    "title": "bundle-runner · UnJS",
    "url": "https://unjs.io/packages/bundle-runner/",
    "html": "bundle-runner\n\nRun webpack bundles in Node.js with optional VM sandboxing\n\nThis package allows running a Webpack bundle in Node.js with optional sandboxed context. Useful for development, loading bundle from memory (HMR) and a consistent way of loading bundle between development and production environments.\n\n✅ What sandboxing is for:\n\nOptional sandboxing using Node.js VM\nMitigate script evaluation side-effects to global object\nAvoid unwanted shared state\nAvoid memory leaks during HMR\n\n❌ What sandboxing is not for:\n\nFully avoid side effects of evaluation\nA secure sandbox to run untrusted code\nHigh performance\nInstall\nyarn add bundle-runner\n\n\n\nnpm install bundle-runner\n\nUsage\nimport { createBundle } from 'bundle-runner'\n\n\n\nconst { evaluateEntry } = createBundle('path/to/bundle.json')\n\n\n\nconst entry = evaluateEntry(context)\n\n\ncreateBundle\n\nfunction createBundle(bundle: Partial<Bundle> | string, options?: CreateBundleOptions): {\n\n    bundle: Bundle;\n\n    evaluateEntry: (context: object) => any;\n\n    evaluateModule: (filename: string, context: object) => any;\n\n    rewriteErrorTrace: (err: Error) => Promise<Error>;\n\n}\n\n\nCreateBundleOptions\n\ntype CreateBundleOptions = {\n\n    basedir?: string;\n\n    runInNewContext?: 'once' | boolean;\n\n    runningScriptOptions?: VM.RunningScriptOptions;\n\n}\n\nBundle Format\n\nInput can be string (path to a .js file or .json file with bundle format) or directly bundle object with type of:\n\ntype Bundle = {\n\n    basedir: string;\n\n    entry: string;\n\n    files: {\n\n        [filename: string]: string\n\n    };\n\n    maps: {\n\n        [filename: string]: string\n\n    };\n\n}\n\nSourceMap Support\n\nAfter creating bundle, a rewriteErrorTrace utility is exposed which you can use to rewrite traces:\n\nconst { evaluateEntry, rewriteErrorTrace } = createBundle('path/to/bundle.json')\n\n\n\ntry {\n\n  const entry = evaluateEntry(context)\n\n  const app = await entry({})\n\n} catch (err) {\n\n  await rewriteErrorTrace(err)\n\n  throw err\n\n}\n\nCredits\n\nInspired by vue-server-renderer made by Evan You.\n"
  },
  {
    "title": "Packages · UnJS",
    "url": "https://unjs.io/packages/",
    "html": "Packages\n\nEvery project of the organization. A gateway to our galaxy of JavaScript utilities, libraries, and tools created to empower developers.\n\nPackages list\nName\nbundle-runner\n\nRun webpack bundles in Node.js with optional VM sandboxing\n\nc12\n\nSmart Configuration Loader.\n\nchangelogen\n\nGenerate Beautiful Changelogs using Conventional Commits.\n\ncitty\n\nElegant CLI Builder.\n\nconsola\n\nElegant Console Wrapper.\n\ncookie-es\n\nESM cookie serializer and deserializer\n\ndefu\n\nAssign default properties, recursively. Lightweight and Fast.\n\ndestr\n\nA faster, secure and convenient alternative for JSON.parse.\n\nfs-memo\n\nEasy persisted memo object for Node.js\n\nget-port-please\n\nGet an available open port\n\ngiget\n\nDownload templates and git repositories with pleasure!\n\nh3\n\nA minimal h(ttp) framework built for high performance and portability.\n\nhookable\n\nAwaitable Hooks\n\nhttpxy\n\nA Full-Featured HTTP and WebSocket Proxy for Node.js\n\nimage-meta\n\nDetect image type and size using pure javascript.\n\nipx\n\nHigh performance, secure and easy to use image proxy based on Sharp and libvips.\n\njimp-compact\n\nLightweight version of Jimp -- An image processing library written entirely in JavaScript for Node.js\n\njiti\n\nRuntime TypeScript and ESM support for Node.js\n\nknitwork\n\nUtilities to generate JavaScript code.\n\nlisthen\n\nElegant HTTP Listener\n\nmagicast\n\nProgrammatically modify JavaScript and TypeScript source codes.\n\nmkdist\n\nLightweight file-to-file transpiler.\n\nmlly\n\nMissing ECMAScript module utils for Node.js\n\nmongoz\n\nZero Config MongoDB Server\n\nnitro\n\nCreate web servers that run anywhere.\n\nnode-fetch-native\n\nA better redistribution of node-fetch\n\nnypm\n\nUnified Package Manager for Node.js\n\nofetch\n\nA better fetch API. Works on node, browser and workers.\n\nohash\n\nSuper fast hashing library based on murmurhash3 written in Vanilla JS\n\npathe\n\nDrop-in replacement of the Node.js's path module module that ensures paths are normalized\n\nperfect-debounce\n\nDebounce promise-returning & async functions.\n\npkg-types\n\nNode.js utilities and TypeScript definitions for package.json and tsconfig.json\n\nradix3\n\nLightweight and fast router for JavaScript based on Radix Tree\n\nrc9\n\nRead/Write config couldn't be easier!\n\nscule\n\nString Case Utils\n\nserve-placeholder\n\nSmart placeholder for missing assets\n\nstd-env\n\nRuntime agnostic JS utils\n\ntheme-colors\n\nEasily generate color shades for themes\n\nufo\n\nURL utils for humans.\n\nunbuild\n\nAn unified javascript build system.\n\nuncrypto\n\nSingle API for Web Crypto API and Crypto Subtle working in Node.js, Browsers and other runtimes\n\nunctx\n\nComposables in vanilla JS\n\nunenv\n\nConvert JavaScript code to be runtime agnostic\n\nungh\n\nUnlimited access to github API\n\nunhead\n\n△ Universal document <head> tag manager. Tiny, adaptable and full-featured.\n\nunimport\n\nUnified utils for auto importing APIs in modules.\n\nunpdf\n\nUtilities to work with PDFs in Node.js, browser and workers\n\nunplugin\n\nUnified plugin system for Vite, Rollup, webpack, esbuild, and more\n\nunstorage\n\nAsync Key-Value storage API with dozens of built-in drivers and a tiny core.\n\nuntun\n\nTunnel your local HTTP(s) server to the world! powered by Cloudflare Quick Tunnels.\n\nuntyped\n\nGenerate types and markdown from a config object.\n\nuqr\n\nGenerate QR Code universally, in any runtime, to ANSI, Unicode or SVG.\n\nwebpackbar\n\nElegant ProgressBar and Profiler for webpack 3 , 4 and 5"
  }
]
